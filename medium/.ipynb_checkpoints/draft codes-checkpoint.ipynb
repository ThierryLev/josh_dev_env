{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "359ee48a-7b9e-412a-a29d-a721d0747cfb",
   "metadata": {},
   "source": [
    "## MLOps With Kubeflow Pipelines (PartÂ 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0262e835-e335-4404-8ac4-723957cf103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import the entire dataset into `data` for quick EDA\n",
    "data = load_breast_cancer() \n",
    "df = pd.DataFrame(data = data.data, columns = data.feature_names) \n",
    "df['target'] = pd.Series(data.target) \n",
    "\n",
    "#import features into X and target into y for training\n",
    "X, y = load_breast_cancer(return_X_y = True, as_frame = True) \n",
    "\n",
    "# Create the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202f4c40-3089-4eec-8362-aff0540dcf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print head \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe42674-eeda-4e8f-93c8-1bf0333e3ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the dimenions of data\n",
    "print(data.shape)\n",
    "print(X.shape) \n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ebf4ea-9205-4250-959e-c61e5487fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Dataset and Train Model\n",
    "@component(\n",
    "    base_image=\"northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/wb-platform/pipelines/kubeflow-pycaret:latest\",\n",
    "    output_component_file=\"train_model.yaml\",\n",
    ")\n",
    "def model_training(\n",
    "            dataset_id: str,\n",
    "            file_bucket: str, \n",
    "            save_path: str,\n",
    "            model: Output[Model],\n",
    "            metrics: Output[Metrics],\n",
    "            metricsc: Output[ClassificationMetrics], \n",
    "            col_list: list \n",
    "    ) -> NamedTuple(\n",
    "        \"Outputs\",\n",
    "        [\n",
    "            (\"accuracy\", float),  # Return parameters\n",
    "            (\"f1_score\", float),\n",
    "            (\"roc_auc\", float), \n",
    "            (\"X_y_val_index\", list), \n",
    "            (\"model_location\", str)\n",
    "        ],\n",
    "    ):\n",
    "\n",
    "    ### Added to model_training component: save model artifacts in GCS bucket\n",
    "\n",
    "# Import Libraries\n",
    "import pickle\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from google.cloud import storage\n",
    "\n",
    "# define model artifacts and assign elements to the dict\n",
    "model_artifacts = {}\n",
    "create_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "model_artifacts['create_time'] = create_time\n",
    "model_artifacts['model'] = xgb_model\n",
    "model_artifacts['col_list'] = col_list\n",
    "\n",
    "# create and write model_artifacts.pkl\n",
    "with open('model_artifacts.pkl', 'wb') as pkl_file:\n",
    "    pickle.dump(model_artifacts, pkl_file)\n",
    "\n",
    "    # Use the 'pickle.dump()' method to serialize and store the 'model_artifacts' data\n",
    "    pickle.dump(model_artifacts, pkl_file)\n",
    "\n",
    "# create a gcs bucket instance\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(file_bucket)\n",
    "\n",
    "# define the folder path where the models will be saved. create one if not found. \n",
    "model_path = 'breast_cancer_models/'\n",
    "blob = bucket.blob(model_path)\n",
    "if not blob.exists(storage_client):\n",
    "    blob.upload_from_string('')\n",
    "\n",
    "# set model name and upload 'model_artifacts.pkl' to the folder in gcs bucket \n",
    "model_name = 'breast_cancer_models_{}'.format(model_artifacts['create_time'])\n",
    "model_location = f'{model_path}{model_name}'\n",
    "blob = bucket.blob(model_location)\n",
    "blob.upload_from_filename('model_artifacts.pkl')\n",
    "\n",
    "print(f\"Model artifacts loaded to GCS Bucket: {model_location}\")\n",
    "\n",
    "#     model.metadata['accuracy'] = accuracy\n",
    "#     model.metadata['precision'] = precision\n",
    "#     model.metadata['recall'] = recall\n",
    "#     model.metadata['f1_score'] = f1_score\n",
    "#     model.metadata['auc'] = roc_auc\n",
    "\n",
    "model.uri = f'gs://{file_bucket}/{model_location}'\n",
    "\n",
    "#     # Log additional model details \n",
    "#     with open(model.path, 'w') as output_file:\n",
    "#         output_file.write(f'You can enter additional model details here')\n",
    "#     output_file.close()\n",
    "    \n",
    "    time.sleep(120)\n",
    "\n",
    "    return (accuracy, f1_score, roc_auc, list(X_val.index), model_location)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497b2f47-ddd5-4df0-bc87-86aa43b16143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.v2.dsl import (Model, Input, Output, component)\n",
    "\n",
    "# Component for uploading model to Vertex Model Registry\n",
    "@component(\n",
    "# Uploads model\n",
    "    base_image=\"northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/wb-platform/pipelines/kubeflow-pycaret:latest\",\n",
    "    output_component_file=\"model-upload.yaml\",\n",
    ")\n",
    "\n",
    "def upload_model_to_mr(\n",
    "    model: Input[Model],\n",
    "    vertex_model: Output[Model],\n",
    "    model_name: str,\n",
    "    prediction_image: str,\n",
    "    col_list: list, \n",
    "    result: str\n",
    "):\n",
    "    from google.cloud import aiplatform\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "\n",
    "    aiplatform.init(project=project_id, location=region)\n",
    "    \n",
    "    if result == \"Pass\": \n",
    "\n",
    "        ## check for existing models \n",
    "        # if model already exists, update version\n",
    "        try:\n",
    "            model_uid = aiplatform.Model.list(\n",
    "                filter=f'display_name={model_name}',      \n",
    "                order_by=\"update_time\",\n",
    "                location=region)[-1].resource_name\n",
    "\n",
    "            uploaded_model = aiplatform.Model.upload(\n",
    "                display_name = model_name, \n",
    "                artifact_uri = os.path.dirname(model.uri),\n",
    "                parent_model = model_uid,\n",
    "                is_default_version = True\n",
    "            )\n",
    "        # if model does not exist, upload as a new model\n",
    "        except:\n",
    "            uploaded_model = aiplatform.Model.upload(\n",
    "                display_name = model_name,\n",
    "                artifact_uri = os.path.dirname(model.uri),\n",
    "            )\n",
    "\n",
    "        vertex_model.uri = uploaded_model.resource_name\n",
    "        vertex_model.version_create_time = datetime.now()\n",
    "        vertex_model.version_description = \"breast cancer model\" \n",
    "    \n",
    "    else: \n",
    "        \n",
    "        print(\"Training performance is not satisfactory. Upload to the Model Registry revoked.\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b7788-60af-4c5c-982b-aae58764a0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02bfa32-b10a-41b3-90de-13af9495e068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3958cb78-eeb7-4d13-ba97-491ca0a6262a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f09ce4e-7aea-4b17-96ff-61a9fa7ddff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683c1a3e-6989-45f8-9912-f6acfdf73dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
