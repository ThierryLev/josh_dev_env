{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1f0d6d-7daa-4e24-87fb-e09a8e5675c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output, OutputPath, ClassificationMetrics,\n",
    "                        Metrics, component)\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import google\n",
    "from google.oauth2 import credentials\n",
    "from google.oauth2 import service_account\n",
    "from google.oauth2.service_account import Credentials\n",
    "from google.cloud import storage\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "from google_cloud_pipeline_components.v1.batch_predict_job import \\\n",
    "    ModelBatchPredictOp as batch_prediction_op\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8becae65-c238-4e54-9930-64bef185c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME='divg-josh-pr-d1cc3a-default'\n",
    "REGION = \"northamerica-northeast1\"\n",
    "PIPELINE_ROOT = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fe9530-c7d7-4003-b6de-9b848a17a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(base_image=\"northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/wb-platform/pipelines/kubeflow-pycaret:latest\", output_component_file=\"component_one.yaml\")\n",
    "def input_integer(num: int) -> int:\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2319994f-0180-4c38-bfb9-77d6a889ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(base_image=\"northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/wb-platform/pipelines/kubeflow-pycaret:latest\", output_component_file=\"component_two.yaml\")\n",
    "def double_square(\n",
    "    num: int\n",
    ") -> NamedTuple(\n",
    "    \"Outputs\",\n",
    "    [\n",
    "        (\"value\", int),  # Return parameters\n",
    "        (\"double\", int),\n",
    "        (\"square\", int)\n",
    "    ],\n",
    "):\n",
    "    double = num * 2 \n",
    "    square = num * num\n",
    "\n",
    "    print(f\"input value: {num}, double: {double}, square: {square}\") \n",
    "    return (num, double, square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee995332-4b3b-4f62-acdb-22a2662b72aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(base_image=\"northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/wb-platform/pipelines/kubeflow-pycaret:latest\", output_component_file=\"component_three.yaml\")\n",
    "def show_results(\n",
    "    num: int,\n",
    "    double: int,\n",
    "    square: int\n",
    ") -> str:\n",
    "    print(\"Here is the output: \")\n",
    "\n",
    "    end_str = f\"The double of {num} is {double}, and the square of {num} is {square}\"\n",
    "\n",
    "    return end_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c86762-135e-43fe-b2ec-f506c589436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"demo-pipeline\",\n",
    "    description=\"vertex pipeline example\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "# You can change the `text` and `emoji_str` parameters here to update the pipeline output\n",
    "def pipeline(num: int = 5):\n",
    "    \n",
    "    # ----- component 1 --------\n",
    "    input_integer_op = input_integer(num)\n",
    "    \n",
    "    # ----- component 2 --------\n",
    "    double_square_op = double_square(num)\n",
    "    \n",
    "    # ----- component 3 --------\n",
    "    show_results_op = show_results(\n",
    "            input_integer_op.output,\n",
    "            double_square_op.outputs[\"double\"],\n",
    "            double_square_op.outputs[\"square\"] ,\n",
    "        ) \n",
    "    \n",
    "    show_results_op.after(input_integer_op)\n",
    "    show_results_op.after(double_square_op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea3138-ef53-4f80-9d80-1a74c5b5f15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.oauth2.credentials\n",
    "import json\n",
    "\n",
    "token = !gcloud auth print-access-token\n",
    "CREDENTIALS = google.oauth2.credentials.Credentials(token[0])\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "   pipeline_func=pipeline, package_path=\"pipeline.json\"\n",
    ")\n",
    "\n",
    "job = pipeline_jobs.PipelineJob(\n",
    "   display_name=\"demo-pipeline-job\",\n",
    "   template_path=\"pipeline.json\",\n",
    "   credentials = CREDENTIALS,\n",
    "   pipeline_root = PIPELINE_ROOT,\n",
    "   location=REGION,\n",
    "   enable_caching=True # I encourage you to enable caching when testing as it will reduce resource use\n",
    ")\n",
    "\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4b5eda-1962-4447-991c-eed5324e296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @dsl.pipeline(\n",
    "#     name=\"hello-world\",\n",
    "#     description=\"An intro pipeline\",\n",
    "#     pipeline_root=PIPELINE_ROOT,\n",
    "# )\n",
    "# # You can change the `text` and `emoji_str` parameters here to update the pipeline output\n",
    "# def intro_pipeline(text: str = \"Vertex Pipelines\", emoji_str: str = \"sparkles\"):\n",
    "#     product_task = product_name(text)\n",
    "#     emoji_task = emoji(emoji_str)\n",
    "#     consumer_task = build_sentence(\n",
    "#         product_task.output,\n",
    "#         emoji_task.outputs[\"emoji\"],\n",
    "#         emoji_task.outputs[\"emoji_text\"],\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c463822-2121-4613-a544-b603e83c8dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_square(\n",
    "    num: int,\n",
    ") -> NamedTuple(\n",
    "    \"Outputs\",\n",
    "    [\n",
    "        (\"value\", int),  # Return parameters\n",
    "        (\"double\", int),\n",
    "        (\"square\", int)\n",
    "    ],\n",
    "):\n",
    "    double = num * 2 \n",
    "    square = num * num\n",
    "\n",
    "    print(f\"input value: {num}, double: {double}, square: {square}\") \n",
    "    return (num, double, square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c733d084-0e5e-4501-a050-390f0f93bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_square(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3076205d-dd8a-46a5-83e5-63c3f8e3419d",
   "metadata": {},
   "source": [
    "## MLOps With Kubeflow Pipelines (PartÂ 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae23a433-f024-4d71-9e90-aefe64501688",
   "metadata": {},
   "source": [
    "### 1) Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c1aaf-bf49-43db-8fde-7c544938295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# import the entire dataset into `data` for quick EDA\n",
    "data = load_breast_cancer() \n",
    "df = pd.DataFrame(data = data.data, columns = data.feature_names) \n",
    "df['target'] = pd.Series(data.target) \n",
    "\n",
    "#import features into X and target into y for training\n",
    "X, y = load_breast_cancer(return_X_y = True, as_frame = True) \n",
    "\n",
    "# Create the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb65663-0fb7-437b-88c7-6c6f3e2e1d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('target')[['mean radius', 'mean perimeter', 'mean area']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f22794e-49c7-41c0-8924-282e5a912a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83afa26c-52e8-48a1-af8e-0b78f6ab9b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target names\n",
    "print(data.target_names)\n",
    "\n",
    "# Check value counts\n",
    "print(df['target'].value_counts()) \n",
    "\n",
    "# Analyzing the target variable\n",
    "plt.title('Count of cancer type')\n",
    "sns.countplot(x=df['target'])\n",
    "plt.xlabel('Cancer Severity')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ba213c-66b0-46d6-be63-6a626b589502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting correlation between diagnosis and radius\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "sns.boxplot(x=\"target\", y=\"mean radius\", data=df)\n",
    "plt.subplot(1,3,2)\n",
    "sns.boxplot(x=\"target\", y=\"mean perimeter\", data=df)\n",
    "plt.subplot(1,3,3)\n",
    "sns.boxplot(x=\"target\", y=\"mean concave points\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b6317f-e3f3-41ca-a4a4-970f99809b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf141a20-7526-448a-a2de-f1197d41e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Matplotlib and Seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create scatter plot of horsepower vs. mpg\n",
    "sns.relplot(x='mean radius', y='mean concave points', data=df, style='target', hue='target', kind='scatter')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a764288b-5843-4c24-b102-62261e606f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size the plot\n",
    "plt.figure(figsize=(15,4))\n",
    "\n",
    "# Plotting bivariate relations between each pair of features \n",
    "sns.pairplot(df, hue=\"target\", vars = [\"mean radius\", \"mean concave points\", \"mean texture\", \"mean smoothness\"])\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324e762f-e9fa-406f-8ec0-137559faa052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the data statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41505112-1c95-4043-8f88-44631ff9faec",
   "metadata": {},
   "source": [
    "### 2) Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bee86f4-677b-40dd-9356-638e301032ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output, OutputPath, ClassificationMetrics,\n",
    "                        Metrics, component)\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "from typing import NamedTuple\n",
    "import google\n",
    "from google.oauth2 import credentials\n",
    "from google.oauth2 import service_account\n",
    "from google.oauth2.service_account import Credentials\n",
    "from google.cloud import storage\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "from google_cloud_pipeline_components.v1.batch_predict_job import \\\n",
    "    ModelBatchPredictOp as batch_prediction_op\n",
    "\n",
    "# Import Dataset and Save in GCS\n",
    "@component(\n",
    "    base_image=\"northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/wb-platform/pipelines/kubeflow-pycaret:latest\",\n",
    "    output_component_file=\"import_data.yaml\",\n",
    ")\n",
    "def import_data(\n",
    "            project_id: str,\n",
    "            dataset_id: str,\n",
    "            file_bucket: str, \n",
    "    ) -> str: \n",
    "    # Import Libraries\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "    # import the entire dataset into 'data'\n",
    "    data = load_breast_cancer() \n",
    "    \n",
    "    # save the data in df, including the targets\n",
    "    df = pd.DataFrame(data = data.data, columns = data.feature_names) \n",
    "    df['target'] = pd.Series(data.target) \n",
    "    \n",
    "    # save df in cloud storage \n",
    "    save_path = f'gs://{file_bucket}/{dataset_id}/{dataset_id}_data.csv'\n",
    "    df.to_csv(save_path, index=True) \n",
    "    \n",
    "    print(f'{dataset_id}_data.csv saved in {save_path}')\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "# Load Dataset and Train Model\n",
    "@component(\n",
    "    base_image=\"northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/wb-platform/pipelines/kubeflow-pycaret:latest\",\n",
    "    output_component_file=\"train_model.yaml\",\n",
    ")\n",
    "def model_training(\n",
    "            project_id: str,\n",
    "            dataset_id: str,\n",
    "            file_bucket: str, \n",
    "            save_path: str,\n",
    "            metrics: Output[Metrics],\n",
    "            metricsc: Output[ClassificationMetrics]\n",
    "    ) -> NamedTuple(\n",
    "        \"Outputs\",\n",
    "        [\n",
    "            (\"accuracy\", int),  # Return parameters\n",
    "            (\"roc_auc\", int),\n",
    "            (\"f1_score\", int)\n",
    "        ],\n",
    "    ):\n",
    "    # Import Libraries\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from sklearn import metrics\n",
    "    from sklearn.datasets import load_breast_cancer\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import xgboost as xgb\n",
    "    from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "    \n",
    "    # Read csv that was saved in 'import_data' component\n",
    "    df = pd.read_csv(save_path)  \n",
    "\n",
    "    # X and y\n",
    "    y = np.squeeze(df['target'].values)\n",
    "    X = df.drop(columns='target')\n",
    "\n",
    "    # Create the training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "    # Instantiate the XGB Classifier: xgb_model\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=100,\n",
    "        max_depth=8,\n",
    "        min_child_weight=1,\n",
    "        max_delta_step=1, \n",
    "        colsample_bytree=0.9,\n",
    "        subsample=0.9,\n",
    "        objective='binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1, \n",
    "        eval_metric='auc', \n",
    "        base_score=0.5\n",
    "    )\n",
    "\n",
    "    # Fit the classifier to the training set\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict based on X_test\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Model accuracy \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    # ROC AUC Score\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    print(\"ROC AUC Score:\", roc_auc)\n",
    "    \n",
    "    # F1 Score \n",
    "    f1_score = f1_score(y_test, y_pred)\n",
    "    print(\"F1 Score:\", f1_score)\n",
    "    \n",
    "    return (accuracy, roc_auc, f1_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece8b567-6c9e-4409-a834-bcae43b99fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag cell with parameters\n",
    "PROJECT_ID =  'divg-josh-pr-d1cc3a'\n",
    "BUCKET_NAME='divg-josh-pr-d1cc3a-default'\n",
    "DATASET_ID = 'breast_cancer'\n",
    "RESOURCE_BUCKET = 'divg-josh-pr-d1cc3a-default'\n",
    "FILE_BUCKET = 'divg-josh-pr-d1cc3a-default'\n",
    "MODEL_ID = '5070'\n",
    "REGION = 'northamerica-northeast1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca60f16-73dd-4f72-85d6-4faaa2039e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "from kfp.v2 import compiler\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "@dsl.pipeline(\n",
    "    name='breast-cancer-pipeline', \n",
    "    description='breast-cancer-pipeline'\n",
    "    )\n",
    "def pipeline(\n",
    "        project_id: str = PROJECT_ID,\n",
    "        region: str = REGION,\n",
    "        resource_bucket: str = RESOURCE_BUCKET, \n",
    "        file_bucket: str = FILE_BUCKET\n",
    "    ):\n",
    "    \n",
    "    import google.oauth2.credentials\n",
    "    token = !gcloud auth print-access-token\n",
    "    token_str = token[0]\n",
    "    \n",
    "    # ----- create training set --------\n",
    "    import_data_op = import_data(project_id=PROJECT_ID,\n",
    "                          dataset_id=DATASET_ID,\n",
    "                          file_bucket=FILE_BUCKET)\n",
    "    \n",
    "    model_training_op = model_training(project_id=PROJECT_ID,\n",
    "                          dataset_id=DATASET_ID,\n",
    "                          file_bucket=FILE_BUCKET, \n",
    "                          save_path=import_data_op.output)\n",
    "    \n",
    "    \n",
    "    model_training_op.after(import_data_op)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee492c4-c526-497a-ba7d-cd4d163da6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.oauth2.credentials\n",
    "import json\n",
    "\n",
    "token = !gcloud auth print-access-token\n",
    "CREDENTIALS = google.oauth2.credentials.Credentials(token[0])\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "   pipeline_func=pipeline, package_path=\"pipeline.json\"\n",
    ")\n",
    "\n",
    "job = pipeline_jobs.PipelineJob(\n",
    "   display_name='breast-cancer-pipeline',\n",
    "   template_path=\"pipeline.json\",\n",
    "   credentials = CREDENTIALS,\n",
    "   pipeline_root = f\"gs://{FILE_BUCKET}\",\n",
    "   location=REGION,\n",
    "   enable_caching=True # I encourage you to enable caching when testing as it will reduce resource use\n",
    ")\n",
    "\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f824254c-27f6-4aef-aa42-3911eaca0901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88857d8-9b3c-4473-b64d-60bf34bc7575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af52f31-2d56-40e5-9d23-42124f5c988b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ae135-771b-44ea-aba0-2b90e958b652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113878d5-705d-4adf-9851-9b1b03a264bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a1ec55-0ace-4f75-9584-2b6cff9d33e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e3c31-8f15-4625-9df2-bc8c344820e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8a0ac9-8ec3-45ff-ab71-1ebddbc7885b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f2cac0-219b-4f56-9815-b500d975b396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151cee16-07e8-4383-8123-cc54493dedc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c2202-e635-4960-8db1-7e44e7a2c201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
