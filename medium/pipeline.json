{
  "pipelineSpec": {
    "components": {
      "comp-import-data": {
        "executorLabel": "exec-import-data",
        "inputDefinitions": {
          "parameters": {
            "dataset_id": {
              "type": "STRING"
            },
            "file_bucket": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "parameters": {
            "Output": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-model-evaluation": {
        "executorLabel": "exec-model-evaluation",
        "inputDefinitions": {
          "parameters": {
            "accuracy": {
              "type": "DOUBLE"
            },
            "accuracy_threshold": {
              "type": "DOUBLE"
            },
            "f1_score": {
              "type": "DOUBLE"
            },
            "f1_score_threshold": {
              "type": "DOUBLE"
            },
            "roc_auc": {
              "type": "DOUBLE"
            },
            "roc_auc_threshold": {
              "type": "DOUBLE"
            }
          }
        },
        "outputDefinitions": {
          "parameters": {
            "pass_fail": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-model-training": {
        "executorLabel": "exec-model-training",
        "inputDefinitions": {
          "parameters": {
            "dataset_id": {
              "type": "STRING"
            },
            "file_bucket": {
              "type": "STRING"
            },
            "save_path": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "metricsc": {
              "artifactType": {
                "schemaTitle": "system.ClassificationMetrics",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "X_y_val_index": {
              "type": "STRING"
            },
            "accuracy": {
              "type": "DOUBLE"
            },
            "f1_score": {
              "type": "DOUBLE"
            },
            "roc_auc": {
              "type": "DOUBLE"
            }
          }
        }
      }
    },
    "deploymentSpec": {
      "executors": {
        "exec-import-data": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "import_data"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.11' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef import_data(\n            dataset_id: str,\n            file_bucket: str, \n    ) -> str: \n    # Import Libraries\n    import pandas as pd\n    import numpy as np\n    from sklearn.datasets import load_breast_cancer\n\n    # import the entire dataset into 'data'\n    data = load_breast_cancer() \n\n    # save the data in df, including the targets\n    df = pd.DataFrame(data = data.data, columns = data.feature_names) \n    df['target'] = pd.Series(data.target) \n\n    # save df in cloud storage \n    save_path = f'gs://{file_bucket}/{dataset_id}/{dataset_id}_data.csv'\n    df.to_csv(save_path, index=True) \n\n    print(f'{dataset_id}_data.csv saved in {save_path}')\n\n    return save_path\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/wb-platform/pipelines/kubeflow-pycaret:latest"
          }
        },
        "exec-model-evaluation": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "model_evaluation"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.11' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef model_evaluation(\n            accuracy: float, \n            f1_score: float, \n            roc_auc: float, \n            accuracy_threshold: float, \n            f1_score_threshold: float, \n            roc_auc_threshold: float\n            ) -> NamedTuple(\n                \"Output\", [(\"pass_fail\", str)]\n            ):\n\n    # Set checker to True\n    checker = True\n\n    # Set checker to False if any of the eval metrics is below threshold\n    if accuracy < accuracy_threshold: \n        checker = False \n    if f1_score < f1_score_threshold: \n        checker = False \n    if roc_auc < roc_auc_threshold: \n        checker = False \n\n    # if checker == True, return \"Pass\", otherwise return \"Fail\"\n    if checker == True: \n        return (\"Pass\",) \n    else: \n        return (\"Fail\",)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/wb-platform/pipelines/kubeflow-pycaret:latest"
          }
        },
        "exec-model-training": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "model_training"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.11' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef model_training(\n            dataset_id: str,\n            file_bucket: str, \n            save_path: str,\n            metrics: Output[Metrics],\n            metricsc: Output[ClassificationMetrics]\n    ) -> NamedTuple(\n        \"Outputs\",\n        [\n            (\"accuracy\", float),  # Return parameters\n            (\"f1_score\", float),\n            (\"roc_auc\", float), \n            (\"X_y_val_index\", list), \n        ],\n    ):\n    # Import Libraries\n    import pandas as pd\n    import numpy as np\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    from sklearn.datasets import load_breast_cancer\n    from sklearn.model_selection import train_test_split\n    import xgboost as xgb\n    from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, roc_curve, confusion_matrix\n\n    # Read csv that was saved in 'import_data' component\n    df = pd.read_csv(save_path)  \n\n    # X and y\n    y = np.squeeze(df['target'].values)\n    X = df.drop(columns='target')\n\n    # Create the training and test sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n\n    # Reserve some samples for final validation\n    X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.2, random_state=123)\n\n    # Instantiate the XGB Classifier: xgb_model\n    xgb_model = xgb.XGBClassifier(\n        learning_rate=0.01,\n        n_estimators=100,\n        max_depth=8,\n        min_child_weight=1,\n        max_delta_step=1, \n        colsample_bytree=0.9,\n        subsample=0.9,\n        objective='binary:logistic',\n        nthread=4,\n        scale_pos_weight=1, \n        eval_metric='auc', \n        base_score=0.5\n    )\n\n    # Fit the classifier to the training set\n    xgb_model.fit(X_train, y_train)\n\n    # Predict based on X_test\n    y_pred = xgb_model.predict(X_test)\n    y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n\n    # Model accuracy \n    accuracy = accuracy_score(y_test, y_pred)\n    print(\"Accuracy:\", accuracy)\n\n    # Precision & Recall \n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n\n    # F1 Score \n    f1_score = f1_score(y_test, y_pred)\n    print(\"F1 Score:\", f1_score)\n\n    # ROC AUC Score\n    roc_auc = roc_auc_score(y_test, y_pred_proba)\n    print(\"ROC AUC Score:\", roc_auc)\n\n    # Log eval metrics\n    metrics.log_metric(\"Model\", \"XGBClassifier\")\n    metrics.log_metric(\"Size\", df.shape[0])\n    metrics.log_metric(\"Accuracy\",(accuracy * 100.0))\n    metrics.log_metric(\"AUC\", roc_auc)\n    metrics.log_metric(\"F1_Score\", f1_score)\n\n    # Compute fpr, tpr, thresholds for the ROC Curve\n    fpr, tpr, thresholds = roc_curve(\n        y_true=y_test, y_score=y_pred_proba, pos_label=True\n    )\n\n    # Log classification metrics\n    metricsc.log_roc_curve(fpr.tolist(), tpr.tolist(), thresholds.tolist())\n    metricsc.log_confusion_matrix(['Malignant', 'Benign'], confusion_matrix(y_test, y_pred).tolist())\n\n    return (accuracy, f1_score, roc_auc, list(X_val.index))\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/wb-platform/pipelines/kubeflow-pycaret:latest"
          }
        }
      }
    },
    "pipelineInfo": {
      "name": "breast-cancer-pipeline"
    },
    "root": {
      "dag": {
        "outputs": {
          "artifacts": {
            "model-training-metrics": {
              "artifactSelectors": [
                {
                  "outputArtifactKey": "metrics",
                  "producerSubtask": "model-training"
                }
              ]
            },
            "model-training-metricsc": {
              "artifactSelectors": [
                {
                  "outputArtifactKey": "metricsc",
                  "producerSubtask": "model-training"
                }
              ]
            }
          }
        },
        "tasks": {
          "import-data": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-import-data"
            },
            "inputs": {
              "parameters": {
                "dataset_id": {
                  "componentInputParameter": "dataset_id"
                },
                "file_bucket": {
                  "componentInputParameter": "file_bucket"
                }
              }
            },
            "taskInfo": {
              "name": "import-data"
            }
          },
          "model-evaluation": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-model-evaluation"
            },
            "dependentTasks": [
              "model-training"
            ],
            "inputs": {
              "parameters": {
                "accuracy": {
                  "taskOutputParameter": {
                    "outputParameterKey": "accuracy",
                    "producerTask": "model-training"
                  }
                },
                "accuracy_threshold": {
                  "runtimeValue": {
                    "constantValue": {
                      "doubleValue": 0.95
                    }
                  }
                },
                "f1_score": {
                  "taskOutputParameter": {
                    "outputParameterKey": "f1_score",
                    "producerTask": "model-training"
                  }
                },
                "f1_score_threshold": {
                  "runtimeValue": {
                    "constantValue": {
                      "doubleValue": 0.95
                    }
                  }
                },
                "roc_auc": {
                  "taskOutputParameter": {
                    "outputParameterKey": "roc_auc",
                    "producerTask": "model-training"
                  }
                },
                "roc_auc_threshold": {
                  "runtimeValue": {
                    "constantValue": {
                      "doubleValue": 0.95
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "model-evaluation"
            }
          },
          "model-training": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-model-training"
            },
            "dependentTasks": [
              "import-data"
            ],
            "inputs": {
              "parameters": {
                "dataset_id": {
                  "componentInputParameter": "dataset_id"
                },
                "file_bucket": {
                  "componentInputParameter": "file_bucket"
                },
                "save_path": {
                  "taskOutputParameter": {
                    "outputParameterKey": "Output",
                    "producerTask": "import-data"
                  }
                }
              }
            },
            "taskInfo": {
              "name": "model-training"
            }
          }
        }
      },
      "inputDefinitions": {
        "parameters": {
          "dataset_id": {
            "type": "STRING"
          },
          "file_bucket": {
            "type": "STRING"
          },
          "region": {
            "type": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "model-training-metrics": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          },
          "model-training-metricsc": {
            "artifactType": {
              "schemaTitle": "system.ClassificationMetrics",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "schemaVersion": "2.0.0",
    "sdkVersion": "kfp-1.8.11"
  },
  "runtimeConfig": {
    "parameters": {
      "dataset_id": {
        "stringValue": "breast_cancer"
      },
      "file_bucket": {
        "stringValue": "divg-josh-pr-d1cc3a-default"
      },
      "region": {
        "stringValue": "northamerica-northeast1"
      }
    }
  }
}