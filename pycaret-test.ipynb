{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e10a49d-244a-4f8f-b940-be5222702172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from datetime import datetime\n",
    "import logging \n",
    "from pycaret.classification import setup,create_model,tune_model, predict_model,get_config,compare_models,save_model,tune_model\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_curve, mean_squared_error, f1_score, precision_score, recall_score, confusion_matrix, roc_curve\n",
    "import gc\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac41ae3-3bc7-4ccb-bf30-95f40ec84765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag cell with parameters\n",
    "PROJECT_ID =  'divg-josh-pr-d1cc3a'\n",
    "BUCKET_NAME='divg-josh-pr-d1cc3a-default'\n",
    "DATASET_ID = 'telus_rewards'\n",
    "RESOURCE_BUCKET = 'divg-josh-pr-d1cc3a-default'\n",
    "FILE_BUCKET = 'divg-josh-pr-d1cc3a-default'\n",
    "MODEL_ID = '5070'\n",
    "SERVICE_TYPE = 'telus_rewards'\n",
    "\n",
    "project_id = PROJECT_ID \n",
    "bucket_name = BUCKET_NAME \n",
    "dataset_id = DATASET_ID \n",
    "resource_bucket = RESOURCE_BUCKET \n",
    "file_bucket = FILE_BUCKET \n",
    "service_type = SERVICE_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c5b2d-9528-4e88-b051-1ff29752562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google     \n",
    "import google.oauth2.credentials\n",
    "token = !gcloud auth print-access-token\n",
    "token_str = token[0]\n",
    "\n",
    "CREDENTIALS = google.oauth2.credentials.Credentials(token)\n",
    "\n",
    "client = bigquery.Client(project=project_id, location='northamerica-northeast1')\n",
    "storage_client = storage.Client(project=project_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692d89d2-7cb3-4602-bb00-6f81c9dbf646",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoringDate = date(2022, 7, 1)  # date.today() - relativedelta(days=2)- relativedelta(months=30)\n",
    "valScoringDate = date(2023, 1, 1)  # scoringDate - relativedelta(days=2)\n",
    "\n",
    "# training dates\n",
    "SCORE_DATE = scoringDate.strftime('%Y%m%d')  # date.today().strftime('%Y%m%d')\n",
    "SCORE_DATE_DASH = scoringDate.strftime('%Y-%m-%d')\n",
    "SCORE_DATE_MINUS_6_MOS_DASH = ((scoringDate - relativedelta(months=6)).replace(day=1)).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_LAST_MONTH_START_DASH = (scoringDate.replace(day=1) - timedelta(days=1)).replace(day=1).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_LAST_MONTH_END_DASH = ((scoringDate.replace(day=1)) - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "PROMO_EXPIRY_START = (scoringDate.replace(day=1) + relativedelta(months=3)).replace(day=1).strftime('%Y-%m-%d')\n",
    "PROMO_EXPIRY_END = (scoringDate.replace(day=1) + relativedelta(months=4)).replace(day=1).strftime('%Y-%m-%d')\n",
    "\n",
    "# validation dates\n",
    "SCORE_DATE_VAL = valScoringDate.strftime('%Y%m%d')\n",
    "SCORE_DATE_VAL_DASH = valScoringDate.strftime('%Y-%m-%d')\n",
    "SCORE_DATE_VAL_MINUS_6_MOS_DASH = ((valScoringDate - relativedelta(months=6)).replace(day=1)).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_VAL_LAST_MONTH_START_DASH = (valScoringDate.replace(day=1) - timedelta(days=1)).replace(day=1).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_VAL_LAST_MONTH_END_DASH = ((valScoringDate.replace(day=1)) - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "PROMO_EXPIRY_START_VAL = (valScoringDate.replace(day=1) + relativedelta(months=3)).replace(day=1).strftime('%Y-%m-%d')\n",
    "PROMO_EXPIRY_END_VAL = (valScoringDate.replace(day=1) + relativedelta(months=4)).replace(day=1).strftime('%Y-%m-%d')\n",
    "\n",
    "SCORE_DATE_DELTA = 0\n",
    "SCORE_DATE_VAL_DELTA = 0\n",
    "TICKET_DATE_WINDOW = 30  # Days of ticket data to be queried\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba64ec22-d02b-4f74-abf2-42374bcb9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# josh test starts here\n",
    "df_train = pd.read_csv('gs://{}/{}_train_monitoring.csv'.format(file_bucket, service_type))\n",
    "\n",
    "#set up df_train\n",
    "client = bigquery.Client(project=project_id)\n",
    "sql_train = ''' SELECT * FROM `{}.{}.bq_telus_rwrd_redemption_targets` '''.format(project_id, dataset_id) \n",
    "df_target_train = client.query(sql_train).to_dataframe()\n",
    "# df_target_train = df_target_train.loc[\n",
    "#     df_target_train['YEAR_MONTH'] == '-'.join(score_date_dash.split('-')[:2])]  # score_date_dash = '2022-08-31'\n",
    "df_target_train = df_target_train.loc[df_target_train['YEAR_MONTH'] == '2023']  # score_date_dash = '2022-08-31'\n",
    "df_target_train['ban'] = df_target_train['ban'].astype('int64')\n",
    "df_target_train = df_target_train.groupby('ban').tail(1)\n",
    "df_train = df_train.merge(df_target_train[['ban', 'target_ind']], on='ban', how='left')\n",
    "df_train.rename(columns={'target_ind': 'target'}, inplace=True)\n",
    "# df_train.dropna(subset=['target'], inplace=True)\n",
    "df_train.fillna(0, inplace=True)\n",
    "df_train['target'] = df_train['target'].astype(int)\n",
    "print(df_train.shape)\n",
    "\n",
    "train_all = df_train.copy()\n",
    "\n",
    "features = [col for col in train_all.columns if col not in ['ban', 'target']]\n",
    "\n",
    " ##############  Split train/valid/test based of Dev Training Sample Size   #######################\n",
    "training_perc = 0.62\n",
    "train_df = train_all.iloc[:int(train_all.shape[0]*training_perc)]\n",
    "\n",
    "lower_bound = int(train_all.shape[0]*training_perc)\n",
    "upper_bound = lower_bound + int(train_all.shape[0]*((1-training_perc)/2))\n",
    "valid_df = train_all.iloc[lower_bound:upper_bound]\n",
    "\n",
    "lower_bound = train_df.shape[0] + valid_df.shape[0]\n",
    "upper_bound = lower_bound + int(train_all.shape[0]*((1-training_perc)/2))\n",
    "test_df = train_all.iloc[lower_bound:]\n",
    "\n",
    "drop_cols =  ['ban']\n",
    "\n",
    "feats = [col for col in train_df.columns if col not in drop_cols]\n",
    "train_df.drop(columns = drop_cols , inplace=True)\n",
    "valid_df.drop(columns = drop_cols , inplace=True)\n",
    "\n",
    "print(train_df.columns)\n",
    "\n",
    "# train.rpc_flag = train.rpc_flag.astype(int)\n",
    "train_df.target = train_df.target.astype(int)\n",
    "valid_df.target = train_df.target.astype(int)\n",
    "test_df.target = test_df.target.astype(int)\n",
    "\n",
    "# //todo : Training class 0 and class 1 sample function integration\n",
    "numeric_features = [col for col in train_df.columns if col != 'target']\n",
    "\n",
    "################################ Pycaret Setup initialize  ############################ \n",
    "classification_setup = setup(data=train_df, \n",
    "                         # ignore_features=drop_cols,\n",
    "                         test_data = valid_df ,\n",
    "                         target='target',\n",
    "                         fix_imbalance=False,\n",
    "                         remove_outliers = True,\n",
    "                         normalize=True,\n",
    "                         normalize_method='zscore',\n",
    "                         log_experiment=False,\n",
    "                         remove_multicollinearity=True,\n",
    "                         multicollinearity_threshold=0.95,\n",
    "                         feature_selection=True,\n",
    "                         fold=5,\n",
    "                         fold_shuffle=True,\n",
    "                         session_id=123,\n",
    "                         numeric_features=numeric_features,\n",
    "                         silent=True)\n",
    "\n",
    "### Pycaret top 3 models to analyze\n",
    "best_model = compare_models(include = ['rf','xgboost','lightgbm','et'],errors='raise', n_select=3)\n",
    "# save the model reports and report fig of all top 2 models to GCS\n",
    "todays_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "save_path = f'pycaret/test_{todays_date}/'\n",
    "model_reports, model_to_report_map = evaluate_and_save_models(models=best_model.copy(), \n",
    "                                     bucket_name=file_bucket,\n",
    "                                     save_path=save_path, \n",
    "                                     test_df=test_df,\n",
    "                                     actual_label_str='target_ind',\n",
    "                                     columns = get_config('X_train').columns,\n",
    "                                     save_columns=True,\n",
    "                                     show_report=False)\n",
    "\n",
    "# Find the top Model and top model's report Figs\n",
    "top_model = None\n",
    "for i in range(len(best_model)):\n",
    "    if best_model[i].__class__.__name__ == model_reports.sort_values([\"Recall\",\"Precision\"],ascending=False).head(1)[\"model_name\"][0]:\n",
    "        top_model = best_model.copy()[i]\n",
    "\n",
    "\n",
    "best_model = model_reports.sort_values([\"Recall\",\"Precision\"],ascending=False).head(1)[\"model_name\"][0]\n",
    "best_model_report = model_to_report_map[top_model.__class__.__name__]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89237ca6-521e-43b8-93b7-9d1cc903e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_to_false_ratio = (7013/32853)\n",
    "\n",
    "def downsampling(df,true_to_false_ratio):\n",
    "    expected_rpc_flag_0 = df[df[\"target\"]==1][\"target\"].value_counts().values[0]/true_to_false_ratio\n",
    "    perc_samples = expected_rpc_flag_0/df[df[\"target\"]==0][\"target\"].value_counts().values[0]\n",
    "    \n",
    "    unique_trips_data = df[df[\"target\"]==0][[\"ban\"]].drop_duplicates()\n",
    "    unique_trips_sampled = unique_trips_data.sample(int(unique_trips_data.shape[0]*perc_samples))\n",
    "    \n",
    "    data_negtv_class = df[df[\"target\"]==0]\n",
    "    \n",
    "    data_ngtv_sampled = data_negtv_class[data_negtv_class[\"ban\"].isin(unique_trips_sampled.event_id.values)]\n",
    "    data_downsampled = pd.concat([data_ngtv_sampled,df[df[\"target\"]!=0]])\n",
    "    \n",
    "    return data_downsampled\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8b3361-4c68-47ed-ad78-7b813bcb3fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############  Downsample train/valid   #######################\n",
    "sample_perc_training = (7013/32853)\n",
    "train_sampled = downsampling(df=train_df, true_to_false_ratio=sample_perc_training)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_sampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ebb93f-c8b2-4445-90d4-f7a42023d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9fe423-70b9-4e57-801b-f24b253a4101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
