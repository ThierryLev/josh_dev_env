{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0c603b-3f78-40d0-bc02-7dac3ea2a76c",
   "metadata": {},
   "source": [
    "### Import Libraries, declare variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1294f3f-ee1c-4c57-bbb1-635ef08b52d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import google\n",
    "from google.oauth2 import credentials\n",
    "from google.oauth2 import service_account\n",
    "from google.oauth2.service_account import Credentials\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# build model\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "SERVICE_TYPE = 'tos_crosssell'\n",
    "DATASET_ID = 'tos_crosssell'\n",
    "PROJECT_ID = 'divg-josh-pr-d1cc3a' #mapping['PROJECT_ID']\n",
    "RESOURCE_BUCKET = 'divg-josh-pr-d1cc3a-default' #mapping['resources_bucket']\n",
    "FILE_BUCKET = 'divg-josh-pr-d1cc3a-default' #mapping['gcs_csv_bucket']\n",
    "REGION = 'northamerica-northeast1' #mapping['REGION']\n",
    "MODEL_ID = '9999'\n",
    "FOLDER_NAME = 'xgb_tos_cross_sell_train_deploy'.format(MODEL_ID)\n",
    "QUERIES_PATH = 'vertex_pipelines/' + FOLDER_NAME + '/queries/'\n",
    "\n",
    "scoringDate = date(2022, 7, 1)  # date.today() - relativedelta(days=2)- relativedelta(months=30)\n",
    "valScoringDate = date(2022, 10, 1)  # scoringDate - relativedelta(days=2)\n",
    "\n",
    "# training views\n",
    "CONSL_VIEW_NAME = '{}_pipeline_consl_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "FFH_BILLING_VIEW_NAME = '{}_pipeline_ffh_billing_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "HS_USAGE_VIEW_NAME = '{}_pipeline_hs_usage_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "DEMO_INCOME_VIEW_NAME = '{}_pipeline_demo_income_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "PROMO_EXPIRY_VIEW_NAME = '{}_pipeline_promo_expiry_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "TROUBLE_TICKETS_VIEW_NAME = '{}_pipeline_trouble_tickets_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "GPON_COPPER_VIEW_NAME = '{}_pipeline_gpon_copper_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "CALL_DATA_VIEW_NAME = '{}_pipeline_call_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "HSIA_DROPS_VIEW_NAME = '{}_pipeline_hsia_drops_training_bi_layer'.format(SERVICE_TYPE)\n",
    "CLCKSTRM_TELUS_VIEW_NAME = '{}_pipeline_clckstrm_telus_training_bi_layer'.format(SERVICE_TYPE)\n",
    "ALARMDOTCOM_APP_USAGE_VIEW_NAME = '{}_pipeline_alarmdotcom_app_usage_training_bi_layer'.format(SERVICE_TYPE)\n",
    "\n",
    "# validation views\n",
    "CONSL_VIEW_VALIDATION_NAME = '{}_pipeline_consl_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "FFH_BILLING_VIEW_VALIDATION_NAME = '{}_pipeline_ffh_billing_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "HS_USAGE_VIEW_VALIDATION_NAME = '{}_pipeline_hs_usage_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "DEMO_INCOME_VIEW_VALIDATION_NAME = '{}_pipeline_demo_income_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "PROMO_EXPIRY_VIEW_VALIDATION_NAME = '{}_pipeline_promo_expiry_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "TROUBLE_TICKETS_VIEW_VALIDATION_NAME = '{}_pipeline_trouble_tickets_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "GPON_COPPER_VIEW_VALIDATION_NAME = '{}_pipeline_gpon_copper_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "CALL_DATA_VIEW_VALIDATION_NAME = '{}_pipeline_call_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "HSIA_DROPS_VIEW_VALIDATION_NAME = '{}_pipeline_hsia_drops_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "CLCKSTRM_TELUS_VIEW_VALIDATION_NAME = '{}_pipeline_clckstrm_telus_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "ALARMDOTCOM_APP_USAGE_VIEW_VALIDATION_NAME = '{}_pipeline_alarmdotcom_app_usage_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "\n",
    "# training dates\n",
    "SCORE_DATE = scoringDate.strftime('%Y%m%d')  # date.today().strftime('%Y%m%d')\n",
    "SCORE_DATE_DASH = scoringDate.strftime('%Y-%m-%d')\n",
    "SCORE_DATE_MINUS_6_MOS_DASH = ((scoringDate - relativedelta(months=6)).replace(day=1)).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_LAST_MONTH_END_DASH = ((scoringDate.replace(day=1)) - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_LAST_MONTH_YEAR = ((scoringDate.replace(day=1)) - timedelta(days=1)).year\n",
    "SCORE_DATE_LAST_MONTH_MONTH = ((scoringDate.replace(day=1)) - timedelta(days=1)).month\n",
    "\n",
    "# validation dates\n",
    "SCORE_DATE_VAL = valScoringDate.strftime('%Y%m%d')\n",
    "\n",
    "SCORE_DATE_VAL_DASH = valScoringDate.strftime('%Y-%m-%d')\n",
    "SCORE_DATE_VAL_MINUS_6_MOS_DASH = ((valScoringDate - relativedelta(months=6)).replace(day=1)).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_VAL_LAST_MONTH_END_DASH = ((valScoringDate.replace(day=1)) - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_VAL_LAST_MONTH_YEAR = ((valScoringDate.replace(day=1)) - timedelta(days=1)).year\n",
    "SCORE_DATE_VAL_LAST_MONTH_MONTH = ((valScoringDate.replace(day=1)) - timedelta(days=1)).month\n",
    "\n",
    "SCORE_DATE_DELTA = 0\n",
    "SCORE_DATE_VAL_DELTA = 0\n",
    "TICKET_DATE_WINDOW = 30  # Days of ticket data to be queried\n",
    "\n",
    "ACCOUNT_CONSL_QUERY_PATH = QUERIES_PATH + 'create_input_account_consl_query.txt'\n",
    "ACCOUNT_HSIA_DROPS_QUERY_PATH = QUERIES_PATH + 'create_input_account_hsia_drops_query.txt'\n",
    "ACCOUNT_CALL_DATA_QUERY_PATH = QUERIES_PATH + 'create_input_account_call_data_query.txt'\n",
    "ACCOUNT_GPON_COPPER_QUERY_PATH = QUERIES_PATH + 'create_input_account_gpon_copper_query.txt'\n",
    "ACCOUNT_TROUBLE_TICKETS_QUERY_PATH = QUERIES_PATH + 'create_input_account_trouble_tickets_query.txt'\n",
    "ACCOUNT_PROMO_EXPIRY_QUERY_PATH = QUERIES_PATH + 'create_input_account_promo_expiry_query.txt'\n",
    "# ACCOUNT_TV_USAGE_QUERY_PATH = QUERIES_PATH + 'create_input_account_tv_usage_query.txt'\n",
    "ACCOUNT_DEMO_INCOME_QUERY_PATH = QUERIES_PATH + 'create_input_account_demo_income_query.txt'\n",
    "ACCOUNT_HS_USAGE_QUERY_PATH = QUERIES_PATH + 'create_input_account_hs_usage_query.txt'\n",
    "ACCOUNT_FFH_BILLING_QUERY_PATH = QUERIES_PATH + 'create_input_account_ffh_billing_query.txt'\n",
    "ACCOUNT_CLCKSTRM_TELUS_QUERY_PATH = QUERIES_PATH + 'create_input_account_clckstrm_telus_query.txt'\n",
    "ACCOUNT_ALARMDOTCOM_APP_USAGE_QUERY_PATH = QUERIES_PATH + 'create_input_account_alarmdotcom_app_usage_query.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a31e45-47f9-445e-aab4-1e2d8243e1f9",
   "metadata": {},
   "source": [
    "### define get_lift function, import df_train and df_test from gcs bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea3837b0-0180-4a8a-978d-b56402062efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "project_id = PROJECT_ID\n",
    "region = REGION\n",
    "resource_bucket = RESOURCE_BUCKET\n",
    "file_bucket = FILE_BUCKET\n",
    "service_type=SERVICE_TYPE\n",
    "score_date_dash=SCORE_DATE_DASH\n",
    "score_date_val_dash=SCORE_DATE_VAL_DASH\n",
    "project_id=PROJECT_ID\n",
    "dataset_id=DATASET_ID\n",
    "\n",
    "def get_lift(prob, y_test, q):\n",
    "    result = pd.DataFrame(columns=['Prob', 'Churn'])\n",
    "    result['Prob'] = prob\n",
    "    result['Churn'] = y_test\n",
    "    # result['Decile'] = pd.qcut(1-result['Prob'], 10, labels = False)\n",
    "    result['Decile'] = pd.qcut(result['Prob'], q, labels=[i for i in range(q, 0, -1)])\n",
    "    add = pd.DataFrame(result.groupby('Decile')['Churn'].mean()).reset_index()\n",
    "    add.columns = ['Decile', 'avg_real_churn_rate']\n",
    "    result = result.merge(add, on='Decile', how='left')\n",
    "    result.sort_values('Decile', ascending=True, inplace=True)\n",
    "    lg = pd.DataFrame(result.groupby('Decile')['Prob'].mean()).reset_index()\n",
    "    lg.columns = ['Decile', 'avg_model_pred_churn_rate']\n",
    "    lg.sort_values('Decile', ascending=False, inplace=True)\n",
    "    lg['avg_churn_rate_total'] = result['Churn'].mean()\n",
    "    lg = lg.merge(add, on='Decile', how='left')\n",
    "    lg['lift'] = lg['avg_real_churn_rate'] / lg['avg_churn_rate_total']\n",
    "\n",
    "    return lg\n",
    "\n",
    "df_train = pd.read_csv('gs://{}/{}_train.csv.gz'.format(file_bucket, service_type),\n",
    "                       compression='gzip')  # for 2022-08-01\n",
    "df_test = pd.read_csv('gs://{}/{}_validation.csv.gz'.format(file_bucket, service_type),  # 2022-09-01\n",
    "                      compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b56f45-0b8a-44bd-b6a2-e160f23b7b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot\n",
    "\n",
    "# Create the correlation matrix\n",
    "corr = df_train.corr()\n",
    "\n",
    "# Create the cmap \n",
    "cmap = sns.diverging_palette(h_neg = 10, h_pos = 240, as_cmap = True) \n",
    "\n",
    "# Draw the heatmap\n",
    "sns.heatmap(corr,  cmap=cmap, center=0, linewidths=1, annot=True, fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94961cc0-7e92-44eb-9e1e-15d16d2024ed",
   "metadata": {},
   "source": [
    "### add targets to df_train and df_target \n",
    "\n",
    "- df_target_train is from `divg-josh-pr-d1cc3a.tos_crosssell.bq_tos_cross_sell_targets_q3` \n",
    "- df_target_test is from `divg-josh-pr-d1cc3a.tos_crosssell.bq_tos_cross_sell_targets_q4` \n",
    "- some parts of the code and sql queries need to be dynamically adjusted to be included in the deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc272d97-768b-401b-9100-923cc63cf1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32559\n",
      "31756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_gcp_bqclient(project_id, use_local_credential=True):\n",
    "    token = os.popen('gcloud auth print-access-token').read()\n",
    "    token = re.sub(f'\\n$', '', token)\n",
    "    credentials = google.oauth2.credentials.Credentials(token)\n",
    "\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    if use_local_credential:\n",
    "        bq_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "    return bq_client\n",
    "\n",
    "client = get_gcp_bqclient(project_id)\n",
    "\n",
    "#set up df_train\n",
    "sql_train = ''' SELECT * FROM `{}.{}.bq_tos_cross_sell_targets_q3` '''.format(project_id, dataset_id)\n",
    "df_target_train = client.query(sql_train).to_dataframe()\n",
    "df_target_train = df_target_train.loc[\n",
    "    df_target_train['YEAR_MONTH'] == \"2022-Q3\"] #'-'.join(score_date_dash.split('-')[:2])]  # score_date_dash = '2022-08-31'\n",
    "\n",
    "#set up df_train and df_test (add 'target')\n",
    "df_target_train['ban'] = df_target_train['ban'].astype('int64')\n",
    "df_target_train = df_target_train.groupby('ban').tail(1)\n",
    "\n",
    "df_train = df_train.merge(df_target_train[['ban', 'product_crosssell_ind']], on='ban', how='left')\n",
    "df_train.rename(columns={'product_crosssell_ind': 'target'}, inplace=True)\n",
    "df_train.dropna(subset=['target'], inplace=True)\n",
    "df_train['target'] = df_train['target'].astype(int)\n",
    "df_train.to_csv('gs://{}/outputs/{}_train_final.csv'.format(FILE_BUCKET, SERVICE_TYPE), index=False)\n",
    "\n",
    "print(np.sum(df_train['target']))\n",
    "\n",
    "client = get_gcp_bqclient(project_id)\n",
    "\n",
    "#set up df_test\n",
    "sql_test = ''' SELECT * FROM `{}.{}.bq_tos_cross_sell_targets_q4` '''.format(project_id, dataset_id)\n",
    "df_target_test = client.query(sql_test).to_dataframe()\n",
    "df_target_test = df_target_test.loc[\n",
    "    df_target_test['YEAR_MONTH'] == \"2022-Q4\"] #'-'.join(score_date_val_dash.split('-')[:2])]  # score_date_dash = '2022-09-30'\n",
    "\n",
    "#set up df_train and df_test (add 'target')\n",
    "df_target_test['ban'] = df_target_test['ban'].astype('int64')\n",
    "df_target_test = df_target_test.groupby('ban').tail(1)\n",
    "\n",
    "df_test = df_test.merge(df_target_test[['ban', 'product_crosssell_ind']], on='ban', how='left')\n",
    "df_test.rename(columns={'product_crosssell_ind': 'target'}, inplace=True)\n",
    "df_test.dropna(subset=['target'], inplace=True)\n",
    "df_test['target'] = df_test['target'].astype(int)\n",
    "df_test.to_csv('gs://{}/outputs/{}_test_final.csv'.format(FILE_BUCKET, SERVICE_TYPE), index=False)\n",
    "\n",
    "print(np.sum(df_test['target']))\n",
    "\n",
    "#set up features (list)\n",
    "cols_1 = df_train.columns.values\n",
    "cols_2 = df_test.columns.values\n",
    "cols = set(cols_1).intersection(set(cols_2))\n",
    "features = [f for f in cols if f not in ['ban', 'target']]\n",
    "\n",
    "# #train test split\n",
    "# df_train, df_val = train_test_split(df_train, shuffle=True, test_size=0.3, random_state=42,\n",
    "#                                     stratify=df_train['target']\n",
    "#                                     )\n",
    "\n",
    "ban_train = df_train['ban']\n",
    "X_train = df_train[features]\n",
    "y_train = np.squeeze(df_train['target'].values)\n",
    "target_train = df_train['target']\n",
    "\n",
    "# ban_val = df_val['ban']\n",
    "# X_val = df_val[features]\n",
    "# y_val = np.squeeze(df_val['target'].values)\n",
    "# target_val = df_val['target']\n",
    "\n",
    "ban_test = df_test['ban']\n",
    "X_test = df_test[features]\n",
    "y_test = np.squeeze(df_test['target'].values)\n",
    "target_test = df_test['target']\n",
    "\n",
    "# del df_train, df_val, df_test\n",
    "del df_train, df_test\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfd29e3-d1b3-4cbe-983c-b0033ed8554a",
   "metadata": {},
   "source": [
    "### fit training data in xgboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe7616d7-5909-4cb8-8e74-821d3e92dee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb training done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build model and fit in training data\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1\n",
    "    # seed=27\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print('xgb training done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb7dfaa-92ea-4788-b698-392ed5ea442a",
   "metadata": {},
   "source": [
    "### fit training data in random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5235b1c5-c12c-4d1d-9826-e5f2aad525a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=9, max_features=8, n_estimators=75)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=9, max_features=8, n_estimators=75)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=9, max_features=8, n_estimators=75)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Create the random forest model and fit to the training data\n",
    "rfc = RandomForestClassifier(n_estimators=75, max_features=8, max_depth=9)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d2c799-5e4b-4b79-84c3-97208961956a",
   "metadata": {},
   "source": [
    "### make predictions on validation set and get auc score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df9015b5-b0e0-4b1a-bd1e-1e2ecbba4026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #predictions on X_val\n",
    "# y_pred = xgb_model.predict_proba(X_val, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "# y_pred_label = (y_pred > 0.5).astype(int)\n",
    "# auc = roc_auc_score(y_val, y_pred_label)\n",
    "# print(f'auc score is {auc}')\n",
    "# # metrics.log_metric(\"AUC\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994582c9-d3ff-4ecc-96c2-deaf0311fad3",
   "metadata": {},
   "source": [
    "### make predictions on X_test set, assign deciles to the predicted values, and save in df_test_exp (RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31e1c29c-7af6-4ce7-b1c0-d13bc20ae1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decile</th>\n",
       "      <th>avg_model_pred_churn_rate</th>\n",
       "      <th>avg_churn_rate_total</th>\n",
       "      <th>avg_real_churn_rate</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.040957</td>\n",
       "      <td>2.498731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.025029</td>\n",
       "      <td>1.526958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.020781</td>\n",
       "      <td>1.267794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.018014</td>\n",
       "      <td>1.099007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.015676</td>\n",
       "      <td>0.956356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.013941</td>\n",
       "      <td>0.850545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.011856</td>\n",
       "      <td>0.723329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.009311</td>\n",
       "      <td>0.568083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.005705</td>\n",
       "      <td>0.348069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>0.161181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Decile  avg_model_pred_churn_rate  avg_churn_rate_total  \\\n",
       "0      1                   0.001297              0.016391   \n",
       "1      2                   0.000925              0.016391   \n",
       "2      3                   0.000792              0.016391   \n",
       "3      4                   0.000699              0.016391   \n",
       "4      5                   0.000616              0.016391   \n",
       "5      6                   0.000540              0.016391   \n",
       "6      7                   0.000473              0.016391   \n",
       "7      8                   0.000413              0.016391   \n",
       "8      9                   0.000268              0.016391   \n",
       "9     10                   0.000101              0.016391   \n",
       "\n",
       "   avg_real_churn_rate      lift  \n",
       "0             0.040957  2.498731  \n",
       "1             0.025029  1.526958  \n",
       "2             0.020781  1.267794  \n",
       "3             0.018014  1.099007  \n",
       "4             0.015676  0.956356  \n",
       "5             0.013941  0.850545  \n",
       "6             0.011856  0.723329  \n",
       "7             0.009311  0.568083  \n",
       "8             0.005705  0.348069  \n",
       "9             0.002642  0.161181  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#predictions on X_test\n",
    "pred_prb = rfc.predict_proba(X_test)[:, 1]\n",
    "pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "#join ban_test, X_test, y_test and pred_prb and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_test = ban_test.to_frame()\n",
    "df_test_exp = df_ban_test.join(X_test) \n",
    "df_test_exp['y_test'] = y_test\n",
    "df_test_exp['y_pred_proba'] = pred_prb\n",
    "df_test_exp['y_pred'] = (df_test_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_test_exp['decile'] = pd.qcut(df_test_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(pred_prb, y_test, q)\n",
    "\n",
    "lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8450ef-a002-412e-8d8f-d2f63a43a59e",
   "metadata": {},
   "source": [
    "### make predictions on X_train set, assign deciles to the predicted values, and save in df_train_exp (RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8017502e-75eb-44e8-9edc-cfd06d42f14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decile</th>\n",
       "      <th>avg_model_pred_churn_rate</th>\n",
       "      <th>avg_churn_rate_total</th>\n",
       "      <th>avg_real_churn_rate</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.048860</td>\n",
       "      <td>2.887058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.025693</td>\n",
       "      <td>1.518170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.021052</td>\n",
       "      <td>1.243898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.018031</td>\n",
       "      <td>1.065447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.015926</td>\n",
       "      <td>0.941063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.013665</td>\n",
       "      <td>0.807459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.011218</td>\n",
       "      <td>0.662833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.008155</td>\n",
       "      <td>0.481868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.004475</td>\n",
       "      <td>0.264444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.127768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Decile  avg_model_pred_churn_rate  avg_churn_rate_total  \\\n",
       "0      1                   0.001260              0.016924   \n",
       "1      2                   0.000899              0.016924   \n",
       "2      3                   0.000773              0.016924   \n",
       "3      4                   0.000684              0.016924   \n",
       "4      5                   0.000603              0.016924   \n",
       "5      6                   0.000528              0.016924   \n",
       "6      7                   0.000461              0.016924   \n",
       "7      8                   0.000402              0.016924   \n",
       "8      9                   0.000251              0.016924   \n",
       "9     10                   0.000099              0.016924   \n",
       "\n",
       "   avg_real_churn_rate      lift  \n",
       "0             0.048860  2.887058  \n",
       "1             0.025693  1.518170  \n",
       "2             0.021052  1.243898  \n",
       "3             0.018031  1.065447  \n",
       "4             0.015926  0.941063  \n",
       "5             0.013665  0.807459  \n",
       "6             0.011218  0.662833  \n",
       "7             0.008155  0.481868  \n",
       "8             0.004475  0.264444  \n",
       "9             0.002162  0.127768  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#predictions on X_test\n",
    "pred_prb = rfc.predict_proba(X_train)[:, 1]\n",
    "pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "#join ban_test, X_test, y_test and pred_prb and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_train = ban_train.to_frame()\n",
    "df_train_exp = df_ban_train.join(X_train) \n",
    "df_train_exp['y_test'] = y_train\n",
    "df_train_exp['y_pred_proba'] = pred_prb\n",
    "df_train_exp['y_pred'] = (df_train_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_train_exp['decile'] = pd.qcut(df_train_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(pred_prb, y_train, q)\n",
    "\n",
    "lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0ea7ec-74db-4419-84bb-0d44545fec56",
   "metadata": {},
   "source": [
    "### make predictions on X_test set, assign deciles to the predicted values, and save in df_test_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b3c55fb-754b-4fa9-b0ac-cdcf45a3dc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/core.py:90: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decile</th>\n",
       "      <th>avg_model_pred_churn_rate</th>\n",
       "      <th>avg_churn_rate_total</th>\n",
       "      <th>avg_real_churn_rate</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.041246</td>\n",
       "      <td>2.516366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.025127</td>\n",
       "      <td>1.532981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.020595</td>\n",
       "      <td>1.256457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.018081</td>\n",
       "      <td>1.103072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.015638</td>\n",
       "      <td>0.954068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>0.871769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.011367</td>\n",
       "      <td>0.693474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.009169</td>\n",
       "      <td>0.559398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.005662</td>\n",
       "      <td>0.345418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>0.169313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Decile  avg_model_pred_churn_rate  avg_churn_rate_total  \\\n",
       "0      1                   0.000878              0.016391   \n",
       "1      2                   0.000776              0.016391   \n",
       "2      3                   0.000748              0.016391   \n",
       "3      4                   0.000730              0.016391   \n",
       "4      5                   0.000712              0.016391   \n",
       "5      6                   0.000694              0.016391   \n",
       "6      7                   0.000679              0.016391   \n",
       "7      8                   0.000666              0.016391   \n",
       "8      9                   0.000640              0.016391   \n",
       "9     10                   0.000608              0.016391   \n",
       "\n",
       "   avg_real_churn_rate      lift  \n",
       "0             0.041246  2.516366  \n",
       "1             0.025127  1.532981  \n",
       "2             0.020595  1.256457  \n",
       "3             0.018081  1.103072  \n",
       "4             0.015638  0.954068  \n",
       "5             0.014289  0.871769  \n",
       "6             0.011367  0.693474  \n",
       "7             0.009169  0.559398  \n",
       "8             0.005662  0.345418  \n",
       "9             0.002775  0.169313  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#predictions on X_test\n",
    "pred_prb = xgb_model.predict_proba(X_test, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "#join ban_test, X_test, y_test and pred_prb and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_test = ban_test.to_frame()\n",
    "df_test_exp = df_ban_test.join(X_test) \n",
    "df_test_exp['y_test'] = y_test\n",
    "df_test_exp['y_pred_proba'] = pred_prb\n",
    "df_test_exp['y_pred'] = (df_test_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_test_exp['decile'] = pd.qcut(df_test_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(pred_prb, y_test, q)\n",
    "\n",
    "lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2767b8f5-8bdb-4d5f-9b5b-2b340289cb94",
   "metadata": {},
   "source": [
    "### export df_test_exp and lift scores to gcs bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c2015d1-d1a5-410f-95c5-2b5054e2abac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....df_test_exp done\n",
      "....lift_to_csv done\n"
     ]
    }
   ],
   "source": [
    "df_test_exp.to_csv('gs://{}/df_test_exp.csv'.format(file_bucket, index=True))\n",
    "print(\"....df_test_exp done\")\n",
    "\n",
    "lg.to_csv('gs://{}/lift_on_scoring_data.csv'.format(file_bucket, index=False))\n",
    "print(\"....lift_to_csv done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a41125-a188-4bc4-885e-71d69a95b8f9",
   "metadata": {},
   "source": [
    "### make predictions on X_train set, assign deciles to the predicted values, and save in df_train_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbc6661c-06cc-44cb-8dd9-a3eba6696156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/core.py:90: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decile</th>\n",
       "      <th>avg_model_pred_churn_rate</th>\n",
       "      <th>avg_churn_rate_total</th>\n",
       "      <th>avg_real_churn_rate</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.046329</td>\n",
       "      <td>2.737498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.026395</td>\n",
       "      <td>1.559625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.021613</td>\n",
       "      <td>1.277076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.018161</td>\n",
       "      <td>1.073103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.015838</td>\n",
       "      <td>0.935865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.013911</td>\n",
       "      <td>0.821951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.011647</td>\n",
       "      <td>0.688221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.008550</td>\n",
       "      <td>0.505177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>0.267472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.141355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Decile  avg_model_pred_churn_rate  avg_churn_rate_total  \\\n",
       "0      1                   0.000876              0.016924   \n",
       "1      2                   0.000777              0.016924   \n",
       "2      3                   0.000750              0.016924   \n",
       "3      4                   0.000732              0.016924   \n",
       "4      5                   0.000715              0.016924   \n",
       "5      6                   0.000696              0.016924   \n",
       "6      7                   0.000680              0.016924   \n",
       "7      8                   0.000668              0.016924   \n",
       "8      9                   0.000641              0.016924   \n",
       "9     10                   0.000610              0.016924   \n",
       "\n",
       "   avg_real_churn_rate      lift  \n",
       "0             0.046329  2.737498  \n",
       "1             0.026395  1.559625  \n",
       "2             0.021613  1.277076  \n",
       "3             0.018161  1.073103  \n",
       "4             0.015838  0.935865  \n",
       "5             0.013911  0.821951  \n",
       "6             0.011647  0.688221  \n",
       "7             0.008550  0.505177  \n",
       "8             0.004527  0.267472  \n",
       "9             0.002392  0.141355  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#predictions on X_test\n",
    "pred_prb = xgb_model.predict_proba(X_train, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "#join ban_test, X_test, y_test and pred_prb and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_train = ban_train.to_frame()\n",
    "df_train_exp = df_ban_train.join(X_train) \n",
    "df_train_exp['y_test'] = y_train\n",
    "df_train_exp['y_pred_proba'] = pred_prb\n",
    "df_train_exp['y_pred'] = (df_train_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_train_exp['decile'] = pd.qcut(df_train_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(pred_prb, y_train, q)\n",
    "\n",
    "lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75c888e-9373-4a25-8803-68f1ad49e402",
   "metadata": {},
   "source": [
    "### export df_test_exp and lift scores to gcs bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3f246bb-de19-40dd-82d8-881903e10349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....df_train_exp done\n",
      "....lift_to_csv done\n"
     ]
    }
   ],
   "source": [
    "df_train_exp.to_csv('gs://{}/df_train_exp.csv'.format(file_bucket, index=True))\n",
    "print(\"....df_train_exp done\")\n",
    "\n",
    "lg.to_csv('gs://{}/lift_on_training_data_.csv'.format(file_bucket, index=False))\n",
    "print(\"....lift_to_csv done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab0b310-accc-4e60-98c7-cff0bc2db9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e1d814-e627-4b25-8ffe-6d15ee24b7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot\n",
    "\n",
    "# Create the correlation matrix\n",
    "corr = df_train.corr()\n",
    "\n",
    "# Create the cmap \n",
    "\n",
    "\n",
    "# Draw the heatmap\n",
    "sns.heatmap(corr,  cmap=cmap, center=0, linewidths=1, annot=True, fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce20d37b-0e62-4c81-b446-a88539baf2d9",
   "metadata": {},
   "source": [
    "### save the model in gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d46e0caa-94a8-497c-a395-15a1ac041f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....model loaded to GCS done at 2023-02-25 14:14:15\n"
     ]
    }
   ],
   "source": [
    "# save the model in GCS\n",
    "from datetime import datetime\n",
    "models_dict = {}\n",
    "create_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "models_dict['create_time'] = create_time\n",
    "models_dict['model'] = xgb_model\n",
    "models_dict['features'] = features\n",
    "\n",
    "with open('model_dict.pkl', 'wb') as handle:\n",
    "    pickle.dump(models_dict, handle)\n",
    "handle.close()\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(file_bucket)\n",
    "\n",
    "MODEL_PATH = '{}_xgb_models/'.format(service_type)\n",
    "blob = bucket.blob(MODEL_PATH)\n",
    "if not blob.exists(storage_client):\n",
    "    blob.upload_from_string('')\n",
    "\n",
    "model_name_onbkt = '{}{}_models_xgb_{}'.format(MODEL_PATH, service_type, models_dict['create_time'])\n",
    "blob = bucket.blob(model_name_onbkt)\n",
    "blob.upload_from_filename('model_dict.pkl')\n",
    "\n",
    "print(f\"....model loaded to GCS done at {str(create_time)}\")\n",
    "\n",
    "time.sleep(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8864bda6-bda0-4032-9704-f513da84e132",
   "metadata": {},
   "source": [
    "### get feature importances from xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43768ef0-d6cc-40e4-a3a9-dbcdbceedb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from xgboost model\n",
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "# Get the index of importances from greatest importance to least\n",
    "sorted_index = np.argsort(importances)[::-1]\n",
    "x = range(len(importances))\n",
    "\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create tick labels \n",
    "labels = np.array(feature_names)[sorted_index]\n",
    "importances = np.array(importances)[sorted_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dba71566-b4d2-4229-8d00-bfb4a3e42d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "productMix_ttv_count 0.11350101\n",
      "productMix_hsic_count 0.101344146\n",
      "ffhBill_tot_net_amt 0.089098126\n",
      "productMix_diic_count 0.073924825\n",
      "productMix_shs_count 0.03757007\n",
      "productMix_new_smhm_ind 0.03542313\n",
      "productMix_sing_count 0.035309553\n",
      "ffhBill_hsic_net_amt 0.027014019\n",
      "ffhBill_sing_net_amt 0.02688081\n",
      "promo_hsic_disc_exp_lst_nxt_mth_cnt 0.02306269\n",
      "productMix_product_mix_all 0.020749139\n",
      "promo_smhm_disc_exp_lst_nxt_mth_cnt 0.017816339\n",
      "ffhBill_ttv_net_amt 0.017370423\n",
      "promo_ttv_disc_exp_lst_nxt_mth_cnt 0.017116876\n",
      "demographics_demo_lsname_Young_Families 0.015965391\n",
      "hsiaUsage_avg_hs_tot_gb 0.015836013\n",
      "clckstrmData_wln_smarthome_security_cnt_r30d 0.014722373\n",
      "ffhBill_smhm_net_amt 0.014673728\n",
      "ffhBill_avg_ffh_amt 0.014010097\n",
      "clckstrmData_wln_security_cnt_r30d 0.012480994\n",
      "productMix_mnh_ind 0.011813527\n",
      "demographics_demo_lsname_Very_Young_Singles_and_Couples 0.011752597\n",
      "promo_ttv_disc_exp_lst_nxt_mth_amt 0.011130181\n",
      "demographics_demo_family_flag 0.011067462\n",
      "productMix_new_ttv_ind 0.010709765\n",
      "ffhBill_bill_tot_inv_amt 0.010067025\n",
      "infra_num_srvc_typ_gpon_sum 0.009990445\n",
      "demographics_demo_lsname_Younger_Singles_and_Couples 0.009703009\n",
      "productMix_mob_count 0.009544232\n",
      "productMix_new_hsic_ind 0.009445545\n",
      "demographics_demo_urban_flag 0.008868578\n",
      "promo_smhm_disc_exp_lst_nxt_mth_amt 0.008835479\n",
      "infra_num_srvc_typ_copper_sum 0.008748283\n",
      "demographics_demo_lsname_Older_Families_and_Empty_Nests 0.008649885\n",
      "promo_hsic_disc_exp_lst_nxt_mth_amt 0.008646554\n",
      "demographics_demo_lsname_Middle_Age_Families 0.008155869\n",
      "clckstrmData_wln_tot_cnt_r30d 0.008127465\n",
      "demographics_demo_lsname_School_Age_Families 0.007916705\n",
      "clckstrmData_tot_click_cnt_r30d 0.007908124\n",
      "demographics_demo_lsname_Mature_Singles_and_Couples 0.0075255223\n",
      "demographics_demo_lsname_Large_Diverse_Families 0.007023569\n",
      "ffhBill_other_net_amt 0.0068694814\n",
      "demographics_demo_avg_income 0.006811828\n",
      "promo_sing_disc_exp_lst_nxt_mth_amt 0.0064084786\n",
      "clckstrmData_wln_tv_cnt_r30d 0.0062401947\n",
      "productMix_new_c_ind 0.0062137074\n",
      "productMix_new_sing_ind 0.0060830195\n",
      "clckstrmData_wln_hsic_cnt_r30d 0.0057226704\n",
      "demographics_demo_lsname_Unassigned 0.005694831\n",
      "clckstrmData_wln_online_security_cnt_r30d 0.0056020375\n",
      "clckstrmData_wln_streaming_cnt_r30d 0.005301417\n",
      "promo_sing_disc_exp_lst_nxt_mth_cnt 0.0052982043\n",
      "clckstrmData_wln_smartwear_security_cnt_r30d 0.0050058146\n",
      "demographics_demo_rural_flag 0.0047514313\n",
      "productMix_stv_count 0.00449725\n",
      "alarmdotcomAppUsage_alarm_dl_pkt_kb 0.0\n",
      "alarmdotcomAppUsage_alarm_ul_vol_kb 0.0\n",
      "alarmdotcomAppUsage_alarm_dl_vol_kb 0.0\n",
      "alarmdotcomAppUsage_alarm_ul_pkt_kb 0.0\n"
     ]
    }
   ],
   "source": [
    "for idx, item in enumerate(labels): \n",
    "    print(labels[idx], importances[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccc17986-5dd7-4e6c-8b90-55d8c7b4ae20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11350101, 0.10134415, 0.08909813, 0.07392482, 0.03757007,\n",
       "       0.03542313, 0.03530955, 0.02701402, 0.02688081, 0.02306269,\n",
       "       0.02074914, 0.01781634, 0.01737042, 0.01711688, 0.01596539,\n",
       "       0.01583601, 0.01472237, 0.01467373, 0.0140101 , 0.01248099,\n",
       "       0.01181353, 0.0117526 , 0.01113018, 0.01106746, 0.01070977,\n",
       "       0.01006703, 0.00999045, 0.00970301, 0.00954423, 0.00944555,\n",
       "       0.00886858, 0.00883548, 0.00874828, 0.00864988, 0.00864655,\n",
       "       0.00815587, 0.00812746, 0.0079167 , 0.00790812, 0.00752552,\n",
       "       0.00702357, 0.00686948, 0.00681183, 0.00640848, 0.00624019,\n",
       "       0.00621371, 0.00608302, 0.00572267, 0.00569483, 0.00560204,\n",
       "       0.00530142, 0.0052982 , 0.00500581, 0.00475143, 0.00449725,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc6c8ac8-5108-4d00-ac4b-c649bb2d7399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 56, 57, 55, 58])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07cc154-244e-4352-8f89-a4e8a3670613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "036d6fe5-7b90-4200-a9bd-1432adfc08c0",
   "metadata": {},
   "source": [
    "### Plotting the ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a260a7-011f-4e98-9c2d-84cec00d85f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pred_prb) \n",
    "plt.plot([0, 1], [0, 1], 'k--') \n",
    "plt.plot(fpr, tpr) \n",
    "plt.xlabel('False Positive Rate') \n",
    "plt.ylabel('True Positive Rate') \n",
    "plt.title('Logistic Regression ROC Curve') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e986d2-bd7d-4fd8-b44d-7ea221df5e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b9f58-8334-43ed-8ea2-bf76eaf93804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d9d01-f009-45c6-90fe-95a61cc169cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb40188a-3865-4993-be01-fb27f7d07dd6",
   "metadata": {},
   "source": [
    "### load the latest saved xgb_model to the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f240186-29e9-4d12-8c11-bb468cae8067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_PATH = '{}_xgb_models/'.format(service_type)\n",
    "# df_score = pd.read_csv('gs://{}/{}_score.csv.gz'.format(file_bucket, service_type), compression='gzip')\n",
    "# df_score.dropna(subset=['ban'], inplace=True)\n",
    "# df_score.reset_index(drop=True, inplace=True)\n",
    "# print('......scoring data loaded:{}'.format(df_score.shape))\n",
    "# time.sleep(10)\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "MODEL_PATH = '{}_xgb_models/'.format(service_type)\n",
    "\n",
    "def load_model(file_bucket: str, service_type: str): \n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(file_bucket)\n",
    "    blobs = storage_client.list_blobs(file_bucket, prefix='{}{}_models_xgb_'.format(MODEL_PATH, service_type))\n",
    "\n",
    "    model_lists = []\n",
    "    for blob in blobs:\n",
    "        model_lists.append(blob.name)\n",
    "\n",
    "    blob = bucket.blob(model_lists[-1])\n",
    "    blob_in = blob.download_as_string()\n",
    "    model_dict = pickle.loads(blob_in)\n",
    "    xgb_model = model_dict['model']\n",
    "    features = model_dict['features']\n",
    "    print('...... model loaded')\n",
    "    time.sleep(10)\n",
    "    \n",
    "    return xgb_model, features\n",
    "\n",
    "xgb_model, features = load_model(file_bucket = FILE_BUCKET, service_type = SERVICE_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625bbaf0-6a67-4151-8504-a187037aa4f8",
   "metadata": {},
   "source": [
    "### backup codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ced94be-d4ec-4eb5-8aed-8199f09bdbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gcp_bqclient(project_id, use_local_credential=True):\n",
    "    token = os.popen('gcloud auth print-access-token').read()\n",
    "    token = re.sub(f'\\n$', '', token)\n",
    "    credentials = google.oauth2.credentials.Credentials(token)\n",
    "\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    if use_local_credential:\n",
    "        bq_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "    return bq_client\n",
    "\n",
    "client = get_gcp_bqclient(project_id)\n",
    "\n",
    "#instantiate df_target_train and df_target_test\n",
    "sql_train = ''' SELECT * FROM `{}.{}.bq_tos_cross_sell_targets_q3` '''.format(project_id, dataset_id)\n",
    "df_target_train = client.query(sql_train).to_dataframe()\n",
    "df_target_train = df_target_train.loc[\n",
    "    df_target_train['YEAR_MONTH'] == \"2022-Q3\"] #'-'.join(score_date_dash.split('-')[:2])]  # score_date_dash = '2022-08-31'\n",
    "\n",
    "#set up df_train and df_test (add 'target')\n",
    "df_target_train['ban'] = df_target_train['ban'].astype('int64')\n",
    "df_target_train = df_target_train.groupby('ban').tail(1)\n",
    "\n",
    "df_train = df_train.merge(df_target_train[['ban', 'product_crosssell_ind']], on='ban', how='left')\n",
    "df_train.rename(columns={'product_crosssell_ind': 'target'}, inplace=True)\n",
    "df_train.dropna(subset=['target'], inplace=True)\n",
    "df_train['target'] = df_train['target'].astype(int)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32473d2-a75d-48ff-afc1-f34af20e2cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b9b389-df11-402a-ab09-20bd55af3d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gcp_bqclient(project_id, use_local_credential=True):\n",
    "    token = os.popen('gcloud auth print-access-token').read()\n",
    "    token = re.sub(f'\\n$', '', token)\n",
    "    credentials = google.oauth2.credentials.Credentials(token)\n",
    "\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    if use_local_credential:\n",
    "        bq_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "    return bq_client\n",
    "\n",
    "client = get_gcp_bqclient(project_id)\n",
    "sql_test = ''' SELECT * FROM `{}.{}.bq_tos_cross_sell_targets_q4` '''.format(project_id, dataset_id)\n",
    "df_target_test = client.query(sql_test).to_dataframe()\n",
    "df_target_test = df_target_test.loc[\n",
    "    df_target_test['YEAR_MONTH'] == \"2022-Q4\"] #'-'.join(score_date_val_dash.split('-')[:2])]  # score_date_dash = '2022-09-30'\n",
    "\n",
    "#set up df_train and df_test (add 'target')\n",
    "df_target_test['ban'] = df_target_test['ban'].astype('int64')\n",
    "df_target_test = df_target_test.groupby('ban').tail(1)\n",
    "\n",
    "df_test = df_test.merge(df_target_test[['ban', 'product_crosssell_ind']], on='ban', how='left')\n",
    "df_test.rename(columns={'product_crosssell_ind': 'target'}, inplace=True)\n",
    "df_test.dropna(subset=['target'], inplace=True)\n",
    "df_test['target'] = df_test['target'].astype(int)\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62170f7-10b3-47f6-9610-7d758e68b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_test['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426e602c-d3dd-4748-9617-410bc68b193e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbace01-af78-4606-be60-24a54a9d73ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9160899b-d021-4fd8-a872-99da8fabb4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f18065-c141-461c-9a6a-ceb9e30cd595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b5220-bd60-499a-8007-223fbf0afc47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca08d2-cba3-4688-927c-3b0925b916b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502dee0c-28ed-42cb-b0ec-a915d94dcb3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031e2eac-09ae-4456-a0a1-ed0f41a27ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c634d001-0124-4325-8f3f-58838fdd1451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6f555e-86fa-416f-970c-bd980b464287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
