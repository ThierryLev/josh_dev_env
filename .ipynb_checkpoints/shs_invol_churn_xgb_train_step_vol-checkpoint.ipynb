{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0c603b-3f78-40d0-bc02-7dac3ea2a76c",
   "metadata": {},
   "source": [
    "### Import Libraries, declare variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1294f3f-ee1c-4c57-bbb1-635ef08b52d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import google\n",
    "from google.oauth2 import credentials\n",
    "from google.oauth2 import service_account\n",
    "from google.oauth2.service_account import Credentials\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# build model\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "SERVICE_TYPE = 'shs_invol_churn'\n",
    "DATASET_ID = 'shs_invol_churn'\n",
    "PROJECT_ID = 'divg-groovyhoon-pr-d2eab4' #mapping['PROJECT_ID']\n",
    "RESOURCE_BUCKET = 'divg-groovyhoon-pr-d2eab4-default' #mapping['resources_bucket']\n",
    "FILE_BUCKET = 'divg-groovyhoon-pr-d2eab4-default' #mapping['gcs_csv_bucket']\n",
    "REGION = 'northamerica-northeast1' #mapping['REGION']\n",
    "MODEL_ID = '9999'\n",
    "FOLDER_NAME = 'telus_postpaid_churn'.format(MODEL_ID)\n",
    "QUERIES_PATH = 'vertex_pipelines/' + FOLDER_NAME + '/queries/'\n",
    "TABLE_ID = 'shs_invol_churn_data_final'\n",
    "\n",
    "# scoringDate = date(2023, 9, 1)  # date.today() - relativedelta(days=2)- relativedelta(months=30)\n",
    "# valScoringDate = date(2023, 11, 1)  # scoringDate - relativedelta(days=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb30300f-ff71-417d-956f-6d3dcede6c29",
   "metadata": {},
   "source": [
    "### import bq to dataframe function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e098413-7211-4346-b1c9-eafd38ef076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import credentials\n",
    "\n",
    "def import_bq_to_dataframe(project_id, dataset_id, table_id, client): \n",
    "    \n",
    "    \"\"\"\n",
    "    Imports a specific table from BigQuery to a DataFrame. \n",
    "    \n",
    "    Args: \n",
    "        project_id: The name of the project_id where the table is located.\n",
    "        dataset_id: The name of the dataset_id where the table is located.\n",
    "        table_id: The name of the table_id you wish to import to DataFrame.\n",
    "        client: A BigQuery client instance. e.g. client = bigquery.Client(project=project_id).\n",
    "\n",
    "    Returns: \n",
    "        A DataFrame\n",
    "        \n",
    "    Example: \n",
    "        import_bq_to_dataframe('bi-stg-divg-speech-pr-9d940b', 'call_to_retention_dataset', 'bq_ctr_pipeline_dataset')\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    sql = f\"SELECT * FROM `{project_id}.{dataset_id}.{table_id}`\"\n",
    "    \n",
    "    df_return = client.query(sql).to_dataframe()\n",
    "\n",
    "    return df_return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a31e45-47f9-445e-aab4-1e2d8243e1f9",
   "metadata": {},
   "source": [
    "### define get_lift function, import df_train and df_test from gcs bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea3837b0-0180-4a8a-978d-b56402062efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df: (796251, 189)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "project_id = PROJECT_ID\n",
    "region = REGION\n",
    "resource_bucket = RESOURCE_BUCKET\n",
    "file_bucket = FILE_BUCKET\n",
    "service_type=SERVICE_TYPE\n",
    "project_id=PROJECT_ID\n",
    "dataset_id=DATASET_ID\n",
    "table_id = TABLE_ID\n",
    "\n",
    "def get_lift(prob, y_test, q):\n",
    "    result = pd.DataFrame(columns=['Prob', 'Churn'])\n",
    "    result['Prob'] = prob\n",
    "    result['Churn'] = y_test\n",
    "    # result['Decile'] = pd.qcut(1-result['Prob'], 10, labels = False)\n",
    "    result['Decile'] = pd.qcut(result['Prob'], q, labels=[i for i in range(q, 0, -1)])\n",
    "    add = pd.DataFrame(result.groupby('Decile')['Churn'].mean()).reset_index()\n",
    "    add.columns = ['Decile', 'avg_real_churn_rate']\n",
    "    result = result.merge(add, on='Decile', how='left')\n",
    "    result.sort_values('Decile', ascending=True, inplace=True)\n",
    "    lg = pd.DataFrame(result.groupby('Decile')['Prob'].mean()).reset_index()\n",
    "    lg.columns = ['Decile', 'avg_model_pred_churn_rate']\n",
    "    lg.sort_values('Decile', ascending=False, inplace=True)\n",
    "    lg['avg_churn_rate_total'] = result['Churn'].mean()\n",
    "    lg = lg.merge(add, on='Decile', how='left')\n",
    "    lg['lift'] = lg['avg_real_churn_rate'] / lg['avg_churn_rate_total']\n",
    "\n",
    "    return lg\n",
    "\n",
    "def get_gcp_bqclient(project_id, use_local_credential=True):\n",
    "    token = os.popen('gcloud auth print-access-token').read()\n",
    "    token = re.sub(f'\\n$', '', token)\n",
    "    credentials = google.oauth2.credentials.Credentials(token)\n",
    "\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    if use_local_credential:\n",
    "        bq_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "    return bq_client\n",
    "\n",
    "client = get_gcp_bqclient(project_id)\n",
    "\n",
    "df = import_bq_to_dataframe(project_id, dataset_id, table_id, client)\n",
    "\n",
    "print(f'df: {df.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94961cc0-7e92-44eb-9e1e-15d16d2024ed",
   "metadata": {},
   "source": [
    "### add targets to df_train and df_target \n",
    "\n",
    "- df_target_train is from `divg-josh-pr-d1cc3a.tos_crosssell.bq_tos_cross_sell_targets_q3` \n",
    "- df_target_test is from `divg-josh-pr-d1cc3a.tos_crosssell.bq_tos_cross_sell_targets_q4` \n",
    "- some parts of the code and sql queries need to be dynamically adjusted to be included in the deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc272d97-768b-401b-9100-923cc63cf1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496735, 189)\n",
      "(299516, 189)\n"
     ]
    }
   ],
   "source": [
    "# Define the start and end dates of the range\n",
    "train_start_date = date(2023, 1, 1)\n",
    "train_end_date = date(2023, 9, 30)\n",
    "\n",
    "test_start_date = date(2023, 10, 1)\n",
    "test_end_date = date(2024, 1, 1)\n",
    "\n",
    "# Filter the DataFrame\n",
    "df_train = df[(df['Base_Snapshot_Date'] >= train_start_date) & (df['Base_Snapshot_Date'] <= train_end_date)]\n",
    "print(df_train.shape)\n",
    "\n",
    "df_test = df[(df['Base_Snapshot_Date'] >= test_start_date) & (df['Base_Snapshot_Date'] <= test_end_date)]\n",
    "print(df_test.shape)\n",
    "\n",
    "#set up features (list)\n",
    "cols_1 = df_train.columns.values\n",
    "cols_2 = df_test.columns.values\n",
    "\n",
    "cols = set(cols_1).intersection(set(cols_2))\n",
    "\n",
    "features_to_exclude = ['CUST_ID', 'Bus_Billing_Account_Num', 'Bus_Prod_Instnc_Id', \n",
    "                       'Base_Snapshot_Date', 'Security_Origin', 'ACQUIRED_FROM', \n",
    "                       'Acquisition_Source', 'vol', 'invol', 'churn']\n",
    "\n",
    "features = [f for f in cols if f not in features_to_exclude]\n",
    "\n",
    "ban_train = df_train[['CUST_ID', 'Bus_Billing_Account_Num', 'Bus_Prod_Instnc_Id']]\n",
    "X_train = df_train[features]\n",
    "y_train = np.squeeze(df_train['invol'].values)\n",
    "\n",
    "ban_test = df_test[['CUST_ID', 'Bus_Billing_Account_Num', 'Bus_Prod_Instnc_Id']]\n",
    "X_test = df_test[features]\n",
    "y_test = np.squeeze(df_test['invol'].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a591fa94-0f6d-47a7-9bb5-53d4a39ca42b",
   "metadata": {},
   "source": [
    "### preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38820930-8f64-4d21-bd82-54aef8e6d7a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tot_disc_amt_2', 'census_subdivision_desc', 'HasT_Pre',\n",
      "       'Channel_Category', 'tot_inv_amt_1', 'HasWHP_K', 'ttv_chrg_amt_3',\n",
      "       'hsic_crdt_amt_2', 'bi_chnl_tag_cd', 'hsic_chrg_amt_2',\n",
      "       ...\n",
      "       'sing_disc_amt_l12m', 'sing_disc_amt_3', 'tot_net_amt_l12m', 'HasWHP_T',\n",
      "       'HasNOS', 'HasLWC', 'CHNL_ORG_TXT__Custom_SQL_Query_',\n",
      "       'Contracted__Account_', 'HasWHP', 'smhm_crdt_amt_1'],\n",
      "      dtype='object', length=179)\n"
     ]
    }
   ],
   "source": [
    "# Now we need to transform the features of the feature store.\n",
    "def encode_categorical_features(df):\n",
    "    # Get a list of all categorical columns\n",
    "    cat_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    # Encode each categorical column\n",
    "    for col in cat_columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        \n",
    "    return df\n",
    "    \n",
    "X_train = encode_categorical_features(X_train)\n",
    "X_test = encode_categorical_features(X_test)\n",
    "\n",
    "#set up features (list)\n",
    "cols_1 = X_train.columns.values\n",
    "cols_2 = X_test.columns.values\n",
    "\n",
    "cols = set(cols_1).intersection(set(cols_2))\n",
    "\n",
    "features = [f for f in cols if f not in features_to_exclude]\n",
    "\n",
    "X_train = X_train[features] \n",
    "X_test = X_test[features] \n",
    "\n",
    "print(X_train.columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfd29e3-d1b3-4cbe-983c-b0033ed8554a",
   "metadata": {},
   "source": [
    "### fit training data in xgboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe7616d7-5909-4cb8-8e74-821d3e92dee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb training done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build model and fit in training data\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=250,\n",
    "    max_depth=12,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print('xgb training done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0ea7ec-74db-4419-84bb-0d44545fec56",
   "metadata": {},
   "source": [
    "### make predictions on X_test set, assign deciles to the predicted values, and save in df_test_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b3c55fb-754b-4fa9-b0ac-cdcf45a3dc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1457/4227574850.py:25: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  add = pd.DataFrame(result.groupby('Decile')['Churn'].mean()).reset_index()\n",
      "/tmp/ipykernel_1457/4227574850.py:29: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  lg = pd.DataFrame(result.groupby('Decile')['Prob'].mean()).reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decile</th>\n",
       "      <th>avg_model_pred_churn_rate</th>\n",
       "      <th>avg_churn_rate_total</th>\n",
       "      <th>avg_real_churn_rate</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.111989</td>\n",
       "      <td>0.013909</td>\n",
       "      <td>0.125167</td>\n",
       "      <td>8.998920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.013909</td>\n",
       "      <td>0.009749</td>\n",
       "      <td>0.700926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>0.013909</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.194429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.013909</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.038407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.013909</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.016802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.013909</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.024004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.013909</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.004801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.013909</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.007201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.013909</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.007201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.013909</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.007201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Decile  avg_model_pred_churn_rate  avg_churn_rate_total  \\\n",
       "0      1                   0.111989              0.013909   \n",
       "1      2                   0.006156              0.013909   \n",
       "2      3                   0.002035              0.013909   \n",
       "3      4                   0.001024              0.013909   \n",
       "4      5                   0.000618              0.013909   \n",
       "5      6                   0.000398              0.013909   \n",
       "6      7                   0.000260              0.013909   \n",
       "7      8                   0.000163              0.013909   \n",
       "8      9                   0.000089              0.013909   \n",
       "9     10                   0.000036              0.013909   \n",
       "\n",
       "   avg_real_churn_rate      lift  \n",
       "0             0.125167  8.998920  \n",
       "1             0.009749  0.700926  \n",
       "2             0.002704  0.194429  \n",
       "3             0.000534  0.038407  \n",
       "4             0.000234  0.016802  \n",
       "5             0.000334  0.024004  \n",
       "6             0.000067  0.004801  \n",
       "7             0.000100  0.007201  \n",
       "8             0.000100  0.007201  \n",
       "9             0.000100  0.007201  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictions on X_test\n",
    "y_pred = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#join ban_test, X_test, y_test and y_pred and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_test = ban_test\n",
    "df_test_exp = df_ban_test.join(X_test) \n",
    "df_test_exp['y_test'] = y_test\n",
    "df_test_exp['y_pred_proba'] = y_pred\n",
    "df_test_exp['y_pred'] = (df_test_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_test_exp['decile'] = pd.qcut(df_test_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(y_pred, y_test, q)\n",
    "\n",
    "lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "487d5075-6c43-436e-9b7f-b15ee46d928e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenure_Month_Groups, 0.07723607867956161\n",
      "Tenure_Month_Groups__All_, 0.07379674166440964\n",
      "CREDIT_VALUE_CD__group_, 0.05787818878889084\n",
      "Commitment_Type, 0.04177093133330345\n",
      "smhm_chrg_amt_1, 0.029099594801664352\n",
      "Contract_Type, 0.02799258753657341\n",
      "price_plan, 0.01979736238718033\n",
      "smhm_chrg_amt_2, 0.019004415720701218\n",
      "tot_chrg_amt_1, 0.017116041854023933\n",
      "Security_Plan_Group, 0.017021914944052696\n",
      "Price_Plan_Txt__SHS_, 0.012706797569990158\n",
      "PRICE_PLAN_RATE_AMT__Custom_SQL_Query_, 0.012491551227867603\n",
      "other_chrg_amt_3, 0.012043689377605915\n",
      "smhm_chrg_amt_3, 0.011646443046629429\n",
      "smhm_net_amt_1, 0.011556265875697136\n",
      "tot_inv_amt_1, 0.011354784481227398\n",
      "tot_chrg_amt_2, 0.011181851848959923\n",
      "prov_cd, 0.011034419760107994\n",
      "Product_Profile, 0.010659968480467796\n",
      "tot_chrg_amt_3, 0.01018329057842493\n",
      "Province_Grp, 0.009880646131932735\n",
      "other_chrg_amt_1, 0.009363624267280102\n",
      "Security_Plan_Type, 0.009313363581895828\n",
      "hsic_disc_amt_3, 0.009199962019920349\n",
      "Tenure_Year_Group, 0.008927229791879654\n",
      "other_disc_amt_3, 0.008908083662390709\n",
      "tot_net_amt_l12m, 0.008783848024904728\n",
      "other_chrg_amt_2, 0.008564816787838936\n",
      "tot_net_amt_1, 0.008385430090129375\n",
      "Contracted__Account_, 0.008379289880394936\n",
      "tot_inv_amt_3, 0.007923563942313194\n",
      "smhm_net_amt_3, 0.007644218392670155\n",
      "tot_inv_amt_2, 0.007434655912220478\n",
      "HasHSIA, 0.0073971739038825035\n",
      "tot_net_amt_3, 0.00663641607388854\n",
      "tot_inv_amt_l12m, 0.006478260736912489\n",
      "smhm_net_amt_2, 0.006379575468599796\n",
      "Installation_Type, 0.006256203167140484\n",
      "DIY_Activated, 0.006103869527578354\n",
      "other_chrg_amt_l12m, 0.006100769154727459\n",
      "tot_chrg_amt_l12m, 0.0059878830797970295\n",
      "HSIA_Per_Cust, 0.005975105334073305\n",
      "tot_net_amt_2, 0.005861025769263506\n",
      "avg_income, 0.00584265124052763\n",
      "tot_tax_inv_amt_1, 0.0057471380569040775\n",
      "smhm_net_amt_l12m, 0.005715611390769482\n",
      "other_disc_amt_l12m, 0.0056752306409180164\n",
      "tot_disc_amt_3, 0.0055536204017698765\n",
      "smhm_disc_amt_3, 0.00546884024515748\n",
      "smhm_chrg_amt_l12m, 0.005344651639461517\n",
      "tot_disc_amt_1, 0.0053336299024522305\n",
      "PRICE_PLAN_TXT__Custom_SQL_Query_, 0.005241621285676956\n",
      "HS_CNT, 0.005150666926056147\n",
      "tot_tax_inv_amt_2, 0.005082177463918924\n",
      "tot_crdt_amt_3, 0.005050502251833677\n",
      "other_disc_amt_1, 0.005009850952774286\n",
      "smhm_crdt_amt_2, 0.004994502291083336\n",
      "HasTOS, 0.00497662415727973\n",
      "tot_tax_inv_amt_3, 0.004916093777865171\n",
      "tot_tax_inv_amt_l12m, 0.004859419073909521\n",
      "smhm_crdt_amt_3, 0.004783761687576771\n",
      "yr_mth_2, 0.004738722462207079\n",
      "smhm_disc_amt_1, 0.0046598417684435844\n",
      "smhm_disc_amt_l12m, 0.004650582559406757\n",
      "tot_crdt_amt_1, 0.004610829520970583\n",
      "tot_disc_amt_l12m, 0.004607388749718666\n",
      "yr_mth_1, 0.004583318717777729\n",
      "tot_crdt_amt_l12m, 0.00455286493524909\n",
      "other_net_amt_2, 0.00447944225743413\n",
      "Contract_Expiring_Soon, 0.004462930373847485\n",
      "med_income, 0.004442252684384584\n",
      "smhm_crdt_amt_l12m, 0.004440451506525278\n",
      "Customer_Category, 0.004439566284418106\n",
      "bi_chnl_tag_cd, 0.004428820218890905\n",
      "Channel__Best_, 0.004385992884635925\n",
      "HasMobility, 0.0042701344937086105\n",
      "HasT_Post, 0.004242741037160158\n",
      "Channel, 0.004203304648399353\n",
      "Video_, 0.00419383030384779\n",
      "tot_disc_amt_2, 0.0041547780856490135\n",
      "census_subdivision_typ, 0.00413886271417141\n",
      "other_crdt_amt_2, 0.004135994706302881\n",
      "CHNL_ORG_TXT__Custom_SQL_Query_, 0.0041091060265898705\n",
      "other_net_amt_3, 0.004095396026968956\n",
      "other_net_amt_1, 0.004037957172840834\n",
      "other_crdt_amt_3, 0.004036398604512215\n",
      "other_net_amt_l12m, 0.003987112082540989\n",
      "Channel_Category, 0.003975473344326019\n",
      "census_subdivision_desc, 0.003891421016305685\n",
      "TOS_FLAG, 0.0038845976814627647\n",
      "social_grp_cd, 0.0038485818076878786\n",
      "smhm_crdt_amt_1, 0.0038097966462373734\n",
      "POSTAL_CD__Custom_SQL_Query_, 0.0037920724134892225\n",
      "Epp_Discount_Months, 0.0037515268195420504\n",
      "community_nm, 0.003670973004773259\n",
      "HasKoodo, 0.0036561486776918173\n",
      "Activation_Ts__Month___Year_, 0.0036438768729567528\n",
      "Community, 0.0035887022968381643\n",
      "social_grp_nm, 0.0035614718217402697\n",
      "other_disc_amt_2, 0.003542726393789053\n",
      "prizm_name, 0.0035389300901442766\n",
      "lifestage_nm, 0.0035002201329916716\n",
      "hsic_chrg_amt_3, 0.003435941180214286\n",
      "lifestage_cd, 0.00323891406878829\n",
      "yr_mth_3, 0.0031895977444946766\n",
      "other_crdt_amt_l12m, 0.0031232379842549562\n",
      "hsic_disc_amt_2, 0.0030496090184897184\n",
      "smhm_disc_amt_2, 0.0030275641474872828\n",
      "HasTV, 0.002901864005252719\n",
      "hsic_disc_amt_l12m, 0.0027883294969797134\n",
      "HasPublic, 0.002769224112853408\n",
      "other_crdt_amt_1, 0.0026330016553401947\n",
      "tot_crdt_amt_2, 0.0025824520271271467\n",
      "hsic_net_amt_2, 0.002543861512094736\n",
      "hsic_chrg_amt_1, 0.002492043189704418\n",
      "KBRAND_BAN_CT, 0.002486241515725851\n",
      "hsic_chrg_amt_l12m, 0.0022069544065743685\n",
      "hsic_net_amt_l12m, 0.0017229251097887754\n",
      "hsic_crdt_amt_l12m, 0.001581329619511962\n",
      "hsic_crdt_amt_2, 0.0014464923879131675\n",
      "ttv_crdt_amt_2, 0.0014407499693334103\n",
      "ttv_net_amt_1, 0.0014405017718672752\n",
      "ttv_crdt_amt_1, 0.0014352030120790005\n",
      "ttv_crdt_amt_l12m, 0.0013866190565750003\n",
      "sing_chrg_amt_l12m, 0.0012503499165177345\n",
      "ttv_chrg_amt_1, 0.001228221575729549\n",
      "sing_net_amt_1, 0.0012157098390161991\n",
      "sing_chrg_amt_1, 0.0011896813521161675\n",
      "sing_chrg_amt_2, 0.0011556888930499554\n",
      "hsic_chrg_amt_2, 0.0010711572831496596\n",
      "ttv_chrg_amt_l12m, 0.0010280075948685408\n",
      "ttv_chrg_amt_2, 0.0009713628678582609\n",
      "TV_Count, 0.0009093626867979765\n",
      "ttv_disc_amt_1, 0.0008036207291297615\n",
      "ttv_chrg_amt_3, 0.000717757036909461\n",
      "hsic_net_amt_1, 0.0005867909057997167\n",
      "HasWHP, 0.0\n",
      "sing_crdt_amt_l12m, 0.0\n",
      "sing_disc_amt_3, 0.0\n",
      "sing_disc_amt_l12m, 0.0\n",
      "ttv_disc_amt_l12m, 0.0\n",
      "HasWHP_T, 0.0\n",
      "HasNOS, 0.0\n",
      "sing_crdt_amt_3, 0.0\n",
      "HasLWC, 0.0\n",
      "Cultural_Segment, 0.0\n",
      "HasWHP_K, 0.0\n",
      "ttv_net_amt_2, 0.0\n",
      "ttv_disc_amt_3, 0.0\n",
      "HasT_Pre, 0.0\n",
      "hsic_net_amt_3, 0.0\n",
      "hsic_crdt_amt_1, 0.0\n",
      "HSLTE_TOTAL, 0.0\n",
      "HasK_Pre, 0.0\n",
      "HasSMHM, 0.0\n",
      "Delivery_Technology, 0.0\n",
      "HasHP, 0.0\n",
      "HasFibreTag, 0.0\n",
      "sing_crdt_amt_2, 0.0\n",
      "sing_disc_amt_2, 0.0\n",
      "ttv_net_amt_3, 0.0\n",
      "Nho_Discount_Months, 0.0\n",
      "ttv_crdt_amt_3, 0.0\n",
      "hsic_disc_amt_1, 0.0\n",
      "sing_net_amt_2, 0.0\n",
      "IPTV_CNT, 0.0\n",
      "HasIPTV, 0.0\n",
      "HasWHSIA, 0.0\n",
      "sing_disc_amt_1, 0.0\n",
      "HasPik, 0.0\n",
      "ttv_disc_amt_2, 0.0\n",
      "sing_chrg_amt_3, 0.0\n",
      "Delivery_Technology__Account_, 0.0\n",
      "hsic_crdt_amt_3, 0.0\n",
      "ttv_net_amt_l12m, 0.0\n",
      "sing_crdt_amt_1, 0.0\n",
      "HP_CNT, 0.0\n",
      "sing_net_amt_l12m, 0.0\n",
      "sing_net_amt_3, 0.0\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances from xgboost model\n",
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "# Get the index of importances from greatest importance to least\n",
    "sorted_index = np.argsort(importances)[::-1]\n",
    "x = range(len(importances))\n",
    "\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create tick labels \n",
    "labels = np.array(feature_names)[sorted_index]\n",
    "\n",
    "for idx in sorted_index: \n",
    "    print(f'{feature_names[idx]}, {importances[idx]}', end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8864bda6-bda0-4032-9704-f513da84e132",
   "metadata": {},
   "source": [
    "### get feature importances from xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43768ef0-d6cc-40e4-a3a9-dbcdbceedb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from xgboost model\n",
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "# Get the index of importances from greatest importance to least\n",
    "sorted_index = np.argsort(importances)[::-1]\n",
    "x = range(len(importances))\n",
    "\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create tick labels \n",
    "labels = np.array(feature_names)[sorted_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82e9b69c-0ab4-4595-b2f2-3b0a6387d3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tenure_Month_Groups', 'Tenure_Month_Groups__All_',\n",
       "       'CREDIT_VALUE_CD__group_', 'Commitment_Type', 'smhm_chrg_amt_1',\n",
       "       'Contract_Type', 'price_plan', 'smhm_chrg_amt_2', 'tot_chrg_amt_1',\n",
       "       'Security_Plan_Group', 'Price_Plan_Txt__SHS_',\n",
       "       'PRICE_PLAN_RATE_AMT__Custom_SQL_Query_', 'other_chrg_amt_3',\n",
       "       'smhm_chrg_amt_3', 'smhm_net_amt_1', 'tot_inv_amt_1',\n",
       "       'tot_chrg_amt_2', 'prov_cd', 'Product_Profile', 'tot_chrg_amt_3',\n",
       "       'Province_Grp', 'other_chrg_amt_1', 'Security_Plan_Type',\n",
       "       'hsic_disc_amt_3', 'Tenure_Year_Group', 'other_disc_amt_3',\n",
       "       'tot_net_amt_l12m', 'other_chrg_amt_2', 'tot_net_amt_1',\n",
       "       'Contracted__Account_', 'tot_inv_amt_3', 'smhm_net_amt_3',\n",
       "       'tot_inv_amt_2', 'HasHSIA', 'tot_net_amt_3', 'tot_inv_amt_l12m',\n",
       "       'smhm_net_amt_2', 'Installation_Type', 'DIY_Activated',\n",
       "       'other_chrg_amt_l12m', 'tot_chrg_amt_l12m', 'HSIA_Per_Cust',\n",
       "       'tot_net_amt_2', 'avg_income', 'tot_tax_inv_amt_1',\n",
       "       'smhm_net_amt_l12m', 'other_disc_amt_l12m', 'tot_disc_amt_3',\n",
       "       'smhm_disc_amt_3', 'smhm_chrg_amt_l12m', 'tot_disc_amt_1',\n",
       "       'PRICE_PLAN_TXT__Custom_SQL_Query_', 'HS_CNT', 'tot_tax_inv_amt_2',\n",
       "       'tot_crdt_amt_3', 'other_disc_amt_1', 'smhm_crdt_amt_2', 'HasTOS',\n",
       "       'tot_tax_inv_amt_3', 'tot_tax_inv_amt_l12m', 'smhm_crdt_amt_3',\n",
       "       'yr_mth_2', 'smhm_disc_amt_1', 'smhm_disc_amt_l12m',\n",
       "       'tot_crdt_amt_1', 'tot_disc_amt_l12m', 'yr_mth_1',\n",
       "       'tot_crdt_amt_l12m', 'other_net_amt_2', 'Contract_Expiring_Soon',\n",
       "       'med_income', 'smhm_crdt_amt_l12m', 'Customer_Category',\n",
       "       'bi_chnl_tag_cd', 'Channel__Best_', 'HasMobility', 'HasT_Post',\n",
       "       'Channel', 'Video_', 'tot_disc_amt_2', 'census_subdivision_typ',\n",
       "       'other_crdt_amt_2', 'CHNL_ORG_TXT__Custom_SQL_Query_',\n",
       "       'other_net_amt_3', 'other_net_amt_1', 'other_crdt_amt_3',\n",
       "       'other_net_amt_l12m', 'Channel_Category',\n",
       "       'census_subdivision_desc', 'TOS_FLAG', 'social_grp_cd',\n",
       "       'smhm_crdt_amt_1', 'POSTAL_CD__Custom_SQL_Query_',\n",
       "       'Epp_Discount_Months', 'community_nm', 'HasKoodo',\n",
       "       'Activation_Ts__Month___Year_', 'Community', 'social_grp_nm',\n",
       "       'other_disc_amt_2', 'prizm_name', 'lifestage_nm',\n",
       "       'hsic_chrg_amt_3', 'lifestage_cd', 'yr_mth_3',\n",
       "       'other_crdt_amt_l12m', 'hsic_disc_amt_2', 'smhm_disc_amt_2',\n",
       "       'HasTV', 'hsic_disc_amt_l12m', 'HasPublic', 'other_crdt_amt_1',\n",
       "       'tot_crdt_amt_2', 'hsic_net_amt_2', 'hsic_chrg_amt_1',\n",
       "       'KBRAND_BAN_CT', 'hsic_chrg_amt_l12m', 'hsic_net_amt_l12m',\n",
       "       'hsic_crdt_amt_l12m', 'hsic_crdt_amt_2', 'ttv_crdt_amt_2',\n",
       "       'ttv_net_amt_1', 'ttv_crdt_amt_1', 'ttv_crdt_amt_l12m',\n",
       "       'sing_chrg_amt_l12m', 'ttv_chrg_amt_1', 'sing_net_amt_1',\n",
       "       'sing_chrg_amt_1', 'sing_chrg_amt_2', 'hsic_chrg_amt_2',\n",
       "       'ttv_chrg_amt_l12m', 'ttv_chrg_amt_2', 'TV_Count',\n",
       "       'ttv_disc_amt_1', 'ttv_chrg_amt_3', 'hsic_net_amt_1', 'HasWHP',\n",
       "       'sing_crdt_amt_l12m', 'sing_disc_amt_3', 'sing_disc_amt_l12m',\n",
       "       'ttv_disc_amt_l12m', 'HasWHP_T', 'HasNOS', 'sing_crdt_amt_3',\n",
       "       'HasLWC', 'Cultural_Segment', 'HasWHP_K', 'ttv_net_amt_2',\n",
       "       'ttv_disc_amt_3', 'HasT_Pre', 'hsic_net_amt_3', 'hsic_crdt_amt_1',\n",
       "       'HSLTE_TOTAL', 'HasK_Pre', 'HasSMHM', 'Delivery_Technology',\n",
       "       'HasHP', 'HasFibreTag', 'sing_crdt_amt_2', 'sing_disc_amt_2',\n",
       "       'ttv_net_amt_3', 'Nho_Discount_Months', 'ttv_crdt_amt_3',\n",
       "       'hsic_disc_amt_1', 'sing_net_amt_2', 'IPTV_CNT', 'HasIPTV',\n",
       "       'HasWHSIA', 'sing_disc_amt_1', 'HasPik', 'ttv_disc_amt_2',\n",
       "       'sing_chrg_amt_3', 'Delivery_Technology__Account_',\n",
       "       'hsic_crdt_amt_3', 'ttv_net_amt_l12m', 'sing_crdt_amt_1', 'HP_CNT',\n",
       "       'sing_net_amt_l12m', 'sing_net_amt_3'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38edf5cf-4f19-41c3-ab79-3b560cdd1f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00415478, 0.00389142, 0.        , 0.00397547, 0.01135478,\n",
       "       0.        , 0.00071776, 0.00144649, 0.00442882, 0.00107116,\n",
       "       0.        , 0.00444045, 0.00637958, 0.00138662, 0.01065997,\n",
       "       0.04177093, 0.00080362, 0.0127068 , 0.00379207, 0.00290186,\n",
       "       0.        , 0.00444225, 0.00323891, 0.00647826, 0.0040954 ,\n",
       "       0.00936362, 0.00890808, 0.00413599, 0.        , 0.        ,\n",
       "       0.00491609, 0.00988065, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.0049945 , 0.00508218, 0.        , 0.        ,\n",
       "       0.00172293, 0.00398711, 0.0035887 , 0.00446293, 0.0038846 ,\n",
       "       0.00473872, 0.00546884, 0.        , 0.        , 0.00478376,\n",
       "       0.        , 0.01900442, 0.0040364 , 0.00524162, 0.01018329,\n",
       "       0.00058679, 0.00102801, 0.01103442, 0.00574714, 0.00856482,\n",
       "       0.        , 0.00500985, 0.00586103, 0.00115569, 0.07723608,\n",
       "       0.05787819, 0.00455286, 0.        , 0.00375153, 0.00458332,\n",
       "       0.        , 0.00663642, 0.00533363, 0.01118185, 0.00220695,\n",
       "       0.00443957, 0.00125035, 0.00931336, 0.00764422, 0.00343594,\n",
       "       0.        , 0.00384858, 0.00584265, 0.        , 0.0014405 ,\n",
       "       0.00304961, 0.00792356, 0.        , 0.        , 0.01711604,\n",
       "       0.01702191, 0.00465058, 0.00090936, 0.00739717, 0.00461083,\n",
       "       0.00610077, 0.00302756, 0.00364388, 0.0031896 , 0.00571561,\n",
       "       0.01249155, 0.01979736, 0.        , 0.00353893, 0.        ,\n",
       "       0.00497662, 0.00413886, 0.00276922, 0.00534465, 0.        ,\n",
       "       0.00365615, 0.00254386, 0.00567523, 0.        , 0.00097136,\n",
       "       0.0042033 , 0.00485942, 0.00597511, 0.00144075, 0.0050505 ,\n",
       "       0.02799259, 0.        , 0.00158133, 0.00460739, 0.01204369,\n",
       "       0.00258245, 0.00555362, 0.0062562 , 0.002633  , 0.00403796,\n",
       "       0.00278833, 0.00838543, 0.00919996, 0.07379674, 0.        ,\n",
       "       0.        , 0.00356147, 0.        , 0.00424274, 0.        ,\n",
       "       0.00465984, 0.00598788, 0.        , 0.        , 0.02909959,\n",
       "       0.01164644, 0.00248624, 0.00249204, 0.00354273, 0.00743466,\n",
       "       0.00438599, 0.00312324, 0.0014352 , 0.        , 0.00367097,\n",
       "       0.        , 0.00515067, 0.        , 0.        , 0.00118968,\n",
       "       0.00121571, 0.00122822, 0.00892723, 0.01155627, 0.00447944,\n",
       "       0.00610387, 0.00419383, 0.00427013, 0.00350022, 0.        ,\n",
       "       0.        , 0.00878385, 0.        , 0.        , 0.        ,\n",
       "       0.00410911, 0.00837929, 0.        , 0.0038098 ], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9209e72-72ba-4c08-a7c6-c8317836fcd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 64, 133,  65,  15, 144, 120, 101,  51,  89,  90,  17, 100, 124,\n",
       "       145, 163,   4,  73,  57,  14,  54,  31,  25,  77, 132, 162,  26,\n",
       "       171,  59, 131, 176,  86,  78, 149,  93,  71,  23,  12, 127, 165,\n",
       "        95, 141, 117,  62,  82,  58,  99, 112, 126,  46, 108,  72,  53,\n",
       "       156,  37, 119,  61,  36, 105,  30, 116,  49,  45, 140,  91,  94,\n",
       "       123,  69,  66, 164,  43,  21,  11,  75,   8, 150, 167, 138, 115,\n",
       "       166,   0, 106,  27, 175,  24, 129,  52,  41,   3,   1,  44,  81,\n",
       "       178,  18,  68, 154, 110,  97,  42, 136, 148, 103, 168,  79,  22,\n",
       "        98, 151,  85,  96,  19, 130, 107, 128, 125, 111, 147, 146,  74,\n",
       "        40, 122,   7, 118,  84, 152,  13,  76, 161, 160, 159,  63,   9,\n",
       "        56, 114,  92,  16,   6,  55, 177,  20, 170, 169, 139, 172, 173,\n",
       "        10, 174,  67,   5, 104, 102,   2,  70,  88,  28, 158,  87, 142,\n",
       "       143, 113, 137,  50,  48,  47,  80,  60,  83, 135, 134,  39,  38,\n",
       "       153, 121,  35,  34,  33,  32, 155, 157,  29, 109])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8819c0-4886-4aed-9fab-ebd0bc19f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f8515b-07cd-4c76-9d79-944145ef3de1",
   "metadata": {},
   "source": [
    "### Load results to BQ - WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514b9b52-17c6-4c7f-8a36-9afdfc17f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORE_TABLE_ID = 'bq_telus_12_months_churn_scores'\n",
    "\n",
    "project_id = PROJECT_ID \n",
    "dataset_id = DATASET_ID\n",
    "score_table_id = SCORE_TABLE_ID\n",
    "\n",
    "# get full score to cave into bucket\n",
    "pred_prob = xgb_model.predict_proba(X_val, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "result = pd.DataFrame(columns=['ban', 'subscriber_no', 'score_date', 'y_true', 'y_pred'])\n",
    "\n",
    "result['ban'] = list(ban_val['ban'])\n",
    "result['ban'] = result['ban'].astype('str')\n",
    "\n",
    "result['subscriber_no'] = list(ban_val['ban'])\n",
    "result['subscriber_no'] = result['subscriber_no'].astype('str')\n",
    "\n",
    "result['score_date'] = \"2023-11-04\"\n",
    "\n",
    "result['y_true'] = list(y_val)\n",
    "result['y_true'] = result['y_true'].fillna(0.0).astype('float64')\n",
    "\n",
    "result['y_pred'] = list(pred_prob)\n",
    "result['y_pred'] = result['y_pred'].fillna(0.0).astype('float64')\n",
    "\n",
    "############# updated up to here ############\n",
    "\n",
    "result.to_csv('gs://{}/{}/ucar/{}_prediction_v2.csv'.format(file_bucket, service_type, service_type), index=False)\n",
    "\n",
    "# define dtype_bq_mapping\n",
    "dtype_bq_mapping = {np.dtype('int64'): 'INTEGER', \n",
    "np.dtype('float64'):  'FLOAT', \n",
    "np.dtype('float32'):  'FLOAT', \n",
    "np.dtype('object'):  'STRING', \n",
    "np.dtype('bool'):  'BOOLEAN', \n",
    "np.dtype('datetime64[ns]'):  'DATE', \n",
    "pd.Int64Dtype(): 'INTEGER'} \n",
    "\n",
    "# export df_final to bigquery \n",
    "schema_list = [] \n",
    "for column in result.columns: \n",
    "    schema_list.append(bigquery.SchemaField(column, dtype_bq_mapping[result.dtypes[column]], mode='NULLABLE')) \n",
    "print(schema_list) \n",
    "\n",
    "dest_table = f'{project_id}.{dataset_id}.{score_table_id}'\n",
    "\n",
    "# Sending to bigquery \n",
    "client = get_gcp_bqclient(project_id)\n",
    "job_config = bigquery.LoadJobConfig(schema=schema_list, write_disposition='WRITE_TRUNCATE') \n",
    "job = client.load_table_from_dataframe(result, dest_table, job_config=job_config) \n",
    "job.result() \n",
    "\n",
    "table = client.get_table(dest_table) # Make an API request \n",
    "print(\"Loaded {} rows and {} columns to {}\".format(table.num_rows, len(table.schema), table_id)) \n",
    "\n",
    "time.sleep(60)\n",
    "\n",
    "# table_ref = f'{project_id}.{dataset_id}.{score_table}'\n",
    "# client = bigquery.Client(project=project_id)\n",
    "# table = client.get_table(table_ref)\n",
    "# schema = table.schema\n",
    "\n",
    "# ll = []\n",
    "# for item in schema:\n",
    "#     col = item.name\n",
    "#     d_type = item.field_type\n",
    "#     if 'float' in str(d_type).lower():\n",
    "#         d_type = 'FLOAT64'\n",
    "#     ll.append((col, d_type))\n",
    "\n",
    "#     if 'integer' in str(d_type).lower():\n",
    "#         result[col] = result[col].fillna(0).astype(int)\n",
    "#     if 'float' in str(d_type).lower():\n",
    "#         result[col] = result[col].fillna(0.0).astype(float)\n",
    "#     if 'string' in str(d_type).lower():\n",
    "#         result[col] = result[col].fillna('').astype(str)\n",
    "\n",
    "# table_ref = '{}.{}.{}'.format(project_id, dataset_id, temp_table)\n",
    "# client = bigquery.Client(project=project_id)\n",
    "# if if_tbl_exists(client, table_ref):\n",
    "#     client.delete_table(table_ref)\n",
    "\n",
    "# client.create_table(table_ref)\n",
    "# config = bigquery.LoadJobConfig(schema=schema)\n",
    "# config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "# bq_table_instance = client.load_table_from_dataframe(result, table_ref, job_config=config)\n",
    "# time.sleep(5)\n",
    "\n",
    "# drop_sql = f\"\"\"delete from `{project_id}.{dataset_id}.{score_table}` where score_date = '{score_date_dash}'\"\"\"  # .format(project_id, dataset_id, score_date_dash)\n",
    "# client.query(drop_sql)\n",
    "# #\n",
    "# load_sql = f\"\"\"insert into `{project_id}.{dataset_id}.{score_table}`\n",
    "#               select * from `{project_id}.{dataset_id}.{temp_table}`\"\"\"\n",
    "# client.query(load_sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bf0cd1-afbc-42e6-9a2f-fd8b727c2cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce20d37b-0e62-4c81-b446-a88539baf2d9",
   "metadata": {},
   "source": [
    "### save the model in gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e0caa-94a8-497c-a395-15a1ac041f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model in GCS\n",
    "from datetime import datetime\n",
    "models_dict = {}\n",
    "create_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "models_dict['create_time'] = create_time\n",
    "models_dict['model'] = xgb_model\n",
    "models_dict['features'] = features\n",
    "\n",
    "with open('model_dict.pkl', 'wb') as handle:\n",
    "    pickle.dump(models_dict, handle)\n",
    "handle.close()\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(file_bucket)\n",
    "\n",
    "MODEL_PATH = '{}_xgb_models/'.format(service_type)\n",
    "blob = bucket.blob(MODEL_PATH)\n",
    "if not blob.exists(storage_client):\n",
    "    blob.upload_from_string('')\n",
    "\n",
    "model_name_onbkt = '{}{}_models_xgb_{}'.format(MODEL_PATH, service_type, models_dict['create_time'])\n",
    "blob = bucket.blob(model_name_onbkt)\n",
    "blob.upload_from_filename('model_dict.pkl')\n",
    "\n",
    "print(f\"....model loaded to GCS done at {str(create_time)}\")\n",
    "\n",
    "time.sleep(300)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c02b2b6-b059-4dde-9393-ad457eebf60e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d9d01-f009-45c6-90fe-95a61cc169cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb40188a-3865-4993-be01-fb27f7d07dd6",
   "metadata": {},
   "source": [
    "### load the latest saved xgb_model to the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f240186-29e9-4d12-8c11-bb468cae8067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_PATH = '{}_xgb_models/'.format(service_type)\n",
    "# df_score = pd.read_csv('gs://{}/{}_score.csv.gz'.format(file_bucket, service_type), compression='gzip')\n",
    "# df_score.dropna(subset=['ban'], inplace=True)\n",
    "# df_score.reset_index(drop=True, inplace=True)\n",
    "# print('......scoring data loaded:{}'.format(df_score.shape))\n",
    "# time.sleep(10)\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "MODEL_PATH = '{}_xgb_models/'.format(service_type)\n",
    "\n",
    "def load_model(file_bucket: str, service_type: str): \n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(file_bucket)\n",
    "    blobs = storage_client.list_blobs(file_bucket, prefix='{}{}_models_xgb_'.format(MODEL_PATH, service_type))\n",
    "\n",
    "    model_lists = []\n",
    "    for blob in blobs:\n",
    "        model_lists.append(blob.name)\n",
    "\n",
    "    blob = bucket.blob(model_lists[-1])\n",
    "    blob_in = blob.download_as_string()\n",
    "    model_dict = pickle.loads(blob_in)\n",
    "    xgb_model = model_dict['model']\n",
    "    features = model_dict['features']\n",
    "    print('...... model loaded')\n",
    "    time.sleep(10)\n",
    "    \n",
    "    return xgb_model, features\n",
    "\n",
    "xgb_model, features = load_model(file_bucket = FILE_BUCKET, service_type = SERVICE_TYPE) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625bbaf0-6a67-4151-8504-a187037aa4f8",
   "metadata": {},
   "source": [
    "### backup codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ced94be-d4ec-4eb5-8aed-8199f09bdbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gcp_bqclient(project_id, use_local_credential=True):\n",
    "    token = os.popen('gcloud auth print-access-token').read()\n",
    "    token = re.sub(f'\\n$', '', token)\n",
    "    credentials = google.oauth2.credentials.Credentials(token)\n",
    "\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    if use_local_credential:\n",
    "        bq_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "    return bq_client\n",
    "\n",
    "client = get_gcp_bqclient(project_id)\n",
    "\n",
    "#instantiate df_target_train and df_target_test\n",
    "sql_train = ''' SELECT * FROM `{}.{}.bq_tos_cross_sell_targets_q3` '''.format(project_id, dataset_id)\n",
    "df_target_train = client.query(sql_train).to_dataframe()\n",
    "df_target_train = df_target_train.loc[\n",
    "    df_target_train['YEAR_MONTH'] == \"2022-Q3\"] #'-'.join(score_date_dash.split('-')[:2])]  # score_date_dash = '2022-08-31'\n",
    "\n",
    "#set up df_train and df_test (add 'target')\n",
    "df_target_train['ban'] = df_target_train['ban'].astype('int64')\n",
    "df_target_train = df_target_train.groupby('ban').tail(1)\n",
    "\n",
    "df_train = df_train.merge(df_target_train[['ban', 'product_crosssell_ind']], on='ban', how='left')\n",
    "df_train.rename(columns={'product_crosssell_ind': 'target'}, inplace=True)\n",
    "df_train.dropna(subset=['target'], inplace=True)\n",
    "df_train['target'] = df_train['target'].astype(int)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32473d2-a75d-48ff-afc1-f34af20e2cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b9b389-df11-402a-ab09-20bd55af3d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gcp_bqclient(project_id, use_local_credential=True):\n",
    "    token = os.popen('gcloud auth print-access-token').read()\n",
    "    token = re.sub(f'\\n$', '', token)\n",
    "    credentials = google.oauth2.credentials.Credentials(token)\n",
    "\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    if use_local_credential:\n",
    "        bq_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "    return bq_client\n",
    "\n",
    "client = get_gcp_bqclient(project_id)\n",
    "sql_test = ''' SELECT * FROM `{}.{}.bq_tos_cross_sell_targets_q4` '''.format(project_id, dataset_id)\n",
    "df_target_test = client.query(sql_test).to_dataframe()\n",
    "df_target_test = df_target_test.loc[\n",
    "    df_target_test['YEAR_MONTH'] == \"2022-Q4\"] #'-'.join(score_date_val_dash.split('-')[:2])]  # score_date_dash = '2022-09-30'\n",
    "\n",
    "#set up df_train and df_test (add 'target')\n",
    "df_target_test['ban'] = df_target_test['ban'].astype('int64')\n",
    "df_target_test = df_target_test.groupby('ban').tail(1)\n",
    "\n",
    "df_test = df_test.merge(df_target_test[['ban', 'product_crosssell_ind']], on='ban', how='left')\n",
    "df_test.rename(columns={'product_crosssell_ind': 'target'}, inplace=True)\n",
    "df_test.dropna(subset=['target'], inplace=True)\n",
    "df_test['target'] = df_test['target'].astype(int)\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62170f7-10b3-47f6-9610-7d758e68b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_test['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426e602c-d3dd-4748-9617-410bc68b193e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
