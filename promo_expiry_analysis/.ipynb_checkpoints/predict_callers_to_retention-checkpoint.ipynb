{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3162205-0a6b-4989-a465-446ae45281ef",
   "metadata": {},
   "source": [
    "## Predict callers to retention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4501997e-cde5-4158-a5f6-e599b21581ec",
   "metadata": {},
   "source": [
    "### read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce90fd-e2b9-47db-96a3-2afa56f7e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import google\n",
    "from google.oauth2 import credentials\n",
    "from google.oauth2 import service_account\n",
    "from google.oauth2.service_account import Credentials\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# build model\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "file_bucket = 'divg-josh-pr-d1cc3a-default' \n",
    "folder_name = 'promo_expiry_analysis'\n",
    "\n",
    "df = pd.read_csv('gs://{}/{}/data_final.csv'.format(file_bucket, folder_name))\n",
    "df_score = pd.read_csv('gs://{}/{}/data_score.csv'.format(file_bucket, folder_name))\n",
    "\n",
    "cols_1 = df.columns.values\n",
    "cols_2 = df_score.columns.values\n",
    "cols = set(cols_1).intersection(set(cols_2))\n",
    "\n",
    "cols_to_preserve = [f for f in cols if f not in ['target']]\n",
    "cols_to_preserve_df = [f for f in cols] \n",
    "cols_to_preserve_df.append('target')\n",
    "\n",
    "df = df[cols_to_preserve_df]\n",
    "df_score = df_score[cols_to_preserve]\n",
    "\n",
    "df_score.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cd0d99-1047-4c61-89c7-075196abc722",
   "metadata": {},
   "source": [
    "### preprocess\n",
    "\n",
    "- Tenure Group: cat\n",
    "- PROV: cat\n",
    "- Pcount: cat\n",
    "- Price Plan Grouping: cat\n",
    "- Technology Group: cat\n",
    "- demographics: cat\n",
    "- CampaignFlag: cat\n",
    "- price_sensitivity: cat\n",
    "- TOTALCalls: remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ee691c-22ef-4a44-9ac9-c05223c13d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6150f7e4-ac8a-4351-a8fd-5989dfab4249",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ded4cc-2b4b-4c0c-8a94-abb27104c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_to_dummy = ['Tenure Group', 'PROV', 'Pcount', 'Price Plan Grouping', 'Technology Group', 'demographics', 'CampaignFlag', 'price_sensitivity']\n",
    "cols_to_dummy = ['Tenure Group', 'PROV', 'Pcount', 'Price Plan Grouping', 'Technology Group', 'demographics', 'price_sensitivity']\n",
    "\n",
    "for col in cols_to_dummy: \n",
    "\n",
    "    # Create dummy variables for the Country column\n",
    "    df = pd.get_dummies(df, columns=[col], drop_first=True, prefix=None, dtype=\"int64\")\n",
    "    df_score = pd.get_dummies(df_score, columns=[col], drop_first=True, prefix=None, dtype=\"int64\")\n",
    "\n",
    "# training & validation set\n",
    "# reorder the df columns so that 'target' comes last\n",
    "df_processed = df[[c for c in df if c not in ['target']] \n",
    "       + ['target']]\n",
    "\n",
    "df_processed.columns = df_processed.columns.str.replace('<', 'less_than_')\n",
    "df_processed.columns = df_processed.columns.str.replace(' ', '_')\n",
    "\n",
    "# scoring set\n",
    "# reorder the df columns so that 'target' comes last\n",
    "df_score_processed = df_score[[c for c in df_score]]\n",
    "\n",
    "df_score_processed.columns = df_score_processed.columns.str.replace('<', 'less_than_')\n",
    "df_score_processed.columns = df_score_processed.columns.str.replace(' ', '_')\n",
    "\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd51f21-175f-489f-ae5f-aa08d70577f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5f25bf-ea3b-453c-a7df-d9920c396e38",
   "metadata": {},
   "source": [
    "### register lift function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b3e8cb-235b-4ceb-9edc-a39e58364707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lift(prob, y_test, q):\n",
    "    result = pd.DataFrame(columns=['Prob', 'CallToRetention'])\n",
    "    result['Prob'] = prob\n",
    "    result['CallToRetention'] = y_test\n",
    "    result['Decile'] = pd.qcut(result['Prob'], q, labels=[i for i in range(q, 0, -1)])\n",
    "    add = pd.DataFrame(result.groupby('Decile')['CallToRetention'].mean()).reset_index()\n",
    "    add.columns = ['Decile', 'avg_real_call_rate']\n",
    "    add2 = pd.DataFrame(result.groupby('Decile')['CallToRetention'].count()).reset_index()\n",
    "    add2.columns = ['Decile', 'ban_count']\n",
    "    result = result.merge(add, on='Decile', how='left')\n",
    "    result = result.merge(add2, on='Decile', how='left')\n",
    "    result.sort_values('Decile', ascending=True, inplace=True)\n",
    "    lg = pd.DataFrame(result.groupby('Decile')['Prob'].mean()).reset_index()\n",
    "    lg.columns = ['Decile', 'avg_model_pred_call_rate']\n",
    "    lg.sort_values('Decile', ascending=False, inplace=True)\n",
    "    lg['avg_call_rate_total'] = result['CallToRetention'].mean()\n",
    "    lg = lg.merge(add, on='Decile', how='left')\n",
    "    lg = lg.merge(add2, on='Decile', how='left')\n",
    "    lg['lift'] = lg['avg_real_call_rate'] / lg['avg_call_rate_total']\n",
    "\n",
    "    return lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45036aa5-b931-4315-b3d2-cb0f982c04b6",
   "metadata": {},
   "source": [
    "### set X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644876f8-1449-4bc6-9ce7-a80674c299c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in df_processed.columns if col not in ['BAN', 'target']]\n",
    "# features = ['Product_Count','productMix_product_mix_all','productMix_hsic_count','productMix_sing_count','productMix_ttv_count','TOTAL_CHARGE',\n",
    "# 'HSIA_CHARGE','HP_CHARGE','TV_CHARGE','tot_disc_amt','hsic_disc_amt','sing_disc_amt','ttv_disc_amt','TOTAL_CHARGE_NO_DISC','HSIC_CHARGE_NO_DISC',\n",
    "# 'SING_CHARGE_NO_DISC','TTV_CHARGE_NO_DISC','total_disc_pct','hsic_disc_pct','sing_disc_pct','ttv_disc_pct','demographics_demo_avg_income','hsiaUsage_hs_tot_gb_average',\n",
    "# 'clckstrmData_wln_tot_cnt_r90d','clckstrmData_deal_tot_cnt_r90d','clckstrmData_supp_tot_cnt_r90d','frequency','recency','have_called','Tenure_Group_5-6Y','Tenure_Group_7+Y',\n",
    "# 'Tenure_Group_less_than_2Y','PROV_BC','Pcount_2P','Pcount_3P','Pcount_4P','Price_Plan_Grouping_Internet/Optik_250-1GB','Price_Plan_Grouping_Internet/Optik_Under_250MB',\n",
    "# 'Price_Plan_Grouping_Other','demographics_rural_family','demographics_unassigned','demographics_urban','demographics_urban_family','demographics_urban_young','CampaignFlag_Reached',\n",
    "# 'CampaignFlag_Targeted','price_sensitivity_Not_Sensitive','price_sensitivity_Very_Sensitive']\n",
    "\n",
    "# X, y = df_processed[[col for col in df_processed.columns if col != \\target\\]], df_processed[\\target\\]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None, shuffle=True, stratify=df_train['target'])\n",
    "\n",
    "#train test split\n",
    "df_train, df_val = train_test_split(df_processed, shuffle=True, test_size=0.2, stratify=df_processed['target'])\n",
    "\n",
    "ban_train = df_train['BAN']\n",
    "X_train = df_train[features]\n",
    "y_train = np.squeeze(df_train['target'].values)\n",
    "\n",
    "ban_test = df_val['BAN']\n",
    "X_test = df_val[features]\n",
    "y_test = np.squeeze(df_val['target'].values)\n",
    "\n",
    "ban_comb = df_processed['BAN']\n",
    "X_comb = df_processed[features]\n",
    "y_comb = np.squeeze(df_processed['target'].values)\n",
    "\n",
    "ban_score = df_score['BAN']\n",
    "X_score = df_score_processed[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb5fb0-61d4-4606-8d7f-32aef6a5a9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65418fb0-cbb9-40eb-bcb3-a29841d53ac9",
   "metadata": {},
   "source": [
    "### set up xgb and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bdaa71-56f6-4c30-97f3-2f9e6a9021ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model and fit in training data\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    learning_rate=0.02,\n",
    "    n_estimators=80,\n",
    "    max_depth=8,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train, \n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)], \n",
    "            early_stopping_rounds=20) \n",
    "# xgb_model.fit(X_train, y_train)\n",
    "print('xgb training done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dbda1d-9820-4b45-ace4-fccc154bf42e",
   "metadata": {},
   "source": [
    "### xgb hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5494ce4a-3962-4bf8-a92a-a9abaff5d976",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import xgboost as xgb \n",
    "# import pandas as pd \n",
    "\n",
    "# # Create your housing DMatrix: housing_dmatrix\n",
    "# class_dmatrix = xgb.DMatrix(data=X_train, label=y_train)\n",
    "\n",
    "# # Create the parameter dictionary for each tree (boosting round)\n",
    "# params = {\"objective\":\"binary:logistic\", \"max_depth\":3}\n",
    "# # Create list of eta values and empty list to store final round rmse per xgboost model\n",
    "# eta_vals = [0.001, 0.005, 0.01, 0.02, 0.05]\n",
    "# max_depths = [5, 8, 10, 12, 15]\n",
    "# colsample_bytree_vals = [0.7, 0.8, 0.9]\n",
    "# n_estimators = [25, 50, 80, 100, 150, 200, 300]\n",
    "\n",
    "# params_col = []\n",
    "# best_accuracy = []\n",
    "\n",
    "\n",
    "# # Systematically vary the eta \n",
    "# for curr_val in eta_vals:\n",
    "    \n",
    "#     for curr_depth in max_depths: \n",
    "        \n",
    "#         for curr_colval in colsample_bytree_vals:\n",
    "            \n",
    "#             for curr_estimators in n_estimators: \n",
    "\n",
    "#                 params[\"eta\"] = curr_val\n",
    "#                 params[\"max_depth\"] = curr_depth\n",
    "#                 params[\"colsample_bytree\"] = curr_colval\n",
    "#                 params[\"n_estimators\"] = curr_estimators\n",
    "\n",
    "#                 # Perform cross-validation: cv_results\n",
    "#                 cv_results = xgb.cv(dtrain=class_dmatrix, params=params, nfold=3, metrics=\"error\", as_pandas=True, early_stopping_rounds=5)\n",
    "\n",
    "#                 # Append the final round rmse to best_rmse\n",
    "#                 params_col.append([curr_val, curr_depth, curr_colval, curr_estimators])\n",
    "#                 best_accuracy.append(1-(cv_results[\"test-error-mean\"]).iloc[-1])\n",
    "\n",
    "# # Print the resultant DataFrame\n",
    "# df_result = pd.DataFrame(list(zip(params_col, best_accuracy)), columns=[\"params\", \"best_accuracy\"])\n",
    "\n",
    "# objs = [df_result, pd.DataFrame(df_result['params'].tolist())]\n",
    "# df_result = pd.concat(objs, axis=1).drop('params', axis=1)\n",
    "# df_result.rename(columns = {0 : 'eta', 1 : 'max_depth', 2: 'colsample_bytree', 3: 'n_estimators'}, inplace = True)\n",
    "# df_result = df_result[['eta', 'max_depth', 'colsample_bytree', 'best_accuracy', 'n_estimators']]\n",
    "\n",
    "# print(df_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602318a0-3d84-4c1b-b767-107b75677698",
   "metadata": {},
   "source": [
    "### make predictions on X_train and get lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c83e8bc-5ba0-4c7b-b81a-ad15b8ae7143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#predictions on X_test\n",
    "pred_prb = xgb_model.predict_proba(X_train, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "#join ban_test, X_test, y_test and pred_prb and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_train = ban_train.to_frame()\n",
    "df_train_exp = df_ban_train.join(X_train) \n",
    "df_train_exp['y_test'] = y_train\n",
    "df_train_exp['y_pred_proba'] = pred_prb\n",
    "df_train_exp['y_pred'] = (df_train_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_train_exp['decile'] = pd.qcut(df_train_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(pred_prb, y_train, q)\n",
    "\n",
    "lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1455fba5-9cbb-4faf-8dfc-2ccea7947634",
   "metadata": {},
   "source": [
    "### make predictions on X_test and get lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4880fd36-75c1-4f52-b952-d0135ab18b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#predictions on X_test\n",
    "pred_prb = xgb_model.predict_proba(X_test, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "#join ban_test, X_test, y_test and pred_prb and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_test = ban_test.to_frame()\n",
    "df_test_exp = df_ban_test.join(X_test) \n",
    "df_test_exp['y_test'] = y_test\n",
    "df_test_exp['y_pred_proba'] = pred_prb\n",
    "df_test_exp['y_pred'] = (df_test_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_test_exp['decile'] = pd.qcut(df_test_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(pred_prb, y_test, q)\n",
    "\n",
    "lg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f8860e-155a-4170-bb6a-8af1c7c05c6f",
   "metadata": {},
   "source": [
    "### make predictions on X_comb and get lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df80f504-e9dd-4eb5-ab18-4e14d90953fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#predictions on X_comb\n",
    "pred_prb = xgb_model.predict_proba(X_comb, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "#join ban_comb, X_comb, y_comb and pred_prb and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_comb = ban_comb.to_frame()\n",
    "df_comb_exp = df_ban_comb.join(X_comb) \n",
    "df_comb_exp['y_comb'] = y_comb\n",
    "df_comb_exp['y_pred_proba'] = pred_prb\n",
    "df_comb_exp['y_pred'] = (df_comb_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_comb_exp['decile'] = pd.qcut(df_comb_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(pred_prb, y_comb, q)\n",
    "\n",
    "lg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e7b509-3823-441d-ae27-026927aceed6",
   "metadata": {},
   "source": [
    "### export df_test_exp and lift scores to gcs bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c379d525-47f5-4d54-824d-97e7d8eb95de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb_exp.to_csv('gs://{}/downloads/df_comb_exp.csv'.format(file_bucket, index=True))\n",
    "print(\"....df_comb_exp done\")\n",
    "\n",
    "# lg.to_csv('gs://{}/lift_on_scoring_data.csv'.format(file_bucket, index=False))\n",
    "# print(\"....lift_to_csv done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e64b1c-e94e-4b7a-8577-1d9113803058",
   "metadata": {},
   "source": [
    "### make predictions on X_score and get lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd69b2f8-9968-439d-a7c7-15dd23c25730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#predictions on X_comb\n",
    "pred_prb = xgb_model.predict_proba(X_score, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "#join ban_comb, X_comb, y_comb and pred_prb and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_score = ban_score.to_frame()\n",
    "df_score_exp = df_ban_score.join(X_score) \n",
    "df_score_exp['y_pred_proba'] = pred_prb\n",
    "df_score_exp['decile'] = pd.qcut(df_score_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "df_score_exp.to_csv('gs://{}/downloads/df_score_exp.csv'.format(file_bucket, index=True))\n",
    "print('....df_score_exp done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91e36f1-d621-4838-a24d-929847aae799",
   "metadata": {},
   "source": [
    "### get feature importances from xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd24787-65c3-48dc-b833-72638406920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from xgboost model\n",
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "# Get the index of importances from greatest importance to least\n",
    "sorted_index = np.argsort(importances)[::-1]\n",
    "x = range(len(importances))\n",
    "\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create tick labels \n",
    "labels = np.array(feature_names)[sorted_index]\n",
    "importances = np.array(importances)[sorted_index]\n",
    "\n",
    "for idx, item in enumerate(labels): \n",
    "    print(labels[idx], importances[idx])\n",
    "    if idx == 25: \n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95957450-4518-4780-a4c8-4812c3cd7654",
   "metadata": {},
   "source": [
    "### set up rfc and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a904161-def5-4173-8083-cdf0b0afe568",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Create the random forest model and fit to the training data\n",
    "rfc_model = RandomForestClassifier(n_estimators=75, max_features=25, max_depth=8)\n",
    "\n",
    "rfc_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbd7d83-81e1-4380-b3f5-c39a43eeee0d",
   "metadata": {},
   "source": [
    "### make predictions on X_train and get lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53197279-2642-47d6-bfb0-b2f13fa1b910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#predictions on X_test\n",
    "pred_prb = rfc_model.predict_proba(X_train)[:, 1]\n",
    "pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "#join ban_test, X_test, y_test and pred_prb and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_train = ban_train.to_frame()\n",
    "df_train_exp = df_ban_train.join(X_train) \n",
    "df_train_exp['y_test'] = y_train\n",
    "df_train_exp['y_pred_proba'] = pred_prb\n",
    "df_train_exp['y_pred'] = (df_train_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_train_exp['decile'] = pd.qcut(df_train_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(pred_prb, y_train, q)\n",
    "\n",
    "lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816df0a5-7fc8-41a9-974d-0c5e0a6818b9",
   "metadata": {},
   "source": [
    "### make predictions on X_test and get lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f3081f-3934-4553-a971-d20209f2e4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#predictions on X_test\n",
    "pred_prb = rfc_model.predict_proba(X_test)[:, 1]\n",
    "pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "#join ban_test, X_test, y_test and pred_prb and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_test = ban_test.to_frame()\n",
    "df_test_exp = df_ban_test.join(X_test) \n",
    "df_test_exp['y_test'] = y_test\n",
    "df_test_exp['y_pred_proba'] = pred_prb\n",
    "df_test_exp['y_pred'] = (df_test_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_test_exp['decile'] = pd.qcut(df_test_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(pred_prb, y_test, q)\n",
    "\n",
    "lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5f8eb7-508b-4729-94b0-a70647d99a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504508b6-bc97-4510-95de-f67381c263cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63df75a2-5f79-4ebc-960b-5123a2971c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
