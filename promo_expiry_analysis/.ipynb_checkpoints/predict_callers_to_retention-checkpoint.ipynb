{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3162205-0a6b-4989-a465-446ae45281ef",
   "metadata": {},
   "source": [
    "## Predict callers to retention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4501997e-cde5-4158-a5f6-e599b21581ec",
   "metadata": {},
   "source": [
    "### read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea217f1-bcf7-4cad-8ecb-24110d052b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import google\n",
    "from google.oauth2 import credentials\n",
    "from google.oauth2 import service_account\n",
    "from google.oauth2.service_account import Credentials\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# build model\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "file_bucket = 'divg-josh-pr-d1cc3a-default' \n",
    "folder_name = 'promo_expiry_analysis'\n",
    "\n",
    "df = pd.read_csv('gs://{}/{}/data_final.csv'.format(file_bucket, folder_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cd0d99-1047-4c61-89c7-075196abc722",
   "metadata": {},
   "source": [
    "### preprocess\n",
    "\n",
    "- Tenure Group: cat\n",
    "- PROV: cat\n",
    "- Pcount: cat\n",
    "- Price Plan Grouping: cat\n",
    "- Technology Group: cat\n",
    "- demographics: cat\n",
    "- CampaignFlag: cat\n",
    "- price_sensitivity: cat\n",
    "- TOTALCalls: remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ee691c-22ef-4a44-9ac9-c05223c13d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6150f7e4-ac8a-4351-a8fd-5989dfab4249",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ded4cc-2b4b-4c0c-8a94-abb27104c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_dummy = ['Tenure Group', 'PROV', 'Pcount', 'Price Plan Grouping', 'Technology Group', 'demographics', 'CampaignFlag', 'price_sensitivity']\n",
    "\n",
    "for col in cols_to_dummy: \n",
    "\n",
    "    # Create dummy variables for the Country column\n",
    "    df = pd.get_dummies(df, columns=[col], drop_first=True, prefix=None, dtype=\"int64\")\n",
    "\n",
    "# reorder the df columns so that 'target' comes last\n",
    "df_processed = df[[c for c in df if c not in ['target']] \n",
    "       + ['target']]\n",
    "\n",
    "df_processed.columns = df_processed.columns.str.replace('<', 'less_than_')\n",
    "df_processed.columns = df_processed.columns.str.replace(' ', '_')\n",
    "\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd51f21-175f-489f-ae5f-aa08d70577f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5f25bf-ea3b-453c-a7df-d9920c396e38",
   "metadata": {},
   "source": [
    "### register lift function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b3e8cb-235b-4ceb-9edc-a39e58364707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lift(prob, y_test, q):\n",
    "    result = pd.DataFrame(columns=['Prob', 'CallToRetention'])\n",
    "    result['Prob'] = prob\n",
    "    result['CallToRetention'] = y_test\n",
    "    result['Decile'] = pd.qcut(result['Prob'], q, labels=[i for i in range(q, 0, -1)])\n",
    "    add = pd.DataFrame(result.groupby('Decile')['CallToRetention'].mean()).reset_index()\n",
    "    add.columns = ['Decile', 'avg_real_call_rate']\n",
    "    add2 = pd.DataFrame(result.groupby('Decile')['CallToRetention'].count()).reset_index()\n",
    "    add2.columns = ['Decile', 'ban_count']\n",
    "    result = result.merge(add, on='Decile', how='left')\n",
    "    result = result.merge(add2, on='Decile', how='left')\n",
    "    result.sort_values('Decile', ascending=True, inplace=True)\n",
    "    lg = pd.DataFrame(result.groupby('Decile')['Prob'].mean()).reset_index()\n",
    "    lg.columns = ['Decile', 'avg_model_pred_call_rate']\n",
    "    lg.sort_values('Decile', ascending=False, inplace=True)\n",
    "    lg['avg_call_rate_total'] = result['CallToRetention'].mean()\n",
    "    lg = lg.merge(add, on='Decile', how='left')\n",
    "    lg = lg.merge(add2, on='Decile', how='left')\n",
    "    lg['lift'] = lg['avg_real_call_rate'] / lg['avg_call_rate_total']\n",
    "\n",
    "    return lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45036aa5-b931-4315-b3d2-cb0f982c04b6",
   "metadata": {},
   "source": [
    "### set X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644876f8-1449-4bc6-9ce7-a80674c299c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in df_processed.columns if col not in [\"BAN\", \"target\"]]\n",
    "\n",
    "X, y = df_processed[[col for col in df_processed.columns if col != \"target\"]], df_processed[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None, shuffle=True)\n",
    "\n",
    "ban_train = X_train['BAN']\n",
    "X_train = X_train[features]\n",
    "y_train = np.squeeze(y_train.values)\n",
    "\n",
    "ban_test = X_test['BAN']\n",
    "X_test = X_test[features]\n",
    "y_test = np.squeeze(y_test.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65418fb0-cbb9-40eb-bcb3-a29841d53ac9",
   "metadata": {},
   "source": [
    "### set up xgb and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bdaa71-56f6-4c30-97f3-2f9e6a9021ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# build model and fit in training data\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=80,\n",
    "    max_depth=8,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1\n",
    "    # seed=27\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print('xgb training done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602318a0-3d84-4c1b-b767-107b75677698",
   "metadata": {},
   "source": [
    "### make predictions on X_train and get lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c83e8bc-5ba0-4c7b-b81a-ad15b8ae7143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#predictions on X_test\n",
    "pred_prb = xgb_model.predict_proba(X_train, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "#join ban_test, X_test, y_test and pred_prb and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_train = ban_train.to_frame()\n",
    "df_train_exp = df_ban_train.join(X_train) \n",
    "df_train_exp['y_test'] = y_train\n",
    "df_train_exp['y_pred_proba'] = pred_prb\n",
    "df_train_exp['y_pred'] = (df_train_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_train_exp['decile'] = pd.qcut(df_train_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(pred_prb, y_train, q)\n",
    "\n",
    "lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1455fba5-9cbb-4faf-8dfc-2ccea7947634",
   "metadata": {},
   "source": [
    "### make predictions on X_test and get lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4880fd36-75c1-4f52-b952-d0135ab18b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#predictions on X_test\n",
    "pred_prb = xgb_model.predict_proba(X_test, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "#join ban_test, X_test, y_test and pred_prb and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_test = ban_test.to_frame()\n",
    "df_test_exp = df_ban_test.join(X_test) \n",
    "df_test_exp['y_test'] = y_test\n",
    "df_test_exp['y_pred_proba'] = pred_prb\n",
    "df_test_exp['y_pred'] = (df_test_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_test_exp['decile'] = pd.qcut(df_test_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(pred_prb, y_test, q)\n",
    "\n",
    "lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95957450-4518-4780-a4c8-4812c3cd7654",
   "metadata": {},
   "source": [
    "### set up rfc and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a904161-def5-4173-8083-cdf0b0afe568",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Create the random forest model and fit to the training data\n",
    "rfc_model = RandomForestClassifier(n_estimators=75, max_features=8, max_depth=9)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbd7d83-81e1-4380-b3f5-c39a43eeee0d",
   "metadata": {},
   "source": [
    "### make predictions on X_train and get lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53197279-2642-47d6-bfb0-b2f13fa1b910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#predictions on X_test\n",
    "pred_prb = rfc_model.predict_proba(X_train, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "#join ban_test, X_test, y_test and pred_prb and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_train = ban_train.to_frame()\n",
    "df_train_exp = df_ban_train.join(X_train) \n",
    "df_train_exp['y_test'] = y_train\n",
    "df_train_exp['y_pred_proba'] = pred_prb\n",
    "df_train_exp['y_pred'] = (df_train_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_train_exp['decile'] = pd.qcut(df_train_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(pred_prb, y_train, q)\n",
    "\n",
    "lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816df0a5-7fc8-41a9-974d-0c5e0a6818b9",
   "metadata": {},
   "source": [
    "### make predictions on X_test and get lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f3081f-3934-4553-a971-d20209f2e4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#predictions on X_test\n",
    "pred_prb = rfc_model.predict_proba(X_test, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "#join ban_test, X_test, y_test and pred_prb and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_test = ban_test.to_frame()\n",
    "df_test_exp = df_ban_test.join(X_test) \n",
    "df_test_exp['y_test'] = y_test\n",
    "df_test_exp['y_pred_proba'] = pred_prb\n",
    "df_test_exp['y_pred'] = (df_test_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_test_exp['decile'] = pd.qcut(df_test_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(pred_prb, y_test, q)\n",
    "\n",
    "lg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
