{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb66167-4608-492e-9c5f-334566d944ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import LGBMClassifier as lgb \n",
    "\n",
    "# lgb_model = lgb.LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, boosting_type='gbdt', \n",
    "# class_weight=None, colsample_bytree=1.0, feature_fraction=0.8, \n",
    "# importance_type='split', learning_rate=0.0005, max_depth=-1, \n",
    "# min_child_samples=1, min_child_weight=0.001, min_split_gain=0.2, \n",
    "# n_estimators=30, n_jobs=-1, num_leaves=256, objective=None, \n",
    "# random_state=123, reg_alpha=3, reg_lambda=0.001, silent='warn', \n",
    "# subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c5d5f5-8e49-4c28-beb1-ff9676bed6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag cell with parameters\n",
    "project_id =  'divg-josh-pr-d1cc3a'\n",
    "dataset_id = 'churn_12_months'\n",
    "resource_bucket = 'divg-josh-pr-d1cc3a-default'\n",
    "file_bucket = 'divg-josh-pr-d1cc3a-default'\n",
    "model_id = '5220'\n",
    "model_name = 'churn_12_months'\n",
    "pipeline_dataset = 'bq_c12m_training_dataset'\n",
    "service_type = 'churn_12_months' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8456331b-5bb2-4a8a-82fe-045e4d862aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import logging \n",
    "from datetime import datetime\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "    \n",
    "import os \n",
    "import gc\n",
    "import time\n",
    "import pickle\n",
    "import joblib\n",
    "import logging \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_curve, mean_squared_error, f1_score, precision_score, recall_score, confusion_matrix, roc_curve, classification_report\n",
    "\n",
    "df_train = pd.read_csv('gs://{}/{}/{}_train.csv'.format(file_bucket, service_type, service_type), index_col=False, nrows=10000)  \n",
    "\n",
    "#train test split\n",
    "df_train, df_test = train_test_split(df_train, shuffle=True, test_size=0.3, random_state=42,\n",
    "                                    stratify=df_train['target']\n",
    "                                    )\n",
    "#train val split\n",
    "df_train, df_val = train_test_split(df_train, shuffle=True, test_size=0.3, random_state=42,\n",
    "                                    stratify=df_train['target']\n",
    "                                    )\n",
    "\n",
    "#set up features (list)\n",
    "cols_1 = df_train.columns.values\n",
    "cols_2 = df_test.columns.values\n",
    "cols = set(cols_1).intersection(set(cols_2))\n",
    "features = [f for f in cols if f not in ['ban', 'target', 'Unnamed: 0']]\n",
    "\n",
    "create_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "ban_train = df_train['ban']\n",
    "X_train = df_train[features]\n",
    "y_train = np.squeeze(df_train['target'].values)\n",
    "\n",
    "ban_val = df_val['ban']\n",
    "X_val = df_val[features]\n",
    "y_val = np.squeeze(df_val['target'].values)\n",
    "\n",
    "ban_test = df_test['ban']\n",
    "X_test = df_test[features]\n",
    "y_test = np.squeeze(df_test['target'].values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd2f00-0211-4733-9f94-c0d43e2a1f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get a list of all column names\n",
    "all_columns = X_train.columns.tolist()\n",
    "\n",
    "# Step 2: Initialize empty lists for numerical and categorical columns\n",
    "numerical_features = []\n",
    "categorical_features = []\n",
    "\n",
    "# Step 3: Loop through each column to determine its data type\n",
    "for column in all_columns:\n",
    "    if pd.api.types.is_numeric_dtype(X_train[column]):\n",
    "        numerical_features.append(column)\n",
    "    else:\n",
    "        categorical_features.append(column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d792505-19e7-426d-b5ea-b1528edd5acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import IsolationForest  # You can also use OneClassSVM or other methods for outlier detection\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), numerical_features),  # Standardization for numerical features\n",
    "        ('cat', OneHotEncoder(), categorical_features)  # One-hot encoding for categorical features\n",
    "    ],\n",
    "    remainder='passthrough'  # Include any unprocessed columns\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195588bb-f9a6-430b-91e6-3f3cc2154eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf51a757-a1a9-42f8-9dec-2d8649a3822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = pipeline.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bf0f4e-3ce6-4058-aa08-aa86a7c862f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c0ce6-8301-4546-8730-a12381298569",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pp = pd.DataFrame(transformed_data)\n",
    "X_train_pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12744fb9-9bd2-440a-bbaf-f58297e466ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd591cc-f546-416e-85fa-b61fc6b67ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import IsolationForest  # You can also use OneClassSVM or other methods for outlier detection\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def preprocess_ml(df): \n",
    "    \n",
    "    # Step 1: Get a list of all column names\n",
    "    all_columns = df.columns.tolist()\n",
    "\n",
    "    # Step 2: Initialize empty lists for numerical and categorical columns\n",
    "    numerical_features = []\n",
    "    categorical_features = []\n",
    "\n",
    "    # Step 3: Loop through each column to determine its data type\n",
    "    for column in all_columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            numerical_features.append(column)\n",
    "        else:\n",
    "            categorical_features.append(column)\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', MinMaxScaler(), numerical_features),  # Standardization for numerical features\n",
    "            ('cat', OneHotEncoder(), categorical_features)  # One-hot encoding for categorical features\n",
    "        ],\n",
    "        remainder='passthrough'  # Include any unprocessed columns\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(df)\n",
    "\n",
    "    transformed_df = pipeline.transform(df)\n",
    "\n",
    "    df_result = pd.DataFrame(transformed_df, columns=df.columns)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76536b3-4fda-42f5-bc47-f4f63365a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pp = preprocess_ml(X_train)\n",
    "print(X_train.shape)\n",
    "print(X_train_pp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d8afe0-6dc8-475f-959f-f8c721cfba94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
