{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b84643f-8aa7-4939-a46e-c4ece6ad28d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6791df7-7985-4f83-b93b-7a04cb548d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,HTML,\n",
    "                        OutputPath, ClassificationMetrics, Metrics, component)\n",
    "\n",
    "\n",
    "# Component for Pycaret AutoML Training Pipeline\n",
    "@component(\n",
    "    base_image=\"northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/wb-platform/initiative/koodo-pyp/koodo-pyp-jupyter:latest\",\n",
    "    output_component_file=\"pycaret_automl.yaml\",\n",
    ")\n",
    "\n",
    "def pycaret_automl(\n",
    "    project_id: str,\n",
    "    bucket_name: str,\n",
    "    resources_bucket_name : str,\n",
    "    dataset: str,\n",
    "    training_dataset: str,\n",
    "    utils_file_path : str,\n",
    "    utils_filename: str,\n",
    "    plot_utils_filename : str,\n",
    "    training_perc : float ,\n",
    "    sample_perc_training : float,\n",
    "    sample_perc_valid :float,\n",
    "    model: Output[Model],\n",
    "    model_metrics_report: Output[HTML]\n",
    "\n",
    "):\n",
    "    from google.cloud import bigquery\n",
    "    from google.cloud import storage\n",
    "    from datetime import datetime\n",
    "    import logging \n",
    "    from pycaret.classification import setup,create_model,tune_model, predict_model,get_config,compare_models,save_model,tune_model\n",
    "    from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_curve, mean_squared_error, f1_score, precision_score, recall_score, confusion_matrix, roc_curve\n",
    " \n",
    "    ## import data\n",
    "    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n",
    "    # import google.oauth2.credentials\n",
    "   \n",
    "    client = bigquery.Client(project=project_id, location='northamerica-northeast1')\n",
    "    storage_client = storage.Client(project=project_id)\n",
    "        \n",
    "    # Get utils.py\n",
    "    bucket = storage_client.get_bucket(resources_bucket_name)\n",
    "    blob = bucket.get_blob(f\"{utils_file_path}/{utils_filename}\")\n",
    "    blob.download_to_filename(utils_filename)\n",
    "    blob = bucket.get_blob(f\"{utils_file_path}/{plot_utils_filename}\")\n",
    "    blob.download_to_filename(plot_utils_filename)\n",
    "    \n",
    "    from preprocessing_utils import pre_process_data\n",
    "    from preprocessing_utils import downsampling\n",
    "    from plotly_utils import evaluate_and_save_models,create_folder_if_not_exists,ploty_model_metrics,plotly_feature_importance,plotly_lift_curve, plotly_model_report,plotly_roc, plotly_confusion_matrix,plotly_output_hist,plotly_precision_recall \n",
    "    # specify the path to the training data\n",
    "    training_table = f\"{project_id}.{dataset}.{training_dataset}\"\n",
    "    \n",
    "    # generate the query\n",
    "    train_query = '''\n",
    "       SELECT * \n",
    "                FROM `{training_table}`\n",
    "    '''.format(training_table = training_table)\n",
    "   \n",
    "\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    \n",
    "    # create a dataframe with the training data\n",
    "    train_all = client.query(train_query, job_config=job_config).to_dataframe()\n",
    "    \n",
    "    # josh test starts here\n",
    "    train_all = pd.read_csv('gs://{}/{}_train.csv.gz'.format(file_bucket, service_type),\n",
    "                           compression='gzip')  \n",
    "    # valid_df = pd.read_csv('gs://{}/{}_validation.csv.gz'.format(file_bucket, service_type),  \n",
    "    #                       compression='gzip')\n",
    "    \n",
    "\n",
    "    #set up df_train\n",
    "    client = bigquery.Client(project=project_id)\n",
    "    sql_train = ''' SELECT * FROM `{}.{}.bq_call_to_retention_targets` '''.format(project_id, dataset_id) \n",
    "    df_target_train = client.query(sql_train).to_dataframe()\n",
    "    df_target_train = df_target_train.loc[\n",
    "        df_target_train['YEAR_MONTH'] == '-'.join(score_date_dash.split('-')[:2])]  # score_date_dash = '2022-08-31'\n",
    "    df_target_train['ban'] = df_target_train['ban'].astype('int64')\n",
    "    df_target_train = df_target_train.groupby('ban').tail(1)\n",
    "    df_train = df_train.merge(df_target_train[['ban', 'target_ind']], on='ban', how='left')\n",
    "    df_train.rename(columns={'target_ind': 'target'}, inplace=True)\n",
    "    df_train.dropna(subset=['target'], inplace=True)\n",
    "    df_train['target'] = df_train['target'].astype(int)\n",
    "    print(df_train.shape)\n",
    "    \n",
    "    df_train.to_csv('gs://{}/{}_train_monitoring.csv'.format(file_bucket, service_type))  \n",
    "    df_test.to_csv('gs://{}/{}_validation_monitoring.csv'.format(file_bucket, service_type))\n",
    "    \n",
    "    #set up df_test\n",
    "    sql_test = ''' SELECT * FROM `{}.{}.bq_call_to_retention_targets` '''.format(project_id, dataset_id) \n",
    "    df_target_test = client.query(sql_test).to_dataframe()\n",
    "    df_target_test = df_target_test.loc[\n",
    "        df_target_test['YEAR_MONTH'] == '-'.join(score_date_val_dash.split('-')[:2])]  # score_date_dash = '2022-09-30'\n",
    "    df_target_test['ban'] = df_target_test['ban'].astype('int64')\n",
    "    df_target_test = df_target_test.groupby('ban').tail(1)\n",
    "    df_test = df_test.merge(df_target_test[['ban', 'target_ind']], on='ban', how='left')\n",
    "    df_test.rename(columns={'target_ind': 'target'}, inplace=True)\n",
    "    df_test.dropna(subset=['target'], inplace=True)\n",
    "    df_test['target'] = df_test['target'].astype(int)\n",
    "    print(df_test.shape)\n",
    "\n",
    "\n",
    "     ##############  Split train/valid/test based of Dev Training Sample Size   #######################\n",
    "    training_perc = 0.62\n",
    "    train_df = train_all.sort_values([\"partition_dt\"]).iloc[:int(train_all.shape[0]*training_perc)]\n",
    "\n",
    "    lower_bound = int(train_all.shape[0]*training_perc)\n",
    "    upper_bound = lower_bound + int(train_all.shape[0]*((1-training_perc)/2))\n",
    "    valid_df = train_all.sort_values([\"partition_dt\"]).iloc[lower_bound:upper_bound]\n",
    "\n",
    "    lower_bound = train_df.shape[0] + valid_df.shape[0]\n",
    "    upper_bound = lower_bound + int(train_all.shape[0]*((1-training_perc)/2))\n",
    "    test_df = train_all.sort_values([\"partition_dt\"]).iloc[lower_bound:]\n",
    "    \n",
    "    ##############  Downsample train/valid   #######################\n",
    "    \n",
    "    train_sampled = downsampling(df=train_df, true_to_false_ratio=sample_perc_training)\n",
    "    valid_sampled = downsampling(df=valid_df, true_to_false_ratio=sample_perc_valid)\n",
    "\n",
    "    ############################# Preprocess data  ############################\n",
    "    \n",
    "    drop_cols =  ['ban']\n",
    "\n",
    "    feats = [col for col in train_sampled.columns if col not in drop_cols]\n",
    "    train_sampled.drop(columns = drop_cols , inplace=True)\n",
    "    valid_sampled.drop(columns = drop_cols , inplace=True)\n",
    "\n",
    "    # train.rpc_flag = train.rpc_flag.astype(int)\n",
    "    train_sampled.rpc_flag = train_sampled.rpc_flag.astype(int)\n",
    "    valid_sampled.rpc_flag = valid_sampled.rpc_flag.astype(int)\n",
    "    test_df.rpc_flag = test_df.rpc_flag.astype(int)    ### Split train/valid/test\n",
    "    # //todo : Training class 0 and class 1 sample function integration\n",
    "    numeric_features = [col for col in train_sampled.columns if col != 'rpc_flag']\n",
    "    \n",
    "    #tag cell with parameters\n",
    "    PROJECT_ID =  'divg-josh-pr-d1cc3a'\n",
    "    BUCKET_NAME='divg-josh-pr-d1cc3a-default'\n",
    "    DATASET_ID = 'telus_rewards'\n",
    "    RESOURCE_BUCKET = 'divg-josh-pr-d1cc3a-default'\n",
    "    FILE_BUCKET = 'divg-josh-pr-d1cc3a-default'\n",
    "    MODEL_ID = '5070'\n",
    "    SERVICE_TYPE = 'call_to_retention'\n",
    "    \n",
    "    file_bucket = FILE_BUCKET\n",
    "    service_type = SERVICE_TYPE\n",
    "    \n",
    "    ################################ Pycaret Setup initialize  ############################ \n",
    "    classification_setup = setup(data=train_sampled, \n",
    "                             ignore_features=drop_cols,\n",
    "                             test_data = valid_sampled ,\n",
    "                             target='target',\n",
    "                             fix_imbalance=False,\n",
    "                             remove_outliers = True,\n",
    "                             normalize=True,\n",
    "                             normalize_method='zscore',\n",
    "                             log_experiment=False,\n",
    "                             remove_multicollinearity=True,\n",
    "                             multicollinearity_threshold=0.95,\n",
    "                             feature_selection=True,\n",
    "                             fold=5,\n",
    "                             fold_shuffle=True,\n",
    "                             session_id=123,\n",
    "                             numeric_features=numeric_features,\n",
    "                             silent=True)\n",
    "    \n",
    "    ### Pycaret top 3 models to analyze\n",
    "    best_model = compare_models(include = ['rf','xgboost','lightgbm','et'],errors='raise', n_select=3)\n",
    "    # save the model reports and report fig of all top 2 models to GCS\n",
    "    todays_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    save_path = f'pycaret/test_{todays_date}/'\n",
    "    model_reports, model_to_report_map = evaluate_and_save_models(models=best_model.copy(), \n",
    "                                         bucket_name=file_bucket,\n",
    "                                         save_path=save_path, \n",
    "                                         test_df=test_df,\n",
    "                                         actual_label_str='target_ind',\n",
    "                                         columns = get_config('X_train').columns,\n",
    "                                         save_columns=True,\n",
    "                                         show_report=False)\n",
    "    # Find the top Model and top model's report Figs\n",
    "    top_model = None\n",
    "    for i in range(len(best_model)):\n",
    "        if best_model[i].__class__.__name__ == model_reports.sort_values([\"Recall\",\"Precision\"],ascending=False).head(1)[\"model_name\"][0]:\n",
    "            top_model = best_model.copy()[i]\n",
    "\n",
    "\n",
    "    best_model = model_reports.sort_values([\"Recall\",\"Precision\"],ascending=False).head(1)[\"model_name\"][0]\n",
    "    best_model_report = model_to_report_map[top_model.__class__.__name__]\n",
    "    \n",
    "    ################ Export the top model's report and figs to GCS ###############################\n",
    "    bucket = storage.Client().bucket(bucket_name)\n",
    "    save_path = f'models/best_model/{todays_date}/'\n",
    "    create_folder_if_not_exists(save_path)\n",
    "    ######### Save HTML report of the best model\n",
    "    best_model_report.write_html(f\"{save_path}{todays_date}_{top_model.__class__.__name__}.html\")\n",
    "\n",
    "    filename = f\"{todays_date}_{top_model.__class__.__name__}.html\"\n",
    "    blob = bucket.blob(f\"{save_path}{filename}\")\n",
    "    blob.upload_from_filename(f\"{save_path}{todays_date}_{top_model.__class__.__name__}.html\")\n",
    "    logging.info(f\"{filename} sucessfully uploaded to GCS bucket!\")\n",
    "\n",
    "    ####### Save the model\n",
    "    model_file_name = '{save_path}{model_type}_{date}'.format(save_path = save_path,\n",
    "                                      model_type = top_model.__class__.__name__,    \n",
    "                                      date=datetime.now().strftime(\"%Y-%m-%d\"))                                                                   \n",
    "    save_model(top_model,model_file_name)\n",
    "    filename = '{model_type}_{date}.pkl'.format(model_type=top_model.__class__.__name__,date=datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "    blob = bucket.blob(f\"{save_path}{filename}\")\n",
    "    blob.upload_from_filename(f\"{model_file_name}.pkl\")\n",
    "    logging.info(f\"{filename} sucessfully uploaded to GCS bucket!\")\n",
    "    \n",
    "    ###############################  Tuned Model  ##############################\n",
    "    model_base = create_model(top_model)\n",
    "    tuned_model, tuner = tune_model(model_base, optimize='recall', return_tuner = True, n_iter = 20)\n",
    "    save_path = f'models/best_model/tuned/{todays_date}/'\n",
    "    model_reports_tuned, model_to_report_map_tuned = evaluate_and_save_models(models=tuned_model, \n",
    "                                         bucket_name=bucket_name,\n",
    "                                         save_path=save_path, \n",
    "                                         test_df=test_df,\n",
    "                                         actual_label_str='rpc_flag',\n",
    "                                         columns = get_config('X_train').columns,\n",
    "                                         save_columns=True,\n",
    "                                         show_report=False)\n",
    "    \n",
    "    ###############################   Define  Final Model     ##############################\n",
    "    \n",
    "    final_model_report = None\n",
    "    final_model_class_name = None\n",
    "    final_model_file = None\n",
    "    if model_reports_tuned.Recall.values[0] >= 1 :\n",
    "        logging.info(\"CAUTION : TUNED MODEL had 100% recall. TUNED model was not selected as best model. \")\n",
    "        final_model_class_name = top_model.__class__.__name__\n",
    "        final_model_report = best_model_report\n",
    "        final_model_file = top_model\n",
    "    elif model_reports_tuned.Recall.values[0] > model_reports.sort_values([\"Recall\",\"Precision\"],ascending=False).head(1).Recall.values[0]:\n",
    "        base_recall = model_reports.sort_values([\"Recall\",\"Precision\"],ascending=False).head(1).Recall.values[0]\n",
    "        logging.info(f\"TUNED MODEL had {model_reports_tuned.Recall.values[0]*100} recall and Base model without tuning had {base_recall*100} Recall. TUNED model was selected as best model. \")\n",
    "        \n",
    "        final_model_class_name = tuned_model.__class__.__name__\n",
    "        final_model_report = model_to_report_map_tuned[final_model_class_name]\n",
    "        final_model_file = tuned_model\n",
    "    else:\n",
    "        base_recall = model_reports.sort_values([\"Recall\",\"Precision\"],ascending=False).head(1).Recall.values[0]\n",
    "        logging.info(f\"TUNED MODEL had {model_reports_tuned.Recall.values[0]*100} recall and Base model without tuning had {base_recall*100} Recall. TUNED model was selected as best model. \")\n",
    "        final_model_class_name = top_model.__class__.__name__\n",
    "        final_model_report = best_model_report\n",
    "        final_model_file = top_model\n",
    "\n",
    "    ###############################  Save the Report and model    ###############################\n",
    "    # Save HTML report of the selected model\n",
    "    # final_model_report = model_to_report_map_tuned[tuned_model.__class__.__name__]\n",
    "    save_path = f'models/final_selected/{todays_date}/'\n",
    "    create_folder_if_not_exists(save_path)\n",
    "    final_model_report.write_html(f\"{save_path}{todays_date}_{final_model_class_name}.html\")\n",
    "    # bucket = storage.Client().bucket(bucket)\n",
    "    filename = f\"{todays_date}_{final_model_class_name}.html\"\n",
    "    blob = bucket.blob(f\"{save_path}{filename}\")\n",
    "    blob.upload_from_filename(f\"{save_path}{todays_date}_{final_model_class_name}.html\")\n",
    "    print(f\"{filename} sucessfully uploaded to GCS bucket!\")\n",
    "\n",
    "    \n",
    "    model_file_name = '{save_path}{model_type}_{date}'.format(save_path = save_path,\n",
    "                                      model_type = final_model_class_name,    \n",
    "                                      date=datetime.now().strftime(\"%Y-%m-%d\"))                                                                   \n",
    "    save_model(final_model_file,model_file_name)\n",
    "    filename = 'model.pkl'.format(model_type=final_model_class_name,date=datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "    blob = bucket.blob(f\"{save_path}{filename}\")\n",
    "    blob.upload_from_filename(f\"{model_file_name}.pkl\")\n",
    "    print(f\"{filename} sucessfully uploaded to GCS bucket!\")\n",
    "    \n",
    "    ######################## Save the final Model for Upload Moel componet with Renaming ##############\n",
    "    model.uri = f'gs://{bucket_name}/models/final_selected/{todays_date}/'\n",
    "    \n",
    "    # save_model(final_model_file,'model.pkl')\n",
    "    # final_model_file.save_model(model.path + \".bst\")\n",
    "    \n",
    "    ###################### Output Final Selected Model's HTML Report View ########################\n",
    "\n",
    "    model_metrics_report.path = f'gs://{bucket_name}/{save_path}{todays_date}_{final_model_class_name}.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d85d4d-2c2b-4028-b793-321c06b65cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9f1220-ed4b-4c32-9cb7-d9214f6f89f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c0c97c-9e7b-4acd-8a01-df0cf3772224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f7a936-06c2-42a8-86a2-a14a862651ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a31b0a-fec9-463a-9a37-c3a228f92e50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
