{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db05bba0-639a-4288-be14-79e6a8d35cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output, OutputPath, ClassificationMetrics,\n",
    "                        Metrics, component)\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import google\n",
    "from google.oauth2 import credentials\n",
    "from google.oauth2 import service_account\n",
    "from google.oauth2.service_account import Credentials\n",
    "from google.cloud import storage\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "from google_cloud_pipeline_components.v1.batch_predict_job import \\\n",
    "    ModelBatchPredictOp as batch_prediction_op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa46381c-e6c3-4983-81a8-7011d1e5226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag cell with parameters\n",
    "PROJECT_ID =  'divg-josh-pr-d1cc3a'\n",
    "BUCKET_NAME='divg-josh-pr-d1cc3a-default'\n",
    "DATASET_ID = 'telus_rewards'\n",
    "RESOURCE_BUCKET = 'divg-josh-pr-d1cc3a-default'\n",
    "FILE_BUCKET = 'divg-josh-pr-d1cc3a-default'\n",
    "MODEL_ID = '5070'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862df6cd-dc64-438b-8530-085ab69c872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_TYPE = 'telus_rewards'\n",
    "SERVICE_TYPE_NAME = 'telus-rewards'\n",
    "TABLE_ID = 'telus_rwrd_redemption_targets'\n",
    "REGION = 'northamerica-northeast1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb7d9d5-c42d-4317-acf1-6a4979dd943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "STACK_NAME = 'telus_rewards'\n",
    "TRAIN_PIPELINE_NAME_PATH = 'telus_rewards/training_pipeline'\n",
    "PREDICT_PIPELINE_NAME_PATH = 'telus_rewards/predicting_pipeline'\n",
    "TRAIN_PIPELINE_NAME = 'telus-rewards-train-pipeline' # Same name as pulumi.yaml\n",
    "PREDICT_PIPELINE_NAME = 'telus-rewards-predict-pipeline' # Same name as pulumi.yaml\n",
    "TRAIN_PIPELINE_DESCRIPTION = 'telus-rewards-train-pipeline'\n",
    "PREDICT_PIPELINE_DESCRIPTION = 'telus-rewards-predict-pipeline'\n",
    "PIPELINE_ROOT = f\"gs://{BUCKET_NAME}\"\n",
    "REGION = \"northamerica-northeast1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e55426-f89d-43a7-bf35-d1ec1c0dfac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATASET_TABLE_NAME = 'bq_telus_rewards_pipeline_dataset'\n",
    "TRAINING_DATASET_SP_NAME = 'bq_sp_telus_rewards_pipeline_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a5f5fa-5b94-4edb-9520-f4fd05302999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download required component files to local\n",
    "prefix = f'{STACK_NAME}/{TRAIN_PIPELINE_NAME_PATH}/components/'\n",
    "dl_dir = 'components/'\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(RESOURCE_BUCKET)\n",
    "blobs = bucket.list_blobs(prefix=prefix)  # Get list of files\n",
    "for blob in blobs: # download each file that starts with \"prefix\" into \"dl_dir\"\n",
    "    if blob.name.endswith(\"/\"):\n",
    "        continue\n",
    "    file_split = blob.name.split(prefix)\n",
    "    file_path = f\"{dl_dir}{file_split[-1]}\"\n",
    "    directory = \"/\".join(file_path.split(\"/\")[0:-1])\n",
    "    Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "    blob.download_to_filename(file_path) \n",
    "\n",
    "# import main pipeline components\n",
    "from components.bq_create_dataset import bq_create_dataset\n",
    "from components.preprocess import preprocess\n",
    "from components.train_and_save_model import train_and_save_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776598bc-482a-4123-a1bb-86f84b348a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoringDate = date(2022, 9, 1)  # date.today() - relativedelta(days=2)- relativedelta(months=30)\n",
    "valScoringDate = date(2022, 11, 1)  # scoringDate - relativedelta(days=2)\n",
    "\n",
    "# training dates\n",
    "SCORE_DATE = scoringDate.strftime('%Y%m%d')  # date.today().strftime('%Y%m%d')\n",
    "SCORE_DATE_DASH = scoringDate.strftime('%Y-%m-%d')\n",
    "SCORE_DATE_MINUS_6_MOS_DASH = ((scoringDate - relativedelta(months=6)).replace(day=1)).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_LAST_MONTH_START_DASH = (scoringDate.replace(day=1) - timedelta(days=1)).replace(day=1).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_LAST_MONTH_END_DASH = ((scoringDate.replace(day=1)) - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "PROMO_EXPIRY_START = (scoringDate.replace(day=1) + relativedelta(months=3)).replace(day=1).strftime('%Y-%m-%d')\n",
    "PROMO_EXPIRY_END = (scoringDate.replace(day=1) + relativedelta(months=4)).replace(day=1).strftime('%Y-%m-%d')\n",
    "\n",
    "# validation dates\n",
    "SCORE_DATE_VAL = valScoringDate.strftime('%Y%m%d')\n",
    "SCORE_DATE_VAL_DASH = valScoringDate.strftime('%Y-%m-%d')\n",
    "SCORE_DATE_VAL_MINUS_6_MOS_DASH = ((valScoringDate - relativedelta(months=6)).replace(day=1)).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_VAL_LAST_MONTH_START_DASH = (valScoringDate.replace(day=1) - timedelta(days=1)).replace(day=1).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_VAL_LAST_MONTH_END_DASH = ((valScoringDate.replace(day=1)) - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "PROMO_EXPIRY_START_VAL = (valScoringDate.replace(day=1) + relativedelta(months=3)).replace(day=1).strftime('%Y-%m-%d')\n",
    "PROMO_EXPIRY_END_VAL = (valScoringDate.replace(day=1) + relativedelta(months=4)).replace(day=1).strftime('%Y-%m-%d')\n",
    "\n",
    "SCORE_DATE_DELTA = 0\n",
    "SCORE_DATE_VAL_DELTA = 0\n",
    "TICKET_DATE_WINDOW = 30  # Days of ticket data to be queried\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d6874-0ee6-4559-baa1-74d433491d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_bucket=FILE_BUCKET\n",
    "service_type=SERVICE_TYPE\n",
    "score_date_dash=SCORE_DATE_DASH\n",
    "score_date_val_dash=SCORE_DATE_VAL_DASH\n",
    "project_id=PROJECT_ID\n",
    "dataset_id=DATASET_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1b0f7e-8287-4d00-bfd1-2dafdb66236b",
   "metadata": {},
   "source": [
    "### bq_create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855355a1-f2ab-4cfa-90ea-992e57d78c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bq_create_dataset(score_date: str,\n",
    "                      score_date_delta: int,\n",
    "                      project_id: str,\n",
    "                      dataset_id: str,\n",
    "                      region: str,\n",
    "                      promo_expiry_start: str, \n",
    "                      promo_expiry_end: str, \n",
    "                      v_start_date: str,\n",
    "                      v_end_date: str):\n",
    " \n",
    "    import google\n",
    "    from google.cloud import bigquery\n",
    "    from datetime import datetime\n",
    "    import logging \n",
    "    import os \n",
    "    import re \n",
    "    from google.oauth2 import credentials\n",
    "\n",
    "    def get_gcp_bqclient(project_id, use_local_credential=True):\n",
    "        token = os.popen('gcloud auth print-access-token').read()\n",
    "        token = re.sub(f'\\n$', '', token)\n",
    "        credentials = google.oauth2.credentials.Credentials(token)\n",
    "\n",
    "        bq_client = bigquery.Client(project=project_id)\n",
    "        if use_local_credential:\n",
    "            bq_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "        return bq_client\n",
    "\n",
    "    client = get_gcp_bqclient(project_id)\n",
    "    \n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "\n",
    "    # Change dataset / table + sp table name to version in bi-layer\n",
    "    query =\\\n",
    "        f'''\n",
    "            DECLARE score_date DATE DEFAULT \"{score_date}\";\n",
    "            DECLARE promo_expiry_start DATE DEFAULT \"{promo_expiry_start}\";\n",
    "            DECLARE promo_expiry_end DATE DEFAULT \"{promo_expiry_end}\";\n",
    "            DECLARE start_date DATE DEFAULT \"{v_start_date}\";\n",
    "            DECLARE end_date DATE DEFAULT \"{v_end_date}\";\n",
    "        \n",
    "            -- Change dataset / sp name to the version in the bi_layer\n",
    "            CALL {dataset_id}.bq_sp_telus_rewards_pipeline_dataset(score_date, promo_expiry_start, promo_expiry_end, start_date, end_date);\n",
    "\n",
    "            SELECT\n",
    "                *\n",
    "            FROM {dataset_id}.INFORMATION_SCHEMA.PARTITIONS\n",
    "            WHERE table_name='bq_telus_rewards_pipeline_dataset'\n",
    "            \n",
    "        '''\n",
    "    \n",
    "    df = client.query(query, job_config=job_config).to_dataframe()\n",
    "    logging.info(df.to_string())\n",
    "    \n",
    "    logging.info(f\"Loaded {df.total_rows[0]} rows into \\\n",
    "             {df.table_catalog[0]}.{df.table_schema[0]}.{df.table_name[0]} on \\\n",
    "             {datetime.strftime((df.last_modified_time[0]), '%Y-%m-%d %H:%M:%S') } !\")\n",
    "    \n",
    "    ######################################## Save column list_##########################\n",
    "    query =\\\n",
    "        f'''\n",
    "           SELECT\n",
    "                *\n",
    "            FROM {dataset_id}.bq_telus_rewards_pipeline_dataset\n",
    "\n",
    "        '''\n",
    "    \n",
    "    df = client.query(query, job_config=job_config).to_dataframe()\n",
    "    \n",
    "    col_list = list([col for col in df.columns])\n",
    "    return (col_list,)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41752093-5734-483b-9b3c-ead15cdb8a23",
   "metadata": {},
   "source": [
    "### preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b97727e-c4a5-4784-8bbe-b9e9aaddb9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(\n",
    "        pipeline_dataset: str, \n",
    "        save_data_path: str,\n",
    "        project_id: str,\n",
    "        dataset_id: str\n",
    "):\n",
    "    from google.cloud import bigquery\n",
    "    import pandas as pd\n",
    "    import gc\n",
    "    import time\n",
    "\n",
    "    # CREDENTIALS = google.oauth2.credentials.Credentials(token) # get credentials from token\n",
    "    \n",
    "    def get_gcp_bqclient(project_id, use_local_credential=True):\n",
    "        token = os.popen('gcloud auth print-access-token').read()\n",
    "        token = re.sub(f'\\n$', '', token)\n",
    "        credentials = google.oauth2.credentials.Credentials(token)\n",
    "\n",
    "        bq_client = bigquery.Client(project=project_id)\n",
    "        if use_local_credential:\n",
    "            bq_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "        return bq_client\n",
    "\n",
    "    client = get_gcp_bqclient(project_id)\n",
    "    \n",
    "    # pipeline_dataset \n",
    "    pipeline_dataset_name = f\"{project_id}.{dataset_id}.{pipeline_dataset}\" \n",
    "    build_df_pipeline_dataset = f'SELECT * FROM `{pipeline_dataset_name}`'\n",
    "    df_pipeline_dataset = client.query(build_df_pipeline_dataset).to_dataframe()\n",
    "    df_pipeline_dataset = df_pipeline_dataset.set_index('ban') \n",
    "\n",
    "    # demo columns\n",
    "    df_pipeline_dataset['demo_urban_flag'] = df_pipeline_dataset.demo_sgname.str.lower().str.contains('urban').fillna(0).astype(int)\n",
    "    df_pipeline_dataset['demo_rural_flag'] = df_pipeline_dataset.demo_sgname.str.lower().str.contains('rural').fillna(0).astype(int)\n",
    "    df_pipeline_dataset['demo_family_flag'] = df_pipeline_dataset.demo_lsname.str.lower().str.contains('families').fillna(0).astype(int)\n",
    "\n",
    "    df_income_dummies = pd.get_dummies(df_pipeline_dataset[['demo_lsname']]) \n",
    "    df_income_dummies.columns = df_income_dummies.columns.str.replace('&', 'and')\n",
    "    df_income_dummies.columns = df_income_dummies.columns.str.replace(' ', '_')\n",
    "\n",
    "    df_pipeline_dataset.drop(columns=['demo_sgname', 'demo_lsname'], axis=1, inplace=True)\n",
    "\n",
    "    df_pipeline_dataset = df_pipeline_dataset.join(df_income_dummies)\n",
    "\n",
    "    df_join = df_pipeline_dataset.copy()\n",
    "\n",
    "    #column name clean-up\n",
    "    df_join.columns = df_join.columns.str.replace(' ', '_')\n",
    "    df_join.columns = df_join.columns.str.replace('-', '_')\n",
    "\n",
    "    #df_final\n",
    "    df_final = df_join.copy()\n",
    "    del df_join\n",
    "    gc.collect()\n",
    "    print('......df_final done')\n",
    "\n",
    "    for f in df_final.columns:\n",
    "        df_final[f] = list(df_final[f])\n",
    "\n",
    "    df_final.to_csv(save_data_path, index=True, compression='gzip') \n",
    "    del df_final\n",
    "    gc.collect()\n",
    "    print(f'......csv saved in {save_data_path}')\n",
    "    time.sleep(120)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569d03c6-53cf-4d9d-a45e-c831a84a72af",
   "metadata": {},
   "source": [
    "### train and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b32558-de04-4653-ac4d-edc62d5bbc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model(\n",
    "            file_bucket: str,\n",
    "            service_type: str,\n",
    "            score_date_dash: str,\n",
    "            score_date_val_dash: str,\n",
    "            project_id: str,\n",
    "            dataset_id: str,\n",
    "            # metrics: Output[Metrics],\n",
    "            # metricsc: Output[ClassificationMetrics]\n",
    "):\n",
    "\n",
    "    import gc\n",
    "    import time\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    from google.cloud import storage\n",
    "    from google.cloud import bigquery\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    def get_lift(prob, y_test, q):\n",
    "        result = pd.DataFrame(columns=['Prob', 'Redemption'])\n",
    "        result['Prob'] = prob\n",
    "        result['Redemption'] = y_test\n",
    "        result['Decile'] = pd.qcut(result['Prob'], q, labels=[i for i in range(q, 0, -1)])\n",
    "        add = pd.DataFrame(result.groupby('Decile')['Redemption'].mean()).reset_index()\n",
    "        add.columns = ['Decile', 'avg_real_redemption_rate']\n",
    "        result = result.merge(add, on='Decile', how='left')\n",
    "        result.sort_values('Decile', ascending=True, inplace=True)\n",
    "        lg = pd.DataFrame(result.groupby('Decile')['Prob'].mean()).reset_index()\n",
    "        lg.columns = ['Decile', 'avg_model_pred_redemption_rate']\n",
    "        lg.sort_values('Decile', ascending=False, inplace=True)\n",
    "        lg['avg_redemption_rate_total'] = result['Redemption'].mean()\n",
    "        lg = lg.merge(add, on='Decile', how='left')\n",
    "        lg['lift'] = lg['avg_real_redemption_rate'] / lg['avg_redemption_rate_total']\n",
    "\n",
    "        return lg    \n",
    "    \n",
    "    df_train = pd.read_csv('gs://{}/{}_train.csv.gz'.format(file_bucket, service_type),\n",
    "                           compression='gzip')  \n",
    "    df_test = pd.read_csv('gs://{}/{}_validation.csv.gz'.format(file_bucket, service_type),  \n",
    "                          compression='gzip')\n",
    "\n",
    "    #set up df_train\n",
    "    def get_gcp_bqclient(project_id, use_local_credential=True):\n",
    "        token = os.popen('gcloud auth print-access-token').read()\n",
    "        token = re.sub(f'\\n$', '', token)\n",
    "        credentials = google.oauth2.credentials.Credentials(token)\n",
    "\n",
    "        bq_client = bigquery.Client(project=project_id)\n",
    "        if use_local_credential:\n",
    "            bq_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "        return bq_client\n",
    "\n",
    "    client = get_gcp_bqclient(project_id)\n",
    "    sql_train = ''' SELECT * FROM `{}.{}.bq_telus_rwrd_redemption_targets` '''.format(project_id, dataset_id) \n",
    "    df_target_train = client.query(sql_train).to_dataframe()\n",
    "    df_target_train = df_target_train.loc[\n",
    "        df_target_train['YEAR_MONTH'] == '-'.join(score_date_dash.split('-')[:2])]  # score_date_dash = '2022-08-31'\n",
    "    df_target_train = df_target_train.loc[df_target_train['YEAR_MONTH'] == '2022-Q3']  # score_date_dash = '2022-08-31'\n",
    "    df_target_train['ban'] = df_target_train['ban'].astype('int64')\n",
    "    df_target_train = df_target_train.groupby('ban').tail(1)\n",
    "    df_train = df_train.merge(df_target_train[['ban', 'target_ind']], on='ban', how='left')\n",
    "    df_train.rename(columns={'target_ind': 'target'}, inplace=True)\n",
    "    # df_train.dropna(subset=['target'], inplace=True)\n",
    "    df_train.fillna(0, inplace=True)\n",
    "    df_train['target'] = df_train['target'].astype(int)\n",
    "    print(df_train.shape)\n",
    "\n",
    "    #set up df_test\n",
    "    sql_test = ''' SELECT * FROM `{}.{}.bq_telus_rwrd_redemption_targets` '''.format(project_id, dataset_id) \n",
    "    df_target_test = client.query(sql_test).to_dataframe()\n",
    "    # df_target_test = df_target_test.loc[\n",
    "    #     df_target_test['YEAR_MONTH'] == '-'.join(score_date_val_dash.split('-')[:2])]  # score_date_dash = '2022-09-30'\n",
    "    df_target_test = df_target_test.loc[df_target_test['YEAR_MONTH'] == '2023-Q1']  # score_date_dash = '2022-08-31'\n",
    "    df_target_test['ban'] = df_target_test['ban'].astype('int64')\n",
    "    df_target_test = df_target_test.groupby('ban').tail(1)\n",
    "    df_test = df_test.merge(df_target_test[['ban', 'target_ind']], on='ban', how='left')\n",
    "    df_test.rename(columns={'target_ind': 'target'}, inplace=True)\n",
    "    # df_test.dropna(subset=['target'], inplace=True)\n",
    "    df_test.fillna(0, inplace=True) \n",
    "    df_test['target'] = df_test['target'].astype(int)\n",
    "    print(df_test.shape)\n",
    "\n",
    "    #set up features (list)\n",
    "    cols_1 = df_train.columns.values\n",
    "    cols_2 = df_test.columns.values\n",
    "    cols = set(cols_1).intersection(set(cols_2))\n",
    "    features = [f for f in cols if f not in ['ban', 'target']]\n",
    "\n",
    "    #train test split\n",
    "    df_train, df_val = train_test_split(df_train, shuffle=True, test_size=0.3, random_state=42,\n",
    "                                        stratify=df_train['target']\n",
    "                                        )\n",
    "\n",
    "    ban_train = df_train['ban']\n",
    "    X_train = df_train[features]\n",
    "    y_train = np.squeeze(df_train['target'].values)\n",
    "\n",
    "    ban_val = df_val['ban']\n",
    "    X_val = df_val[features]\n",
    "    y_val = np.squeeze(df_val['target'].values)\n",
    "\n",
    "    ban_test = df_test['ban']\n",
    "    X_test = df_test[features]\n",
    "    y_test = np.squeeze(df_test['target'].values)\n",
    "\n",
    "    del df_train, df_val, df_test\n",
    "    gc.collect()\n",
    "\n",
    "    # build model and fit in training data\n",
    "    import xgboost as xgb\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=100,\n",
    "        max_depth=8,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective='binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1\n",
    "        # seed=27\n",
    "    )\n",
    "\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    print('xgb training done')\n",
    "\n",
    "    from sklearn.preprocessing import normalize\n",
    "\n",
    "    #predictions on X_val\n",
    "    y_pred = xgb_model.predict_proba(X_val, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "    y_pred_label = (y_pred > 0.5).astype(int)\n",
    "    auc = roc_auc_score(y_val, y_pred_label)\n",
    "    metrics.log_metric(\"AUC\", auc)\n",
    "\n",
    "    pred_prb = xgb_model.predict_proba(X_test, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "    lg = get_lift(pred_prb, y_test, 10)\n",
    "\n",
    "    # save the model in GCS\n",
    "    from datetime import datetime\n",
    "    models_dict = {}\n",
    "    create_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    models_dict['create_time'] = create_time\n",
    "    models_dict['model'] = xgb_model\n",
    "    models_dict['features'] = features\n",
    "    lg.to_csv('gs://{}/lift_on_scoring_data_{}.csv'.format(file_bucket, create_time, index=False))\n",
    "\n",
    "    with open('model_dict.pkl', 'wb') as handle:\n",
    "        pickle.dump(models_dict, handle)\n",
    "    handle.close()\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(file_bucket)\n",
    "\n",
    "    MODEL_PATH = '{}_xgb_models/'.format(service_type)\n",
    "    blob = bucket.blob(MODEL_PATH)\n",
    "    if not blob.exists(storage_client):\n",
    "        blob.upload_from_string('')\n",
    "\n",
    "    model_name_onbkt = '{}{}_models_xgb_{}'.format(MODEL_PATH, service_type, models_dict['create_time'])\n",
    "    blob = bucket.blob(model_name_onbkt)\n",
    "    blob.upload_from_filename('model_dict.pkl')\n",
    "\n",
    "    print(f\"....model loaded to GCS done at {str(create_time)}\")\n",
    "\n",
    "    from sklearn.preprocessing import normalize\n",
    "\n",
    "    #predictions on X_test\n",
    "    pred_prb = xgb_model.predict_proba(X_test, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "    pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "    #join ban_test, X_test, y_test and pred_prb and print to csv\n",
    "    #CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "    q=10\n",
    "    df_ban_test = ban_test.to_frame()\n",
    "    df_test_exp = df_ban_test.join(X_test) \n",
    "    df_test_exp['y_test'] = y_test\n",
    "    df_test_exp['y_pred_proba'] = pred_prb\n",
    "    df_test_exp['y_pred'] = (df_test_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "    df_test_exp['decile'] = pd.qcut(df_test_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "    lg = get_lift(pred_prb, y_test, q)\n",
    "\n",
    "    df_test_exp.to_csv('gs://{}/df_test_exp.csv'.format(file_bucket, index=True))\n",
    "    print(\"....df_test_exp done\")\n",
    "\n",
    "    lg.to_csv('gs://{}/lift_on_scoring_data.csv'.format(file_bucket, index=False))\n",
    "    print(\"....lift_to_csv done\")\n",
    "    \n",
    "\n",
    "    time.sleep(120)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4b75f5-b748-4be9-a390-3f0d08cba6cc",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f3bb66-183a-4668-8263-ab0a9a963cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pipeline(\n",
    "        project_id: str = PROJECT_ID,\n",
    "        region: str = REGION,\n",
    "        resource_bucket: str = RESOURCE_BUCKET, \n",
    "        file_bucket: str = FILE_BUCKET\n",
    "    ):\n",
    "    \n",
    "    # ----- create training set --------\n",
    "    bq_create_training_dataset_op = bq_create_dataset(score_date=SCORE_DATE_DASH,\n",
    "                          score_date_delta=SCORE_DATE_DELTA,\n",
    "                          project_id=PROJECT_ID,\n",
    "                          dataset_id=DATASET_ID,\n",
    "                          region=REGION,\n",
    "                          promo_expiry_start=PROMO_EXPIRY_START, \n",
    "                          promo_expiry_end=PROMO_EXPIRY_END, \n",
    "                          v_start_date=SCORE_DATE_MINUS_6_MOS_DASH,\n",
    "                          v_end_date=SCORE_DATE_LAST_MONTH_END_DASH\n",
    "                          )\n",
    "    \n",
    "    # ----- preprocessing train data --------\n",
    "    preprocess_train_op = preprocess(\n",
    "        pipeline_dataset=TRAINING_DATASET_TABLE_NAME, \n",
    "        save_data_path='gs://{}/{}_train.csv.gz'.format(FILE_BUCKET, SERVICE_TYPE),\n",
    "        project_id=PROJECT_ID,\n",
    "        dataset_id=DATASET_ID\n",
    "    )\n",
    "    \n",
    "    # ----- create validation set --------\n",
    "    bq_create_validation_dataset_op = bq_create_dataset(score_date=SCORE_DATE_VAL_DASH,\n",
    "                          score_date_delta=SCORE_DATE_VAL_DELTA,\n",
    "                          project_id=PROJECT_ID,\n",
    "                          dataset_id=DATASET_ID,\n",
    "                          region=REGION,\n",
    "                          promo_expiry_start=PROMO_EXPIRY_START_VAL, \n",
    "                          promo_expiry_end=PROMO_EXPIRY_END_VAL, \n",
    "                          v_start_date=SCORE_DATE_VAL_MINUS_6_MOS_DASH,\n",
    "                          v_end_date=SCORE_DATE_VAL_LAST_MONTH_END_DASH\n",
    "                          )\n",
    "    \n",
    "    # ----- preprocessing validation data --------\n",
    "    preprocess_validation_op = preprocess(\n",
    "        pipeline_dataset=TRAINING_DATASET_TABLE_NAME, \n",
    "        save_data_path='gs://{}/{}_validation.csv.gz'.format(FILE_BUCKET, SERVICE_TYPE),\n",
    "        project_id=PROJECT_ID,\n",
    "        dataset_id=DATASET_ID\n",
    "    )\n",
    "    \n",
    "    train_and_save_model_op = train_and_save_model(file_bucket=FILE_BUCKET,\n",
    "                                                   service_type=SERVICE_TYPE,\n",
    "                                                   score_date_dash=SCORE_DATE_DASH,\n",
    "                                                   score_date_val_dash=SCORE_DATE_VAL_DASH,\n",
    "                                                   project_id=PROJECT_ID,\n",
    "                                                   dataset_id=DATASET_ID,\n",
    "                                                   )\n",
    "\n",
    "    bq_create_training_dataset_op\n",
    "    preprocess_train_op\n",
    "    \n",
    "    bq_create_validation_dataset_op\n",
    "    preprocess_validation_op\n",
    "    \n",
    "    train_and_save_model_op\n",
    "\n",
    "pipeline(project_id=PROJECT_ID, region=REGION, resource_bucket=RESOURCE_BUCKET, file_bucket=FILE_BUCKET) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a98817-45be-4325-9fdd-f6a97dfd6cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62417c55-1554-41d3-9452-14460de17362",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import gc\n",
    "# import time\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import pickle\n",
    "# from google.cloud import storage\n",
    "# from google.cloud import bigquery\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# def get_lift(prob, y_test, q):\n",
    "#     result = pd.DataFrame(columns=['Prob', 'Redemption'])\n",
    "#     result['Prob'] = prob\n",
    "#     result['Redemption'] = y_test\n",
    "#     result['Decile'] = pd.qcut(result['Prob'], q, labels=[i for i in range(q, 0, -1)])\n",
    "#     add = pd.DataFrame(result.groupby('Decile')['Redemption'].mean()).reset_index()\n",
    "#     add.columns = ['Decile', 'avg_real_redemption_rate']\n",
    "#     result = result.merge(add, on='Decile', how='left')\n",
    "#     result.sort_values('Decile', ascending=True, inplace=True)\n",
    "#     lg = pd.DataFrame(result.groupby('Decile')['Prob'].mean()).reset_index()\n",
    "#     lg.columns = ['Decile', 'avg_model_pred_redemption_rate']\n",
    "#     lg.sort_values('Decile', ascending=False, inplace=True)\n",
    "#     lg['avg_redemption_rate_total'] = result['Redemption'].mean()\n",
    "#     lg = lg.merge(add, on='Decile', how='left')\n",
    "#     lg['lift'] = lg['avg_real_redemption_rate'] / lg['avg_redemption_rate_total']\n",
    "\n",
    "#     return lg    \n",
    "\n",
    "# df_train = pd.read_csv('gs://{}/{}_train.csv.gz'.format(file_bucket, service_type),\n",
    "#                        compression='gzip')  \n",
    "# df_test = pd.read_csv('gs://{}/{}_validation.csv.gz'.format(file_bucket, service_type),  \n",
    "#                       compression='gzip')\n",
    "\n",
    "# #set up df_train\n",
    "# def get_gcp_bqclient(project_id, use_local_credential=True):\n",
    "#     token = os.popen('gcloud auth print-access-token').read()\n",
    "#     token = re.sub(f'\\n$', '', token)\n",
    "#     credentials = google.oauth2.credentials.Credentials(token)\n",
    "\n",
    "#     bq_client = bigquery.Client(project=project_id)\n",
    "#     if use_local_credential:\n",
    "#         bq_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "#     return bq_client\n",
    "\n",
    "# client = get_gcp_bqclient(project_id)\n",
    "# sql_train = ''' SELECT * FROM `{}.{}.bq_telus_rwrd_redemption_targets` '''.format(project_id, dataset_id) \n",
    "# df_target_train = client.query(sql_train).to_dataframe()\n",
    "# df_target_train = df_target_train.loc[\n",
    "#     df_target_train['YEAR_MONTH'] == '-'.join(score_date_dash.split('-')[:2])]  # score_date_dash = '2022-08-31'\n",
    "# df_target_train['ban'] = df_target_train['ban'].astype('int64')\n",
    "# df_target_train = df_target_train.groupby('ban').tail(1)\n",
    "# df_train = df_train.merge(df_target_train[['ban', 'target_ind']], on='ban', how='left')\n",
    "# df_train.rename(columns={'target_ind': 'target'}, inplace=True)\n",
    "# # df_train.dropna(subset=['target'], inplace=True)\n",
    "# df_train.fillna(0, inplace=True)\n",
    "# df_train['target'] = df_train['target'].astype(int)\n",
    "# print(df_train.shape)\n",
    "\n",
    "# #set up df_test\n",
    "# sql_test = ''' SELECT * FROM `{}.{}.bq_telus_rwrd_redemption_targets` '''.format(project_id, dataset_id) \n",
    "# df_target_test = client.query(sql_test).to_dataframe()\n",
    "# df_target_test = df_target_test.loc[\n",
    "#     df_target_test['YEAR_MONTH'] == '-'.join(score_date_val_dash.split('-')[:2])]  # score_date_dash = '2022-09-30'\n",
    "# df_target_test['ban'] = df_target_test['ban'].astype('int64')\n",
    "# df_target_test = df_target_test.groupby('ban').tail(1)\n",
    "# df_test = df_test.merge(df_target_test[['ban', 'target_ind']], on='ban', how='left')\n",
    "# df_test.rename(columns={'target_ind': 'target'}, inplace=True)\n",
    "# # df_test.dropna(subset=['target'], inplace=True)\n",
    "# df_test.fillna(0, inplace=True) \n",
    "# df_test['target'] = df_test['target'].astype(int)\n",
    "# print(df_test.shape)\n",
    "\n",
    "# #set up features (list)\n",
    "# cols_1 = df_train.columns.values\n",
    "# cols_2 = df_test.columns.values\n",
    "# cols = set(cols_1).intersection(set(cols_2))\n",
    "# features = [f for f in cols if f not in ['ban', 'target']]\n",
    "\n",
    "# #train test split\n",
    "# df_train, df_val = train_test_split(df_train, shuffle=True, test_size=0.3, random_state=42,\n",
    "#                                     stratify=df_train['target']\n",
    "#                                     )\n",
    "\n",
    "# ban_train = df_train['ban']\n",
    "# X_train = df_train[features]\n",
    "# y_train = np.squeeze(df_train['target'].values)\n",
    "\n",
    "# ban_val = df_val['ban']\n",
    "# X_val = df_val[features]\n",
    "# y_val = np.squeeze(df_val['target'].values)\n",
    "\n",
    "# ban_test = df_test['ban']\n",
    "# X_test = df_test[features]\n",
    "# y_test = np.squeeze(df_test['target'].values)\n",
    "\n",
    "# del df_train, df_val, df_test\n",
    "# gc.collect()\n",
    "\n",
    "# # build model and fit in training data\n",
    "# import xgboost as xgb\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# xgb_model = xgb.XGBClassifier(\n",
    "#     learning_rate=0.01,\n",
    "#     n_estimators=100,\n",
    "#     max_depth=8,\n",
    "#     min_child_weight=1,\n",
    "#     gamma=0,\n",
    "#     subsample=0.8,\n",
    "#     colsample_bytree=0.8,\n",
    "#     objective='binary:logistic',\n",
    "#     nthread=4,\n",
    "#     scale_pos_weight=1\n",
    "#     # seed=27\n",
    "# )\n",
    "\n",
    "# xgb_model.fit(X_train, y_train)\n",
    "# print('xgb training done')\n",
    "\n",
    "# from sklearn.preprocessing import normalize\n",
    "\n",
    "# #predictions on X_val\n",
    "# y_pred = xgb_model.predict_proba(X_val, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "# y_pred_label = (y_pred > 0.5).astype(int)\n",
    "# auc = roc_auc_score(y_val, y_pred_label)\n",
    "# metrics.log_metric(\"AUC\", auc)\n",
    "\n",
    "# pred_prb = xgb_model.predict_proba(X_test, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "# lg = get_lift(pred_prb, y_test, 10)\n",
    "\n",
    "# # save the model in GCS\n",
    "# from datetime import datetime\n",
    "# models_dict = {}\n",
    "# create_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "# models_dict['create_time'] = create_time\n",
    "# models_dict['model'] = xgb_model\n",
    "# models_dict['features'] = features\n",
    "# lg.to_csv('gs://{}/lift_on_scoring_data_{}.csv'.format(file_bucket, create_time, index=False))\n",
    "\n",
    "# with open('model_dict.pkl', 'wb') as handle:\n",
    "#     pickle.dump(models_dict, handle)\n",
    "# handle.close()\n",
    "\n",
    "# storage_client = storage.Client()\n",
    "# bucket = storage_client.get_bucket(file_bucket)\n",
    "\n",
    "# MODEL_PATH = '{}_xgb_models/'.format(service_type)\n",
    "# blob = bucket.blob(MODEL_PATH)\n",
    "# if not blob.exists(storage_client):\n",
    "#     blob.upload_from_string('')\n",
    "\n",
    "# model_name_onbkt = '{}{}_models_xgb_{}'.format(MODEL_PATH, service_type, models_dict['create_time'])\n",
    "# blob = bucket.blob(model_name_onbkt)\n",
    "# blob.upload_from_filename('model_dict.pkl')\n",
    "\n",
    "# print(f\"....model loaded to GCS done at {str(create_time)}\")\n",
    "\n",
    "# time.sleep(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bc9e8a-e24a-4e9a-a141-d1c99d72d472",
   "metadata": {},
   "source": [
    "### make predictions on X_test set, assign deciles to the predicted values, and save in df_test_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb1a688-4722-4e3f-9a78-3f7fc558a114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import normalize\n",
    "\n",
    "# #predictions on X_test\n",
    "# pred_prb = xgb_model.predict_proba(X_test, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "# pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "# #join ban_test, X_test, y_test and pred_prb and print to csv\n",
    "# #CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "# q=10\n",
    "# df_ban_test = ban_test.to_frame()\n",
    "# df_test_exp = df_ban_test.join(X_test) \n",
    "# df_test_exp['y_test'] = y_test\n",
    "# df_test_exp['y_pred_proba'] = pred_prb\n",
    "# df_test_exp['y_pred'] = (df_test_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "# df_test_exp['decile'] = pd.qcut(df_test_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "# lg = get_lift(pred_prb, y_test, q)\n",
    "\n",
    "# df_test_exp.to_csv('gs://{}/df_test_exp.csv'.format(file_bucket, index=True))\n",
    "# print(\"....df_test_exp done\")\n",
    "\n",
    "# lg.to_csv('gs://{}/lift_on_scoring_data.csv'.format(file_bucket, index=False))\n",
    "# print(\"....lift_to_csv done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b8e831-26e7-423d-afb4-7007e5dfc328",
   "metadata": {},
   "source": [
    "### export df_test_exp and lift scores to gcs bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c857276b-1f4c-418a-a2a6-de6229115b14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
