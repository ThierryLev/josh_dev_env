name: Nba ffh offer ranking
inputs:
- {name: project_id, type: String}
- {name: dataset_id, type: String}
- {name: table_id, type: String}
- {name: file_bucket, type: String}
- {name: stack_name, type: String}
- {name: token, type: String}
implementation:
  container:
    image: northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing\
      \ import *\n\ndef nba_ffh_offer_ranking(project_id: str\n                  \
      \    , dataset_id: str\n                      , table_id: str\n            \
      \          , file_bucket: str\n                      , stack_name: str\n   \
      \                   , token: str\n                      ):\n\n    from google.cloud\
      \ import bigquery\n    import logging \n    from datetime import datetime\n\n\
      \    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\
      \n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n\
      \    job_config = bigquery.QueryJobConfig()\n\n#     #### For prod \n#     client\
      \ = bigquery.Client(project=project_id)\n#     job_config = bigquery.QueryJobConfig()\n\
      \n    # Change dataset / table + sp table name to version in bi-layer\n    query\
      \ =\\\n        f'''        \n            -- Change dataset / sp name to the\
      \ version in the bi_layer\n\n            CALL {dataset_id}.bq_sp_nba_ffh_model_scores_existing();\
      \ \n\n            CALL {dataset_id}.bq_sp_nba_ffh_offer_ranking_existing();\
      \ \n\n            CALL {dataset_id}.bq_sp_nba_ffh_model_scores_prospects();\
      \ \n\n            CALL {dataset_id}.bq_sp_nba_ffh_offer_ranking_prospects();\
      \ \n\n            CALL {dataset_id}.bq_sp_nba_ffh_offer_ranking_cat3(); \n\n\
      \            CALL {dataset_id}.bq_sp_nba_ffh_offer_ranking(); \n\n         \
      \   CALL {dataset_id}.bq_sp_nba_offer_targeting_dashboard()\n\n            SELECT\n\
      \                *\n            FROM {dataset_id}.INFORMATION_SCHEMA.PARTITIONS\n\
      \            WHERE table_name='nba_ffh_offer_ranking'\n        '''\n\n    df\
      \ = client.query(query, job_config=job_config).to_dataframe()\n    logging.info(df.to_string())\n\
      \n    logging.info(f\"Loaded {df.total_rows[0]} rows into \\\n             {df.table_catalog[0]}.{df.table_schema[0]}.{df.table_name[0]}\
      \ on \\\n             {datetime.strftime((df.last_modified_time[0]), '%Y-%m-%d\
      \ %H:%M:%S') } !\")\n\n    query2 =\\\n        f''' \n            SELECT * FROM\
      \ {dataset_id}.nba_ffh_offer_ranking\n        '''\n\n    df2 = client.query(query2,\
      \ job_config=job_config).to_dataframe() \n\n    df2.to_csv(f'gs://{file_bucket}/{stack_name}/{table_id}.csv')\n\
      \n"
    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - nba_ffh_offer_ranking
