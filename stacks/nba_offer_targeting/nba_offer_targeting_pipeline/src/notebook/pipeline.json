{
  "pipelineSpec": {
    "components": {
      "comp-bq-create-dataset": {
        "executorLabel": "exec-bq-create-dataset",
        "inputDefinitions": {
          "parameters": {
            "dataset_id": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "token": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-bq-export-to-bq": {
        "executorLabel": "exec-bq-export-to-bq",
        "inputDefinitions": {
          "parameters": {
            "casa_data_path": {
              "type": "STRING"
            },
            "dataset_id": {
              "type": "STRING"
            },
            "digital_1p_data_path": {
              "type": "STRING"
            },
            "digital_2p_data_path": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "save_data_path": {
              "type": "STRING"
            },
            "table_id": {
              "type": "STRING"
            },
            "temp_table": {
              "type": "STRING"
            },
            "token": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-bq-import-tbl-to-df": {
        "executorLabel": "exec-bq-import-tbl-to-df",
        "inputDefinitions": {
          "parameters": {
            "dataset_id": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "save_data_path": {
              "type": "STRING"
            },
            "table_id": {
              "type": "STRING"
            },
            "token": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "parameters": {
            "col_list": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-bq-import-tbl-to-df-2": {
        "executorLabel": "exec-bq-import-tbl-to-df-2",
        "inputDefinitions": {
          "parameters": {
            "dataset_id": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "save_data_path": {
              "type": "STRING"
            },
            "table_id": {
              "type": "STRING"
            },
            "token": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "parameters": {
            "col_list": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-bq-import-tbl-to-df-3": {
        "executorLabel": "exec-bq-import-tbl-to-df-3",
        "inputDefinitions": {
          "parameters": {
            "dataset_id": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "save_data_path": {
              "type": "STRING"
            },
            "table_id": {
              "type": "STRING"
            },
            "token": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "parameters": {
            "col_list": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-bq-import-tbl-to-df-4": {
        "executorLabel": "exec-bq-import-tbl-to-df-4",
        "inputDefinitions": {
          "parameters": {
            "dataset_id": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "save_data_path": {
              "type": "STRING"
            },
            "table_id": {
              "type": "STRING"
            },
            "token": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "parameters": {
            "col_list": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-bq-import-tbl-to-df-5": {
        "executorLabel": "exec-bq-import-tbl-to-df-5",
        "inputDefinitions": {
          "parameters": {
            "dataset_id": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "save_data_path": {
              "type": "STRING"
            },
            "table_id": {
              "type": "STRING"
            },
            "token": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "parameters": {
            "col_list": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-bq-import-tbl-to-df-6": {
        "executorLabel": "exec-bq-import-tbl-to-df-6",
        "inputDefinitions": {
          "parameters": {
            "dataset_id": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "save_data_path": {
              "type": "STRING"
            },
            "table_id": {
              "type": "STRING"
            },
            "token": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "parameters": {
            "col_list": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-nba-ffh-offer-ranking": {
        "executorLabel": "exec-nba-ffh-offer-ranking",
        "inputDefinitions": {
          "parameters": {
            "dataset_id": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "token": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-offer-attachment-casa": {
        "executorLabel": "exec-offer-attachment-casa",
        "inputDefinitions": {
          "parameters": {
            "channel": {
              "type": "STRING"
            },
            "irpc_base_csv": {
              "type": "STRING"
            },
            "irpc_offer_plans_csv": {
              "type": "STRING"
            },
            "irpc_offer_prices_csv": {
              "type": "STRING"
            },
            "save_data_path": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-offer-attachment-digital": {
        "executorLabel": "exec-offer-attachment-digital",
        "inputDefinitions": {
          "parameters": {
            "channel": {
              "type": "STRING"
            },
            "irpc_base_csv": {
              "type": "STRING"
            },
            "irpc_offer_plans_csv": {
              "type": "STRING"
            },
            "irpc_offer_prices_csv": {
              "type": "STRING"
            },
            "save_data_path": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-offer-attachment-digital-2": {
        "executorLabel": "exec-offer-attachment-digital-2",
        "inputDefinitions": {
          "parameters": {
            "channel": {
              "type": "STRING"
            },
            "irpc_base_csv": {
              "type": "STRING"
            },
            "irpc_offer_plans_csv": {
              "type": "STRING"
            },
            "irpc_offer_prices_csv": {
              "type": "STRING"
            },
            "save_data_path": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-postprocess": {
        "executorLabel": "exec-postprocess",
        "inputDefinitions": {
          "parameters": {
            "base_type": {
              "type": "STRING"
            },
            "dataset_id": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "read_data_path": {
              "type": "STRING"
            },
            "save_data_path": {
              "type": "STRING"
            },
            "table_id": {
              "type": "STRING"
            },
            "token": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-postprocess-2": {
        "executorLabel": "exec-postprocess-2",
        "inputDefinitions": {
          "parameters": {
            "base_type": {
              "type": "STRING"
            },
            "dataset_id": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "read_data_path": {
              "type": "STRING"
            },
            "save_data_path": {
              "type": "STRING"
            },
            "table_id": {
              "type": "STRING"
            },
            "token": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-postprocess-3": {
        "executorLabel": "exec-postprocess-3",
        "inputDefinitions": {
          "parameters": {
            "base_type": {
              "type": "STRING"
            },
            "dataset_id": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "read_data_path": {
              "type": "STRING"
            },
            "save_data_path": {
              "type": "STRING"
            },
            "table_id": {
              "type": "STRING"
            },
            "token": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-reg-offers-base-cat3": {
        "executorLabel": "exec-reg-offers-base-cat3",
        "inputDefinitions": {
          "parameters": {
            "offer_parameter": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "qua_base": {
              "type": "STRING"
            },
            "token": {
              "type": "STRING"
            },
            "whsia_eligible_base": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-reg-offers-base-existing": {
        "executorLabel": "exec-reg-offers-base-existing",
        "inputDefinitions": {
          "parameters": {
            "offer_parameter": {
              "type": "STRING"
            },
            "prod_cd2remove": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "qua_base": {
              "type": "STRING"
            },
            "shs_professional_install": {
              "type": "STRING"
            },
            "token": {
              "type": "STRING"
            },
            "whsia_eligible_base": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-reg-offers-base-prospects": {
        "executorLabel": "exec-reg-offers-base-prospects",
        "inputDefinitions": {
          "parameters": {
            "offer_parameter": {
              "type": "STRING"
            },
            "prod_cd2remove": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "qua_base": {
              "type": "STRING"
            },
            "shs_professional_install": {
              "type": "STRING"
            },
            "token": {
              "type": "STRING"
            },
            "whsia_eligible_base": {
              "type": "STRING"
            }
          }
        }
      }
    },
    "deploymentSpec": {
      "executors": {
        "exec-bq-create-dataset": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "bq_create_dataset"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef bq_create_dataset(project_id: str\n                      , dataset_id: str\n                      , token: str\n                      ):\n\n    from google.cloud import bigquery\n    import logging \n    from datetime import datetime\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n#     #### For prod \n#     client = bigquery.Client(project=project_id)\n#     job_config = bigquery.QueryJobConfig()\n\n    # Change dataset / table + sp table name to version in bi-layer\n    query =\\\n        f'''        \n            -- Change dataset / sp name to the version in the bi_layer\n            CALL nba_offer_targeting.bq_sp_internet_payment(); \n\n            CALL nba_offer_targeting.bq_sp_irpc_digital_2p_base(); \n\n            CALL nba_offer_targeting.bq_sp_irpc_digital_1p_base();\n\n            CALL nba_offer_targeting.bq_sp_irpc_casa_base(); \n\n            SELECT\n                *\n            FROM {dataset_id}.INFORMATION_SCHEMA.PARTITIONS\n            WHERE table_name='bq_irpc_digital_1p_base'\n        '''\n\n    df = client.query(query, job_config=job_config).to_dataframe()\n    logging.info(df.to_string())\n\n    logging.info(f\"Loaded {df.total_rows[0]} rows into \\\n             {df.table_catalog[0]}.{df.table_schema[0]}.{df.table_name[0]} on \\\n             {datetime.strftime((df.last_modified_time[0]), '%Y-%m-%d %H:%M:%S') } !\")\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 8.0,
              "memoryLimit": 16.0
            }
          }
        },
        "exec-bq-export-to-bq": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "bq_export_to_bq"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef bq_export_to_bq(project_id: str\n              , dataset_id: str\n              , table_id: str\n              , temp_table: str\n              , digital_1p_data_path: str\n              , digital_2p_data_path: str\n              , casa_data_path: str\n              , save_data_path: str\n              , token: str\n              ): \n\n    import time\n\n    import pandas as pd \n    import numpy as np \n\n    from google.cloud import bigquery\n    import logging\n    import datetime as dt\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n#     #### For prod \n#     client = bigquery.Client(project=project_id)\n#     job_config = bigquery.QueryJobConfig()    \n\n    def if_tbl_exists(client, table_ref):\n        from google.cloud.exceptions import NotFound\n        try:\n            client.get_table(table_ref)\n            return True\n        except NotFound:\n            return False\n\n    # read bq_irpc_digital_1p_base_postprocess.csv\n    digital_1p_base = pd.read_csv(digital_1p_data_path, index_col=None)\n\n    # read bq_irpc_digital_2p_base_postprocess.csv\n    digital_2p_base = pd.read_csv(digital_2p_data_path, index_col=None)\n\n    # read bq_irpc_casa_base_postprocess.csv\n    casa_base = pd.read_csv(casa_data_path, index_col=None)\n\n    # concatenate all three files -- irpc_offers_assigned\n    dfs = [digital_1p_base, digital_2p_base, casa_base]\n\n    # Concatenate the DataFrames\n    irpc_offers_assigned = pd.concat(dfs, ignore_index=True)\n    irpc_offers_assigned.reset_index(inplace=False)\n\n    # write the final file to csv irpc_offers_assigned.csv\n    irpc_offers_assigned.to_csv(save_data_path, index=False)\n\n    # insert irpc_offers_assigned again to a bq table -- qua_base_hs \n    table_ref = f'{project_id}.{dataset_id}.{table_id}'\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    table = client.get_table(table_ref)\n    schema = table.schema\n\n    ll = []\n    for item in schema:\n        col = item.name\n        d_type = item.field_type\n        if 'float' in str(d_type).lower():\n            d_type = 'FLOAT64'\n        ll.append((col, d_type))\n\n        if 'integer' in str(d_type).lower():\n            irpc_offers_assigned[col] = irpc_offers_assigned[col].fillna(0).astype(int)\n        elif 'float' in str(d_type).lower():\n            irpc_offers_assigned[col] = irpc_offers_assigned[col].fillna(0.0).astype(float)\n        elif 'string' in str(d_type).lower():\n            irpc_offers_assigned[col] = irpc_offers_assigned[col].fillna('').astype(str)\n        elif 'timestamp' in str(d_type).lower(): \n            irpc_offers_assigned[col] = pd.to_datetime(irpc_offers_assigned[col], errors='coerce')\n        elif 'date' in str(d_type).lower():\n            irpc_offers_assigned[col] = pd.to_datetime(irpc_offers_assigned[col], errors='coerce').dt.date\n\n    table_ref = '{}.{}.{}'.format(project_id, dataset_id, temp_table)\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    if if_tbl_exists(client, table_ref):\n        client.delete_table(table_ref)\n    time.sleep(10)\n\n    client.create_table(table_ref)\n    config = bigquery.LoadJobConfig(schema=schema)\n    config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n    bq_table_instance = client.load_table_from_dataframe(irpc_offers_assigned, table_ref, job_config=config)\n    time.sleep(60)\n\n    # drop_sql = f\"\"\"delete from `{project_id}.{dataset_id}.{table_id}` where true\"\"\"  # .format(project_id, dataset_id, score_date_dash)\n    # client.query(drop_sql)\n\n    load_sql = f\"\"\"insert into `{project_id}.{dataset_id}.{table_id}`\n                  select * from `{project_id}.{dataset_id}.{temp_table}`\"\"\"\n    client.query(load_sql)\n    time.sleep(60)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 16.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-bq-import-tbl-to-df": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "bq_import_tbl_to_df"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef bq_import_tbl_to_df(project_id: str\n              , dataset_id: str\n              , table_id: str\n              , save_data_path: str\n              , token: str \n              ) -> NamedTuple(\"output\", [(\"col_list\", list)]):\n\n    from google.cloud import bigquery\n    import logging\n    from datetime import datetime\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n#     #### For prod \n#     client = bigquery.Client(project=project_id)\n#     job_config = bigquery.QueryJobConfig()\n\n    # Change dataset / table + sp table name to version in bi-layer\n    query =\\\n        f'''\n            SELECT * FROM `{project_id}.{dataset_id}.{table_id}`\n        '''\n\n    df = client.query(query, job_config=job_config).to_dataframe()\n\n    df.to_csv(save_data_path, index=False) \n\n    col_list = list([col for col in df.columns])\n\n    return (col_list,)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 8.0,
              "memoryLimit": 16.0
            }
          }
        },
        "exec-bq-import-tbl-to-df-2": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "bq_import_tbl_to_df"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef bq_import_tbl_to_df(project_id: str\n              , dataset_id: str\n              , table_id: str\n              , save_data_path: str\n              , token: str \n              ) -> NamedTuple(\"output\", [(\"col_list\", list)]):\n\n    from google.cloud import bigquery\n    import logging\n    from datetime import datetime\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n#     #### For prod \n#     client = bigquery.Client(project=project_id)\n#     job_config = bigquery.QueryJobConfig()\n\n    # Change dataset / table + sp table name to version in bi-layer\n    query =\\\n        f'''\n            SELECT * FROM `{project_id}.{dataset_id}.{table_id}`\n        '''\n\n    df = client.query(query, job_config=job_config).to_dataframe()\n\n    df.to_csv(save_data_path, index=False) \n\n    col_list = list([col for col in df.columns])\n\n    return (col_list,)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 8.0,
              "memoryLimit": 16.0
            }
          }
        },
        "exec-bq-import-tbl-to-df-3": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "bq_import_tbl_to_df"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef bq_import_tbl_to_df(project_id: str\n              , dataset_id: str\n              , table_id: str\n              , save_data_path: str\n              , token: str \n              ) -> NamedTuple(\"output\", [(\"col_list\", list)]):\n\n    from google.cloud import bigquery\n    import logging\n    from datetime import datetime\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n#     #### For prod \n#     client = bigquery.Client(project=project_id)\n#     job_config = bigquery.QueryJobConfig()\n\n    # Change dataset / table + sp table name to version in bi-layer\n    query =\\\n        f'''\n            SELECT * FROM `{project_id}.{dataset_id}.{table_id}`\n        '''\n\n    df = client.query(query, job_config=job_config).to_dataframe()\n\n    df.to_csv(save_data_path, index=False) \n\n    col_list = list([col for col in df.columns])\n\n    return (col_list,)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 8.0,
              "memoryLimit": 16.0
            }
          }
        },
        "exec-bq-import-tbl-to-df-4": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "bq_import_tbl_to_df"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef bq_import_tbl_to_df(project_id: str\n              , dataset_id: str\n              , table_id: str\n              , save_data_path: str\n              , token: str \n              ) -> NamedTuple(\"output\", [(\"col_list\", list)]):\n\n    from google.cloud import bigquery\n    import logging\n    from datetime import datetime\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n#     #### For prod \n#     client = bigquery.Client(project=project_id)\n#     job_config = bigquery.QueryJobConfig()\n\n    # Change dataset / table + sp table name to version in bi-layer\n    query =\\\n        f'''\n            SELECT * FROM `{project_id}.{dataset_id}.{table_id}`\n        '''\n\n    df = client.query(query, job_config=job_config).to_dataframe()\n\n    df.to_csv(save_data_path, index=False) \n\n    col_list = list([col for col in df.columns])\n\n    return (col_list,)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 8.0,
              "memoryLimit": 16.0
            }
          }
        },
        "exec-bq-import-tbl-to-df-5": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "bq_import_tbl_to_df"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef bq_import_tbl_to_df(project_id: str\n              , dataset_id: str\n              , table_id: str\n              , save_data_path: str\n              , token: str \n              ) -> NamedTuple(\"output\", [(\"col_list\", list)]):\n\n    from google.cloud import bigquery\n    import logging\n    from datetime import datetime\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n#     #### For prod \n#     client = bigquery.Client(project=project_id)\n#     job_config = bigquery.QueryJobConfig()\n\n    # Change dataset / table + sp table name to version in bi-layer\n    query =\\\n        f'''\n            SELECT * FROM `{project_id}.{dataset_id}.{table_id}`\n        '''\n\n    df = client.query(query, job_config=job_config).to_dataframe()\n\n    df.to_csv(save_data_path, index=False) \n\n    col_list = list([col for col in df.columns])\n\n    return (col_list,)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 8.0,
              "memoryLimit": 16.0
            }
          }
        },
        "exec-bq-import-tbl-to-df-6": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "bq_import_tbl_to_df"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef bq_import_tbl_to_df(project_id: str\n              , dataset_id: str\n              , table_id: str\n              , save_data_path: str\n              , token: str \n              ) -> NamedTuple(\"output\", [(\"col_list\", list)]):\n\n    from google.cloud import bigquery\n    import logging\n    from datetime import datetime\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n#     #### For prod \n#     client = bigquery.Client(project=project_id)\n#     job_config = bigquery.QueryJobConfig()\n\n    # Change dataset / table + sp table name to version in bi-layer\n    query =\\\n        f'''\n            SELECT * FROM `{project_id}.{dataset_id}.{table_id}`\n        '''\n\n    df = client.query(query, job_config=job_config).to_dataframe()\n\n    df.to_csv(save_data_path, index=False) \n\n    col_list = list([col for col in df.columns])\n\n    return (col_list,)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 8.0,
              "memoryLimit": 16.0
            }
          }
        },
        "exec-nba-ffh-offer-ranking": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "nba_ffh_offer_ranking"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef nba_ffh_offer_ranking(project_id: str\n                      , dataset_id: str\n                      , token: str\n                      ):\n\n    from google.cloud import bigquery\n    import logging \n    from datetime import datetime\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n#     #### For prod \n#     client = bigquery.Client(project=project_id)\n#     job_config = bigquery.QueryJobConfig()\n\n    # Change dataset / table + sp table name to version in bi-layer\n    query =\\\n        f'''        \n            -- Change dataset / sp name to the version in the bi_layer\n\n            CALL {dataset_id}.bq_sp_nba_ffh_model_scores_existing(); \n\n            CALL {dataset_id}.bq_sp_nba_ffh_offer_ranking_existing(); \n\n            CALL {dataset_id}.bq_sp_nba_ffh_model_scores_prospects(); \n\n            CALL {dataset_id}.bq_sp_nba_ffh_offer_ranking_prospects(); \n\n            CALL {dataset_id}.bq_sp_nba_ffh_offer_ranking_cat3(); \n\n            CALL {dataset_id}.bq_sp_nba_ffh_offer_ranking(); \n\n            SELECT\n                *\n            FROM {dataset_id}.INFORMATION_SCHEMA.PARTITIONS\n            WHERE table_name='nba_ffh_offer_ranking'\n        '''\n\n    df = client.query(query, job_config=job_config).to_dataframe()\n    logging.info(df.to_string())\n\n    logging.info(f\"Loaded {df.total_rows[0]} rows into \\\n             {df.table_catalog[0]}.{df.table_schema[0]}.{df.table_name[0]} on \\\n             {datetime.strftime((df.last_modified_time[0]), '%Y-%m-%d %H:%M:%S') } !\")\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 8.0,
              "memoryLimit": 16.0
            }
          }
        },
        "exec-offer-attachment-casa": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "offer_attachment_casa"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef offer_attachment_casa(irpc_base_csv: str\n                   , irpc_offer_plans_csv: str \n                   , irpc_offer_prices_csv: str\n                   , channel: str\n                   , save_data_path: str\n                  ): \n    import pandas as pd \n    import numpy as np \n\n    def convert_df_to_list_dict(df, \n                                channel: str = 'digital' # digital or casa\n                                ): \n\n        import re\n        import logging \n        from datetime import datetime\n\n        print(df.head())\n\n        # Change dataset / table + sp table name to version in bi-layer\n        if channel == 'digital': \n            df = df\n        elif channel == 'casa': \n            df = df.iloc[:4]\n        else: \n            print(\"a parameter 'channel' can only be either 'digital' or 'casa'\")\n\n        # create list_hsia_speed = [250, 500, 1000, 1500, 3000]\n        list_hsia_speed = df.columns[3:]\n\n        print(list_hsia_speed)\n\n        list_hsia_speed = [int(re.search(r'\\d+', speed).group()) for speed in list_hsia_speed]\n\n        # create dictionary of hsia_prices \n        # Convert DataFrame to a dictionary\n        dict_hsia_details = df.to_dict(orient='list')\n\n        return list_hsia_speed, dict_hsia_details\n\n    def find_casa_irpc_offers(list_hsia_speed: str, # list_hsia_speed = [250, 500, 1000, 1500, 3000] as of Feb 2024\n                             dict_hsia_plans_details: str, # e.g. internet_250: ['1P:Regular (Internet 250)', '1P:Tier 0 (Internet 250)', '1P:Tier 1 (Internet 250)']\n                             dict_hsia_prices_details: str, # e.g. internet_250: [105, 100, 95, 85, 75]\n                             row, \n                             offer_num: int\n                             ):\n\n        import pandas as pd\n        import numpy as np \n\n        cust_id, ban, lpds_id = row['cust_id'], row['bacct_num'], row['lpds_id']\n\n        if offer_num == 1: \n            provisioned_hs_speed_numeric, hs_max_speed_numeric, total_charges = row['provisioned_hs_speed_numeric'], row['hs_max_speed_numeric'], row['total_charges']\n        elif offer_num == 2: \n            provisioned_hs_speed_numeric, hs_max_speed_numeric, total_charges = row['hsia_speed1'], row['hs_max_speed_numeric1'], row['hsia_price1']\n        elif offer_num == 3: \n            provisioned_hs_speed_numeric, hs_max_speed_numeric, total_charges = row['provisioned_hs_speed_numeric'], row['hs_max_speed_numeric'], row['total_charges']\n\n        if provisioned_hs_speed_numeric is None and hs_max_speed_numeric is None and total_charges is None: \n            return [None, None, None, None] \n\n        ### 1. Find the smallest number in hsia_speed that is greater than provisioned_hs_speed_numeric\n        # exception: if the current hsia_speed >= 150 AND hsia_speed < 500, then change the value to 499 so that it bypasses 250 \n        ## Internet 150 customers should not be shown Internet 250 tier, as they are upsped in the backend to speeds of 300mbps ##\n        if provisioned_hs_speed_numeric >= 150 and provisioned_hs_speed_numeric < 500: \n            provisioned_hs_speed_numeric = 499\n\n        # if offer_3_ind == True: \n        # find an L4L offer - lowest speed tier possible at equal or higher than their current pay\n        # Lower speed tier than offer 1\n        # Can also be in-market rack rate\n\n        if offer_num == 3:\n\n            try: \n\n                hsia_speed = np.min([spd for spd in list_hsia_speed if spd == provisioned_hs_speed_numeric and spd <= hs_max_speed_numeric and not pd.isna(spd)])\n\n                list_hsia_price = dict_hsia_prices_details[f'internet_{hsia_speed}']\n\n                if len([price for price in list_hsia_price if price >= total_charges]) > 0:\n                    hsia_price = np.min([price for price in list_hsia_price if price > total_charges])\n\n                if hsia_price in list_hsia_price:\n                    plan_idx = list_hsia_price.index(hsia_price)\n\n                hsia_plan_name = dict_hsia_plans_details[f'internet_{hsia_speed}'][plan_idx]\n\n                return [hsia_speed, hs_max_speed_numeric, hsia_price, hsia_plan_name]\n\n            except IndexError:\n                provisioned_hs_speed_numeric, hs_max_speed_numeric, total_charges = row['hsia_speed2'], row['hs_max_speed_numeric2'], row['hsia_price2']\n\n            except ValueError: \n                provisioned_hs_speed_numeric, hs_max_speed_numeric, total_charges = row['hsia_speed2'], row['hs_max_speed_numeric2'], row['hsia_price2']\n\n            except UnboundLocalError: \n                provisioned_hs_speed_numeric, hs_max_speed_numeric, total_charges = row['hsia_speed2'], row['hs_max_speed_numeric2'], row['hsia_price2']\n\n        # store minimum hsia speed offer available greater than the current speed in 'hsia_speed'\n        # AND \n        # minimum speed offer available where the highest offer price in that speed is greater than or equal to 'total_charges'\n\n        # requirements:\n            # - list_hsia_speed\n            # - np.max([spd for spd in dict_hsia_prices_details[f'internet_{hsia_speed}'] if not pd.isna(spd)]) --> max offer price in the internet speed\n            # - compare max offer price vs total_charges \n            # - since internet_250 does not have offer tier equal to or greater than $125, we need to move on to the next speed, which is 500\n            # - since internet_500 does not have offer tier equal to or greater than $125, we need to again move on to the next speed, which is 1000\n            # - internet_1000 has an offer tier equal to or greater than $125, so hsia_speed = 1000\n\n        try: \n\n            hsia_speed = np.min([spd for spd in list_hsia_speed if spd > provisioned_hs_speed_numeric and spd <= hs_max_speed_numeric and not pd.isna(spd)])\n            max_offer_price = np.max([spd for spd in dict_hsia_prices_details[f'internet_{hsia_speed}'] if not pd.isna(spd)])\n\n            while max_offer_price < total_charges: \n                hsia_speed_idx = list_hsia_speed.index(hsia_speed)\n                hsia_speed = list_hsia_speed[hsia_speed_idx + 1]\n                max_offer_price = np.max([spd for spd in dict_hsia_prices_details[f'internet_{hsia_speed}'] if not pd.isna(spd)])\n\n        except IndexError:\n            pass\n\n        except ValueError: \n            return [None, None, None, None]\n\n        ### 2. Find the smallest number in dict_hsia_prices_details[hsia_speed] that is greater than total_charges --> 75\n\n        list_hsia_price = dict_hsia_prices_details[f'internet_{hsia_speed}']\n\n        if len([price for price in list_hsia_price if price >= total_charges]) > 0: \n\n            try: \n                hsia_price = np.min([price for price in list_hsia_price if price > total_charges])\n\n                # scenario when the same price DOES EXIST in the next speed offer (e.g. if internet_500, check internet_1000 for $95 offer ==> YES): \n                hsia_speed_idx = list_hsia_speed.index(hsia_speed)\n                next_hsia_speed = list_hsia_speed[hsia_speed_idx + 1]\n\n                if hsia_price in dict_hsia_prices_details[f'internet_{next_hsia_speed}'] and hsia_speed == provisioned_hs_speed_numeric: \n                    list_hsia_price = dict_hsia_prices_details[f'internet_{next_hsia_speed}']\n                    hsia_speed = next_hsia_speed \n\n            except IndexError: \n                return [None, None, None, None]\n\n            except UnboundLocalError: \n                return [None, None, None, None]\n\n            except ValueError: \n                return [None, None, None, None]\n\n            # scenario when the same price DOES NOT EXIST in the next speed offer (e.g. if internet_1000, check internet_1500 for $95 offer ==> NO): \n\n            if hsia_price in list_hsia_price:\n                plan_idx = list_hsia_price.index(hsia_price)    \n\n            ### 4. Call the plan name by hsia_plans[provisioned_hs_speed_numeric]==250][plan_idx==4] --> \"1P: Tier 3 (Internet 250)\"\n\n            hsia_plan_name = dict_hsia_plans_details[f'internet_{hsia_speed}'][plan_idx]\n\n            return [hsia_speed, hs_max_speed_numeric, hsia_price, hsia_plan_name] \n\n        else: \n\n            return [None, None, None, None]\n\n    # read the above 3 csv's (bq_irpc_digital_1p_base.csv, irpc_offer_1p_plans.csv, irpc_offer_prices.csv\n    # read bq_irpc_digital_1p_base and store in df\n    df_base = pd.read_csv(irpc_base_csv)\n    df_plans = pd.read_csv(irpc_offer_plans_csv)\n    df_prices = pd.read_csv(irpc_offer_prices_csv)\n\n    # convert irpc_offer_1p_plans and irpc_offer_prices to lists and dictionaries\n    # - list_hsia_speed\n    # - dict_hsia_details\n    list_hsia_speed, dict_hsia_plans_details = convert_df_to_list_dict(df_plans, channel)\n    list_hsia_speed, dict_hsia_prices_details = convert_df_to_list_dict(df_prices, channel)\n\n    offer_1_list, offer_2_list, offer_3_list = [] , [], [] \n\n    df_base[['hsia_speed1', 'hs_max_speed_numeric1', 'hsia_price1', 'promo_seg1']]  = df_base.apply(lambda row: pd.Series(find_casa_irpc_offers(list_hsia_speed, dict_hsia_plans_details, dict_hsia_prices_details, row, 1)), axis=1)\n    df_base[['hsia_speed2', 'hs_max_speed_numeric2', 'hsia_price2', 'promo_seg2']]  = df_base.apply(lambda row: pd.Series(find_casa_irpc_offers(list_hsia_speed, dict_hsia_plans_details, dict_hsia_prices_details, row, 2)), axis=1)\n    df_base[['hsia_speed3', 'hs_max_speed_numeric3', 'hsia_price3', 'promo_seg3']]  = df_base.apply(lambda row: pd.Series(find_casa_irpc_offers(list_hsia_speed, dict_hsia_plans_details, dict_hsia_prices_details, row, 3)), axis=1)\n\n    df_base = df_base[['cust_id', 'bacct_num', 'fms_address_id', 'lpds_id', 'candate', 'OPTIK_TV_IND', 'HSIA_IND', 'hs_max_speed_numeric', 'provisioned_hs_speed_numeric', \n             'rpp_hsia_end_dt', 'rpp_ttv_end_dt', 'total_charges', 'promo_seg1', 'promo_seg2', 'promo_seg3']] \n\n    df_base.to_csv(save_data_path)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 16.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-offer-attachment-digital": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "offer_attachment_digital"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef offer_attachment_digital(irpc_base_csv: str\n                   , irpc_offer_plans_csv: str \n                   , irpc_offer_prices_csv: str\n                   , channel: str\n                   , save_data_path: str\n                  ): \n    import pandas as pd \n    import numpy as np \n\n    def convert_df_to_list_dict(df, \n                                channel: str = 'digital' # digital or casa\n                                ): \n\n        import re\n        import logging \n        from datetime import datetime\n\n        print(df.head())\n\n        # Change dataset / table + sp table name to version in bi-layer\n        if channel == 'digital': \n            df = df\n        elif channel == 'casa': \n            df = df.iloc[:4]\n        else: \n            print(\"a parameter 'channel' can only be either 'digital' or 'casa'\")\n\n        # create list_hsia_speed = [250, 500, 1000, 1500, 3000]\n        list_hsia_speed = df.columns[3:]\n\n        print(list_hsia_speed)\n\n        list_hsia_speed = [int(re.search(r'\\d+', speed).group()) for speed in list_hsia_speed]\n\n        # create dictionary of hsia_prices \n        # Convert DataFrame to a dictionary\n        dict_hsia_details = df.to_dict(orient='list')\n\n        return list_hsia_speed, dict_hsia_details\n\n    def find_digital_irpc_offers(list_hsia_speed: str, # list_hsia_speed = [250, 500, 1000, 1500, 3000] as of Feb 2024\n                             dict_hsia_plans_details: str, # e.g. internet_250: ['1P:Regular (Internet 250)', '1P:Tier 0 (Internet 250)', '1P:Tier 1 (Internet 250)']\n                             dict_hsia_prices_details: str, # e.g. internet_250: [105, 100, 95, 85, 75]\n                             row, \n                             offer_num: int\n                             ):\n\n        import pandas as pd\n        import numpy as np \n\n        cust_id, ban, lpds_id = row['cust_id'], row['bacct_num'], row['lpds_id']\n\n        if offer_num == 1: \n            provisioned_hs_speed_numeric, hs_max_speed_numeric, total_charges = row['provisioned_hs_speed_numeric'], row['hs_max_speed_numeric'], row['total_charges']\n        elif offer_num == 2: \n            provisioned_hs_speed_numeric, hs_max_speed_numeric, total_charges = row['hsia_speed1'], row['hs_max_speed_numeric1'], row['hsia_price1']\n        elif offer_num == 3: \n            provisioned_hs_speed_numeric, hs_max_speed_numeric, total_charges = row['hsia_speed2'], row['hs_max_speed_numeric2'], row['hsia_price2']\n\n        if provisioned_hs_speed_numeric is None and hs_max_speed_numeric is None and total_charges is None: \n            return [None, None, None, None]\n\n        ### 1. Find the smallest number in hsia_speed that is greater than provisioned_hs_speed_numeric\n\n        # exception: if the current hsia_speed >= 150 AND hsia_speed < 500, then change the value to 499 so that it bypasses 250 \n        ## Internet 150 customers should not be shown Internet 250 tier, as they are upsped in the backend to speeds of 300mbps ##\n        if provisioned_hs_speed_numeric >= 150 and provisioned_hs_speed_numeric < 500: \n            provisioned_hs_speed_numeric = 499\n\n        # It doesn't make sense when hs_max_speed_numeric < provisioned_hs_speed_numeric. \n        # Update hs_max_speed_numeric to provisioned_hs_speed_numeric when it's the case. \n        if hs_max_speed_numeric < provisioned_hs_speed_numeric: \n            hs_max_speed_numeric = provisioned_hs_speed_numeric\n\n        # store minimum hsia speed offer available greater than (or equal to) the current speed in 'hsia_speed'\n        # AND \n        # minimum speed offer available where the highest offer price in that speed is greater than or equal to 'total_charges'\n\n        # requirements:\n            # - list_hsia_speed\n            # - np.max([spd for spd in dict_hsia_prices_details[f'internet_{hsia_speed}'] if not pd.isna(spd)]) --> max offer price in the internet speed\n            # - compare max offer price vs total_charges \n            # - since internet_250 does not have offer tier equal to or greater than $125, we need to move on to the next speed, which is 500\n            # - since internet_500 does not have offer tier equal to or greater than $125, we need to again move on to the next speed, which is 1000\n            # - internet_1000 has an offer tier equal to or greater than $125, so hsia_speed = 1000\n\n        try: \n            if offer_num == 1: \n                hsia_speed = np.min([spd for spd in list_hsia_speed if spd >= provisioned_hs_speed_numeric and spd <= hs_max_speed_numeric and not pd.isna(spd)]) # --> 250\n            else: \n                hsia_speed = np.min([spd for spd in list_hsia_speed if spd > provisioned_hs_speed_numeric and spd <= hs_max_speed_numeric and not pd.isna(spd)])\n\n            max_offer_price = np.max([spd for spd in dict_hsia_prices_details[f'internet_{hsia_speed}'] if not pd.isna(spd)])\n\n        except ValueError: \n            return [None, None, None, None]\n\n        try: \n            while max_offer_price < total_charges: \n                hsia_speed_idx = list_hsia_speed.index(hsia_speed)\n                hsia_speed = list_hsia_speed[hsia_speed_idx + 1]\n                max_offer_price = np.max([spd for spd in dict_hsia_prices_details[f'internet_{hsia_speed}'] if not pd.isna(spd)])\n\n        except IndexError: \n            print(f\"The customer {cust_id} {ban} {lpds_id} is currently paying > $145, thus not eligible for any offers\")\n\n        ### 2. Find the smallest number in dict_hsia_prices_details[hsia_speed] that is greater (or equal to) than total_charges --> 75\n\n        list_hsia_price = dict_hsia_prices_details[f'internet_{hsia_speed}']\n\n        if len([price for price in list_hsia_price if price >= total_charges]) > 0: \n\n            try: \n                if offer_num == 1: \n                    hsia_price = np.min([price for price in list_hsia_price if price >= total_charges])\n                else: \n                    hsia_price = np.min([price for price in list_hsia_price if price > total_charges])\n\n            except ValueError: \n                return [None, None, None, None]\n\n            try: \n                # scenario when the same price DOES EXIST in the next speed offer (e.g. if internet_500, check internet_1000 for $95 offer ==> YES): \n                hsia_speed_idx = list_hsia_speed.index(hsia_speed)\n                next_hsia_speed = list_hsia_speed[hsia_speed_idx + 1]\n\n                if hsia_price in dict_hsia_prices_details[f'internet_{next_hsia_speed}'] and hsia_speed == provisioned_hs_speed_numeric: \n                    list_hsia_price = dict_hsia_prices_details[f'internet_{next_hsia_speed}']\n                    hsia_speed = next_hsia_speed \n\n            except IndexError: \n                print(f\"For {cust_id} {ban} {lpds_id}, the hsia_speed {hsia_speed} is the fastest internet speed available.\")\n\n            except UnboundLocalError: \n                print(f\"For {cust_id} {ban} {lpds_id}, the hsia_speed {hsia_speed} is the fastest internet speed available.\")\n\n            # scenario when the same price DOES NOT EXIST in the next speed offer (e.g. if internet_1000, check internet_1500 for $95 offer ==> NO): \n\n            if hsia_price in list_hsia_price:\n                plan_idx = list_hsia_price.index(hsia_price)    \n\n            ### 4. Call the plan name by hsia_plans[provisioned_hs_speed_numeric]==250][plan_idx==4] --> \"1P: Tier 3 (Internet 250)\"\n\n            hsia_plan_name = dict_hsia_plans_details[f'internet_{hsia_speed}'][plan_idx]\n\n            return [hsia_speed, hs_max_speed_numeric, hsia_price, hsia_plan_name] \n\n        else: \n\n            return [None, None, None, None]\n\n    # read the above 3 csv's (bq_irpc_digital_1p_base.csv, irpc_offer_1p_plans.csv, irpc_offer_prices.csv\n    # read bq_irpc_digital_1p_base and store in df\n    df_base = pd.read_csv(irpc_base_csv)\n    df_plans = pd.read_csv(irpc_offer_plans_csv)\n    df_prices = pd.read_csv(irpc_offer_prices_csv)\n\n    # convert irpc_offer_1p_plans and irpc_offer_prices to lists and dictionaries\n    # - list_hsia_speed\n    # - dict_hsia_details\n    list_hsia_speed, dict_hsia_plans_details = convert_df_to_list_dict(df_plans, channel)\n    list_hsia_speed, dict_hsia_prices_details = convert_df_to_list_dict(df_prices, channel)\n\n    offer_1_list, offer_2_list, offer_3_list = [] , [], [] \n\n    df_base[['hsia_speed1', 'hs_max_speed_numeric1', 'hsia_price1', 'promo_seg1']]  = df_base.apply(lambda row: pd.Series(find_digital_irpc_offers(list_hsia_speed, dict_hsia_plans_details, dict_hsia_prices_details, row, 1)), axis=1)\n    df_base[['hsia_speed2', 'hs_max_speed_numeric2', 'hsia_price2', 'promo_seg2']]  = df_base.apply(lambda row: pd.Series(find_digital_irpc_offers(list_hsia_speed, dict_hsia_plans_details, dict_hsia_prices_details, row, 2)), axis=1)\n    df_base[['hsia_speed3', 'hs_max_speed_numeric3', 'hsia_price3', 'promo_seg3']]  = df_base.apply(lambda row: pd.Series(find_digital_irpc_offers(list_hsia_speed, dict_hsia_plans_details, dict_hsia_prices_details, row, 3)), axis=1)\n\n    df_base = df_base[['cust_id', 'bacct_num', 'fms_address_id', 'lpds_id', 'candate', 'OPTIK_TV_IND', 'HSIA_IND', 'hs_max_speed_numeric', 'provisioned_hs_speed_numeric', \n                       'rpp_hsia_end_dt', 'rpp_ttv_end_dt', 'total_charges', 'promo_seg1', 'promo_seg2', 'promo_seg3']] \n\n    df_base.to_csv(save_data_path)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 16.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-offer-attachment-digital-2": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "offer_attachment_digital"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef offer_attachment_digital(irpc_base_csv: str\n                   , irpc_offer_plans_csv: str \n                   , irpc_offer_prices_csv: str\n                   , channel: str\n                   , save_data_path: str\n                  ): \n    import pandas as pd \n    import numpy as np \n\n    def convert_df_to_list_dict(df, \n                                channel: str = 'digital' # digital or casa\n                                ): \n\n        import re\n        import logging \n        from datetime import datetime\n\n        print(df.head())\n\n        # Change dataset / table + sp table name to version in bi-layer\n        if channel == 'digital': \n            df = df\n        elif channel == 'casa': \n            df = df.iloc[:4]\n        else: \n            print(\"a parameter 'channel' can only be either 'digital' or 'casa'\")\n\n        # create list_hsia_speed = [250, 500, 1000, 1500, 3000]\n        list_hsia_speed = df.columns[3:]\n\n        print(list_hsia_speed)\n\n        list_hsia_speed = [int(re.search(r'\\d+', speed).group()) for speed in list_hsia_speed]\n\n        # create dictionary of hsia_prices \n        # Convert DataFrame to a dictionary\n        dict_hsia_details = df.to_dict(orient='list')\n\n        return list_hsia_speed, dict_hsia_details\n\n    def find_digital_irpc_offers(list_hsia_speed: str, # list_hsia_speed = [250, 500, 1000, 1500, 3000] as of Feb 2024\n                             dict_hsia_plans_details: str, # e.g. internet_250: ['1P:Regular (Internet 250)', '1P:Tier 0 (Internet 250)', '1P:Tier 1 (Internet 250)']\n                             dict_hsia_prices_details: str, # e.g. internet_250: [105, 100, 95, 85, 75]\n                             row, \n                             offer_num: int\n                             ):\n\n        import pandas as pd\n        import numpy as np \n\n        cust_id, ban, lpds_id = row['cust_id'], row['bacct_num'], row['lpds_id']\n\n        if offer_num == 1: \n            provisioned_hs_speed_numeric, hs_max_speed_numeric, total_charges = row['provisioned_hs_speed_numeric'], row['hs_max_speed_numeric'], row['total_charges']\n        elif offer_num == 2: \n            provisioned_hs_speed_numeric, hs_max_speed_numeric, total_charges = row['hsia_speed1'], row['hs_max_speed_numeric1'], row['hsia_price1']\n        elif offer_num == 3: \n            provisioned_hs_speed_numeric, hs_max_speed_numeric, total_charges = row['hsia_speed2'], row['hs_max_speed_numeric2'], row['hsia_price2']\n\n        if provisioned_hs_speed_numeric is None and hs_max_speed_numeric is None and total_charges is None: \n            return [None, None, None, None]\n\n        ### 1. Find the smallest number in hsia_speed that is greater than provisioned_hs_speed_numeric\n\n        # exception: if the current hsia_speed >= 150 AND hsia_speed < 500, then change the value to 499 so that it bypasses 250 \n        ## Internet 150 customers should not be shown Internet 250 tier, as they are upsped in the backend to speeds of 300mbps ##\n        if provisioned_hs_speed_numeric >= 150 and provisioned_hs_speed_numeric < 500: \n            provisioned_hs_speed_numeric = 499\n\n        # It doesn't make sense when hs_max_speed_numeric < provisioned_hs_speed_numeric. \n        # Update hs_max_speed_numeric to provisioned_hs_speed_numeric when it's the case. \n        if hs_max_speed_numeric < provisioned_hs_speed_numeric: \n            hs_max_speed_numeric = provisioned_hs_speed_numeric\n\n        # store minimum hsia speed offer available greater than (or equal to) the current speed in 'hsia_speed'\n        # AND \n        # minimum speed offer available where the highest offer price in that speed is greater than or equal to 'total_charges'\n\n        # requirements:\n            # - list_hsia_speed\n            # - np.max([spd for spd in dict_hsia_prices_details[f'internet_{hsia_speed}'] if not pd.isna(spd)]) --> max offer price in the internet speed\n            # - compare max offer price vs total_charges \n            # - since internet_250 does not have offer tier equal to or greater than $125, we need to move on to the next speed, which is 500\n            # - since internet_500 does not have offer tier equal to or greater than $125, we need to again move on to the next speed, which is 1000\n            # - internet_1000 has an offer tier equal to or greater than $125, so hsia_speed = 1000\n\n        try: \n            if offer_num == 1: \n                hsia_speed = np.min([spd for spd in list_hsia_speed if spd >= provisioned_hs_speed_numeric and spd <= hs_max_speed_numeric and not pd.isna(spd)]) # --> 250\n            else: \n                hsia_speed = np.min([spd for spd in list_hsia_speed if spd > provisioned_hs_speed_numeric and spd <= hs_max_speed_numeric and not pd.isna(spd)])\n\n            max_offer_price = np.max([spd for spd in dict_hsia_prices_details[f'internet_{hsia_speed}'] if not pd.isna(spd)])\n\n        except ValueError: \n            return [None, None, None, None]\n\n        try: \n            while max_offer_price < total_charges: \n                hsia_speed_idx = list_hsia_speed.index(hsia_speed)\n                hsia_speed = list_hsia_speed[hsia_speed_idx + 1]\n                max_offer_price = np.max([spd for spd in dict_hsia_prices_details[f'internet_{hsia_speed}'] if not pd.isna(spd)])\n\n        except IndexError: \n            print(f\"The customer {cust_id} {ban} {lpds_id} is currently paying > $145, thus not eligible for any offers\")\n\n        ### 2. Find the smallest number in dict_hsia_prices_details[hsia_speed] that is greater (or equal to) than total_charges --> 75\n\n        list_hsia_price = dict_hsia_prices_details[f'internet_{hsia_speed}']\n\n        if len([price for price in list_hsia_price if price >= total_charges]) > 0: \n\n            try: \n                if offer_num == 1: \n                    hsia_price = np.min([price for price in list_hsia_price if price >= total_charges])\n                else: \n                    hsia_price = np.min([price for price in list_hsia_price if price > total_charges])\n\n            except ValueError: \n                return [None, None, None, None]\n\n            try: \n                # scenario when the same price DOES EXIST in the next speed offer (e.g. if internet_500, check internet_1000 for $95 offer ==> YES): \n                hsia_speed_idx = list_hsia_speed.index(hsia_speed)\n                next_hsia_speed = list_hsia_speed[hsia_speed_idx + 1]\n\n                if hsia_price in dict_hsia_prices_details[f'internet_{next_hsia_speed}'] and hsia_speed == provisioned_hs_speed_numeric: \n                    list_hsia_price = dict_hsia_prices_details[f'internet_{next_hsia_speed}']\n                    hsia_speed = next_hsia_speed \n\n            except IndexError: \n                print(f\"For {cust_id} {ban} {lpds_id}, the hsia_speed {hsia_speed} is the fastest internet speed available.\")\n\n            except UnboundLocalError: \n                print(f\"For {cust_id} {ban} {lpds_id}, the hsia_speed {hsia_speed} is the fastest internet speed available.\")\n\n            # scenario when the same price DOES NOT EXIST in the next speed offer (e.g. if internet_1000, check internet_1500 for $95 offer ==> NO): \n\n            if hsia_price in list_hsia_price:\n                plan_idx = list_hsia_price.index(hsia_price)    \n\n            ### 4. Call the plan name by hsia_plans[provisioned_hs_speed_numeric]==250][plan_idx==4] --> \"1P: Tier 3 (Internet 250)\"\n\n            hsia_plan_name = dict_hsia_plans_details[f'internet_{hsia_speed}'][plan_idx]\n\n            return [hsia_speed, hs_max_speed_numeric, hsia_price, hsia_plan_name] \n\n        else: \n\n            return [None, None, None, None]\n\n    # read the above 3 csv's (bq_irpc_digital_1p_base.csv, irpc_offer_1p_plans.csv, irpc_offer_prices.csv\n    # read bq_irpc_digital_1p_base and store in df\n    df_base = pd.read_csv(irpc_base_csv)\n    df_plans = pd.read_csv(irpc_offer_plans_csv)\n    df_prices = pd.read_csv(irpc_offer_prices_csv)\n\n    # convert irpc_offer_1p_plans and irpc_offer_prices to lists and dictionaries\n    # - list_hsia_speed\n    # - dict_hsia_details\n    list_hsia_speed, dict_hsia_plans_details = convert_df_to_list_dict(df_plans, channel)\n    list_hsia_speed, dict_hsia_prices_details = convert_df_to_list_dict(df_prices, channel)\n\n    offer_1_list, offer_2_list, offer_3_list = [] , [], [] \n\n    df_base[['hsia_speed1', 'hs_max_speed_numeric1', 'hsia_price1', 'promo_seg1']]  = df_base.apply(lambda row: pd.Series(find_digital_irpc_offers(list_hsia_speed, dict_hsia_plans_details, dict_hsia_prices_details, row, 1)), axis=1)\n    df_base[['hsia_speed2', 'hs_max_speed_numeric2', 'hsia_price2', 'promo_seg2']]  = df_base.apply(lambda row: pd.Series(find_digital_irpc_offers(list_hsia_speed, dict_hsia_plans_details, dict_hsia_prices_details, row, 2)), axis=1)\n    df_base[['hsia_speed3', 'hs_max_speed_numeric3', 'hsia_price3', 'promo_seg3']]  = df_base.apply(lambda row: pd.Series(find_digital_irpc_offers(list_hsia_speed, dict_hsia_plans_details, dict_hsia_prices_details, row, 3)), axis=1)\n\n    df_base = df_base[['cust_id', 'bacct_num', 'fms_address_id', 'lpds_id', 'candate', 'OPTIK_TV_IND', 'HSIA_IND', 'hs_max_speed_numeric', 'provisioned_hs_speed_numeric', \n                       'rpp_hsia_end_dt', 'rpp_ttv_end_dt', 'total_charges', 'promo_seg1', 'promo_seg2', 'promo_seg3']] \n\n    df_base.to_csv(save_data_path)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 16.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-postprocess": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "postprocess"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef postprocess(project_id: str\n              , dataset_id: str\n              , table_id: str\n              , read_data_path: str\n              , save_data_path: str\n              , base_type: str # digital_1p, digital_2p, casa \n              , token: str\n              ): \n\n    import pandas as pd \n    import numpy as np \n\n    from google.cloud import bigquery\n    import logging\n    import datetime as dt\n\n    df = pd.read_csv(read_data_path, index_col=None)\n\n    date_cols = ['candate', 'rpp_hsia_end_dt', 'rpp_ttv_end_dt']\n    df[date_cols] = df[date_cols].apply(pd.to_datetime)\n\n    if base_type == \"digital_1p\" or base_type == \"casa\": \n        rk = [11, 21, 31]\n    elif base_type == \"digital_2p\":\n        rk = [10, 20, 30]\n    else: \n        print(\"\"\"a parameter 'base type' can only accept 'digital_1p', 'digital_2p', or 'casa' as input values\"\"\")\n\n    def create_dict_from_df(df):\n\n        # Convert DataFrame to a list of dictionaries\n        records = df.to_dict(orient='records')\n\n        # Create the desired dictionary format\n        result_dict = {record[df.columns[0]]: [record[df.columns[1]], record[df.columns[2]]] for record in records}\n\n        return result_dict\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n    #     #### For prod \n    #     client = bigquery.Client(project=project_id)\n    #     job_config = bigquery.QueryJobConfig()\n\n    # Change dataset / table + sp table name to version in bi-layer\n    query =\\\n        f'''\n            SELECT * FROM `{project_id}.{dataset_id}.{table_id}`\n        '''\n\n    df_offer_details = client.query(query, job_config=job_config).to_dataframe()\n    dict_offer_details = create_dict_from_df(df_offer_details)\n\n    ### promo_seg1\n    irpc_reco1 = df[df['promo_seg1'].notna() & (df['promo_seg1'] != '')]\n    irpc_reco1.reset_index(drop=True, inplace=True)\n    new_df1 = irpc_reco1['promo_seg1'].apply(lambda x: dict_offer_details.get(x, ['', '']))\n    promo_seg1 = [item[0] for item in new_df1]\n    offer_code1 = [item[1] for item in new_df1]\n    irpc_reco1['promo_seg'] = pd.Series(promo_seg1)\n    irpc_reco1['offer_code'] = pd.Series(offer_code1)\n    irpc_reco1['Category'] = 'Digital Renewal'\n    irpc_reco1['Subcategory'] = 'Internet'\n    irpc_reco1['rpp_hsia_end_dt'] = pd.to_datetime(irpc_reco1['rpp_hsia_end_dt'], errors='coerce')\n    irpc_reco1.loc[irpc_reco1[\"rpp_hsia_end_dt\"].isnull(), \"digital_category\"] = 'Re-contracting'\n    irpc_reco1.loc[irpc_reco1[\"rpp_hsia_end_dt\"].dt.date > dt.date.today(), \"digital_category\"] = 'Renewal'\n    irpc_reco1['ASSMT_VALID_START_TS'] = dt.datetime.now()\n    irpc_reco1['ASSMT_VALID_END_TS'] = dt.datetime.now() + dt.timedelta(days=90)\n    irpc_reco1['rk'] = rk[0]\n\n    irpc_reco1.to_csv('gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/irpc_reco1.csv', index=False)\n\n    ### promo_seg2\n    irpc_reco2 = df[df['promo_seg2'].notna() & (df['promo_seg2'] != '')]\n    irpc_reco2.reset_index(drop=True, inplace=True)\n    new_df2 = irpc_reco2['promo_seg2'].apply(lambda x: dict_offer_details.get(x, ['', '']))\n    promo_seg2 = [item[0] for item in new_df2]\n    offer_code2 = [item[1] for item in new_df2]\n    irpc_reco2['promo_seg'] = pd.Series(promo_seg2)\n    irpc_reco2['offer_code'] = pd.Series(offer_code2)\n    irpc_reco2['Category'] = 'Digital Renewal'\n    irpc_reco2['Subcategory'] = 'Internet'\n    irpc_reco2['rpp_hsia_end_dt'] = pd.to_datetime(irpc_reco2['rpp_hsia_end_dt'], errors='coerce')\n    irpc_reco2.loc[irpc_reco2[\"rpp_hsia_end_dt\"].isnull(), \"digital_category\"] = 'Re-contracting'\n    irpc_reco2.loc[irpc_reco2[\"rpp_hsia_end_dt\"].dt.date > dt.date.today(), \"digital_category\"] = 'Renewal'\n    irpc_reco2['ASSMT_VALID_START_TS'] = dt.datetime.now()\n    irpc_reco2['ASSMT_VALID_END_TS'] = dt.datetime.now() + dt.timedelta(days=90)\n    irpc_reco2['rk'] = rk[1]\n\n    irpc_reco2.to_csv('gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/irpc_reco2.csv', index=False)\n\n    ### promo_seg3\n    irpc_reco3 = df[df['promo_seg3'].notna() & (df['promo_seg3'] != '')]\n    irpc_reco3.reset_index(drop=True, inplace=True)\n    new_df3 = irpc_reco3['promo_seg3'].apply(lambda x: dict_offer_details.get(x, ['', '']))\n    promo_seg3 = [item[0] for item in new_df3]\n    offer_code3 = [item[1] for item in new_df3]\n    irpc_reco3['promo_seg'] = pd.Series(promo_seg3)\n    irpc_reco3['offer_code'] = pd.Series(offer_code3)\n    irpc_reco3['Category'] = 'Digital Renewal'\n    irpc_reco3['Subcategory'] = 'Internet'\n    irpc_reco3['rpp_hsia_end_dt'] = pd.to_datetime(irpc_reco3['rpp_hsia_end_dt'], errors='coerce')\n    irpc_reco3.loc[irpc_reco3[\"rpp_hsia_end_dt\"].isnull(), \"digital_category\"] = 'Re-contracting'\n    irpc_reco3.loc[irpc_reco3[\"rpp_hsia_end_dt\"].dt.date > dt.date.today(), \"digital_category\"] = 'Renewal'\n    irpc_reco3['ASSMT_VALID_START_TS'] = dt.datetime.now()\n    irpc_reco3['ASSMT_VALID_END_TS'] = dt.datetime.now() + dt.timedelta(days=90)\n    irpc_reco3['rk'] = rk[2]\n\n    # concatenate irpc_reco1 + irpc_reco2 + irpc_reco3 \n    # write .csv to gcs\n    irpc_recos = pd.concat([irpc_reco1, irpc_reco2, irpc_reco3], ignore_index=True)\n    irpc_recos.reset_index(inplace=True)\n\n    irpc_recos = irpc_recos[['cust_id', 'bacct_num', 'lpds_id', 'candate', 'Category', 'Subcategory', 'digital_category', 'promo_seg', 'offer_code', 'ASSMT_VALID_START_TS', 'ASSMT_VALID_END_TS', 'rk']]\n\n    irpc_recos.to_csv(save_data_path, index=False)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 16.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-postprocess-2": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "postprocess"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef postprocess(project_id: str\n              , dataset_id: str\n              , table_id: str\n              , read_data_path: str\n              , save_data_path: str\n              , base_type: str # digital_1p, digital_2p, casa \n              , token: str\n              ): \n\n    import pandas as pd \n    import numpy as np \n\n    from google.cloud import bigquery\n    import logging\n    import datetime as dt\n\n    df = pd.read_csv(read_data_path, index_col=None)\n\n    date_cols = ['candate', 'rpp_hsia_end_dt', 'rpp_ttv_end_dt']\n    df[date_cols] = df[date_cols].apply(pd.to_datetime)\n\n    if base_type == \"digital_1p\" or base_type == \"casa\": \n        rk = [11, 21, 31]\n    elif base_type == \"digital_2p\":\n        rk = [10, 20, 30]\n    else: \n        print(\"\"\"a parameter 'base type' can only accept 'digital_1p', 'digital_2p', or 'casa' as input values\"\"\")\n\n    def create_dict_from_df(df):\n\n        # Convert DataFrame to a list of dictionaries\n        records = df.to_dict(orient='records')\n\n        # Create the desired dictionary format\n        result_dict = {record[df.columns[0]]: [record[df.columns[1]], record[df.columns[2]]] for record in records}\n\n        return result_dict\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n    #     #### For prod \n    #     client = bigquery.Client(project=project_id)\n    #     job_config = bigquery.QueryJobConfig()\n\n    # Change dataset / table + sp table name to version in bi-layer\n    query =\\\n        f'''\n            SELECT * FROM `{project_id}.{dataset_id}.{table_id}`\n        '''\n\n    df_offer_details = client.query(query, job_config=job_config).to_dataframe()\n    dict_offer_details = create_dict_from_df(df_offer_details)\n\n    ### promo_seg1\n    irpc_reco1 = df[df['promo_seg1'].notna() & (df['promo_seg1'] != '')]\n    irpc_reco1.reset_index(drop=True, inplace=True)\n    new_df1 = irpc_reco1['promo_seg1'].apply(lambda x: dict_offer_details.get(x, ['', '']))\n    promo_seg1 = [item[0] for item in new_df1]\n    offer_code1 = [item[1] for item in new_df1]\n    irpc_reco1['promo_seg'] = pd.Series(promo_seg1)\n    irpc_reco1['offer_code'] = pd.Series(offer_code1)\n    irpc_reco1['Category'] = 'Digital Renewal'\n    irpc_reco1['Subcategory'] = 'Internet'\n    irpc_reco1['rpp_hsia_end_dt'] = pd.to_datetime(irpc_reco1['rpp_hsia_end_dt'], errors='coerce')\n    irpc_reco1.loc[irpc_reco1[\"rpp_hsia_end_dt\"].isnull(), \"digital_category\"] = 'Re-contracting'\n    irpc_reco1.loc[irpc_reco1[\"rpp_hsia_end_dt\"].dt.date > dt.date.today(), \"digital_category\"] = 'Renewal'\n    irpc_reco1['ASSMT_VALID_START_TS'] = dt.datetime.now()\n    irpc_reco1['ASSMT_VALID_END_TS'] = dt.datetime.now() + dt.timedelta(days=90)\n    irpc_reco1['rk'] = rk[0]\n\n    irpc_reco1.to_csv('gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/irpc_reco1.csv', index=False)\n\n    ### promo_seg2\n    irpc_reco2 = df[df['promo_seg2'].notna() & (df['promo_seg2'] != '')]\n    irpc_reco2.reset_index(drop=True, inplace=True)\n    new_df2 = irpc_reco2['promo_seg2'].apply(lambda x: dict_offer_details.get(x, ['', '']))\n    promo_seg2 = [item[0] for item in new_df2]\n    offer_code2 = [item[1] for item in new_df2]\n    irpc_reco2['promo_seg'] = pd.Series(promo_seg2)\n    irpc_reco2['offer_code'] = pd.Series(offer_code2)\n    irpc_reco2['Category'] = 'Digital Renewal'\n    irpc_reco2['Subcategory'] = 'Internet'\n    irpc_reco2['rpp_hsia_end_dt'] = pd.to_datetime(irpc_reco2['rpp_hsia_end_dt'], errors='coerce')\n    irpc_reco2.loc[irpc_reco2[\"rpp_hsia_end_dt\"].isnull(), \"digital_category\"] = 'Re-contracting'\n    irpc_reco2.loc[irpc_reco2[\"rpp_hsia_end_dt\"].dt.date > dt.date.today(), \"digital_category\"] = 'Renewal'\n    irpc_reco2['ASSMT_VALID_START_TS'] = dt.datetime.now()\n    irpc_reco2['ASSMT_VALID_END_TS'] = dt.datetime.now() + dt.timedelta(days=90)\n    irpc_reco2['rk'] = rk[1]\n\n    irpc_reco2.to_csv('gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/irpc_reco2.csv', index=False)\n\n    ### promo_seg3\n    irpc_reco3 = df[df['promo_seg3'].notna() & (df['promo_seg3'] != '')]\n    irpc_reco3.reset_index(drop=True, inplace=True)\n    new_df3 = irpc_reco3['promo_seg3'].apply(lambda x: dict_offer_details.get(x, ['', '']))\n    promo_seg3 = [item[0] for item in new_df3]\n    offer_code3 = [item[1] for item in new_df3]\n    irpc_reco3['promo_seg'] = pd.Series(promo_seg3)\n    irpc_reco3['offer_code'] = pd.Series(offer_code3)\n    irpc_reco3['Category'] = 'Digital Renewal'\n    irpc_reco3['Subcategory'] = 'Internet'\n    irpc_reco3['rpp_hsia_end_dt'] = pd.to_datetime(irpc_reco3['rpp_hsia_end_dt'], errors='coerce')\n    irpc_reco3.loc[irpc_reco3[\"rpp_hsia_end_dt\"].isnull(), \"digital_category\"] = 'Re-contracting'\n    irpc_reco3.loc[irpc_reco3[\"rpp_hsia_end_dt\"].dt.date > dt.date.today(), \"digital_category\"] = 'Renewal'\n    irpc_reco3['ASSMT_VALID_START_TS'] = dt.datetime.now()\n    irpc_reco3['ASSMT_VALID_END_TS'] = dt.datetime.now() + dt.timedelta(days=90)\n    irpc_reco3['rk'] = rk[2]\n\n    # concatenate irpc_reco1 + irpc_reco2 + irpc_reco3 \n    # write .csv to gcs\n    irpc_recos = pd.concat([irpc_reco1, irpc_reco2, irpc_reco3], ignore_index=True)\n    irpc_recos.reset_index(inplace=True)\n\n    irpc_recos = irpc_recos[['cust_id', 'bacct_num', 'lpds_id', 'candate', 'Category', 'Subcategory', 'digital_category', 'promo_seg', 'offer_code', 'ASSMT_VALID_START_TS', 'ASSMT_VALID_END_TS', 'rk']]\n\n    irpc_recos.to_csv(save_data_path, index=False)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 16.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-postprocess-3": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "postprocess"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef postprocess(project_id: str\n              , dataset_id: str\n              , table_id: str\n              , read_data_path: str\n              , save_data_path: str\n              , base_type: str # digital_1p, digital_2p, casa \n              , token: str\n              ): \n\n    import pandas as pd \n    import numpy as np \n\n    from google.cloud import bigquery\n    import logging\n    import datetime as dt\n\n    df = pd.read_csv(read_data_path, index_col=None)\n\n    date_cols = ['candate', 'rpp_hsia_end_dt', 'rpp_ttv_end_dt']\n    df[date_cols] = df[date_cols].apply(pd.to_datetime)\n\n    if base_type == \"digital_1p\" or base_type == \"casa\": \n        rk = [11, 21, 31]\n    elif base_type == \"digital_2p\":\n        rk = [10, 20, 30]\n    else: \n        print(\"\"\"a parameter 'base type' can only accept 'digital_1p', 'digital_2p', or 'casa' as input values\"\"\")\n\n    def create_dict_from_df(df):\n\n        # Convert DataFrame to a list of dictionaries\n        records = df.to_dict(orient='records')\n\n        # Create the desired dictionary format\n        result_dict = {record[df.columns[0]]: [record[df.columns[1]], record[df.columns[2]]] for record in records}\n\n        return result_dict\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n    #     #### For prod \n    #     client = bigquery.Client(project=project_id)\n    #     job_config = bigquery.QueryJobConfig()\n\n    # Change dataset / table + sp table name to version in bi-layer\n    query =\\\n        f'''\n            SELECT * FROM `{project_id}.{dataset_id}.{table_id}`\n        '''\n\n    df_offer_details = client.query(query, job_config=job_config).to_dataframe()\n    dict_offer_details = create_dict_from_df(df_offer_details)\n\n    ### promo_seg1\n    irpc_reco1 = df[df['promo_seg1'].notna() & (df['promo_seg1'] != '')]\n    irpc_reco1.reset_index(drop=True, inplace=True)\n    new_df1 = irpc_reco1['promo_seg1'].apply(lambda x: dict_offer_details.get(x, ['', '']))\n    promo_seg1 = [item[0] for item in new_df1]\n    offer_code1 = [item[1] for item in new_df1]\n    irpc_reco1['promo_seg'] = pd.Series(promo_seg1)\n    irpc_reco1['offer_code'] = pd.Series(offer_code1)\n    irpc_reco1['Category'] = 'Digital Renewal'\n    irpc_reco1['Subcategory'] = 'Internet'\n    irpc_reco1['rpp_hsia_end_dt'] = pd.to_datetime(irpc_reco1['rpp_hsia_end_dt'], errors='coerce')\n    irpc_reco1.loc[irpc_reco1[\"rpp_hsia_end_dt\"].isnull(), \"digital_category\"] = 'Re-contracting'\n    irpc_reco1.loc[irpc_reco1[\"rpp_hsia_end_dt\"].dt.date > dt.date.today(), \"digital_category\"] = 'Renewal'\n    irpc_reco1['ASSMT_VALID_START_TS'] = dt.datetime.now()\n    irpc_reco1['ASSMT_VALID_END_TS'] = dt.datetime.now() + dt.timedelta(days=90)\n    irpc_reco1['rk'] = rk[0]\n\n    irpc_reco1.to_csv('gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/irpc_reco1.csv', index=False)\n\n    ### promo_seg2\n    irpc_reco2 = df[df['promo_seg2'].notna() & (df['promo_seg2'] != '')]\n    irpc_reco2.reset_index(drop=True, inplace=True)\n    new_df2 = irpc_reco2['promo_seg2'].apply(lambda x: dict_offer_details.get(x, ['', '']))\n    promo_seg2 = [item[0] for item in new_df2]\n    offer_code2 = [item[1] for item in new_df2]\n    irpc_reco2['promo_seg'] = pd.Series(promo_seg2)\n    irpc_reco2['offer_code'] = pd.Series(offer_code2)\n    irpc_reco2['Category'] = 'Digital Renewal'\n    irpc_reco2['Subcategory'] = 'Internet'\n    irpc_reco2['rpp_hsia_end_dt'] = pd.to_datetime(irpc_reco2['rpp_hsia_end_dt'], errors='coerce')\n    irpc_reco2.loc[irpc_reco2[\"rpp_hsia_end_dt\"].isnull(), \"digital_category\"] = 'Re-contracting'\n    irpc_reco2.loc[irpc_reco2[\"rpp_hsia_end_dt\"].dt.date > dt.date.today(), \"digital_category\"] = 'Renewal'\n    irpc_reco2['ASSMT_VALID_START_TS'] = dt.datetime.now()\n    irpc_reco2['ASSMT_VALID_END_TS'] = dt.datetime.now() + dt.timedelta(days=90)\n    irpc_reco2['rk'] = rk[1]\n\n    irpc_reco2.to_csv('gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/irpc_reco2.csv', index=False)\n\n    ### promo_seg3\n    irpc_reco3 = df[df['promo_seg3'].notna() & (df['promo_seg3'] != '')]\n    irpc_reco3.reset_index(drop=True, inplace=True)\n    new_df3 = irpc_reco3['promo_seg3'].apply(lambda x: dict_offer_details.get(x, ['', '']))\n    promo_seg3 = [item[0] for item in new_df3]\n    offer_code3 = [item[1] for item in new_df3]\n    irpc_reco3['promo_seg'] = pd.Series(promo_seg3)\n    irpc_reco3['offer_code'] = pd.Series(offer_code3)\n    irpc_reco3['Category'] = 'Digital Renewal'\n    irpc_reco3['Subcategory'] = 'Internet'\n    irpc_reco3['rpp_hsia_end_dt'] = pd.to_datetime(irpc_reco3['rpp_hsia_end_dt'], errors='coerce')\n    irpc_reco3.loc[irpc_reco3[\"rpp_hsia_end_dt\"].isnull(), \"digital_category\"] = 'Re-contracting'\n    irpc_reco3.loc[irpc_reco3[\"rpp_hsia_end_dt\"].dt.date > dt.date.today(), \"digital_category\"] = 'Renewal'\n    irpc_reco3['ASSMT_VALID_START_TS'] = dt.datetime.now()\n    irpc_reco3['ASSMT_VALID_END_TS'] = dt.datetime.now() + dt.timedelta(days=90)\n    irpc_reco3['rk'] = rk[2]\n\n    # concatenate irpc_reco1 + irpc_reco2 + irpc_reco3 \n    # write .csv to gcs\n    irpc_recos = pd.concat([irpc_reco1, irpc_reco2, irpc_reco3], ignore_index=True)\n    irpc_recos.reset_index(inplace=True)\n\n    irpc_recos = irpc_recos[['cust_id', 'bacct_num', 'lpds_id', 'candate', 'Category', 'Subcategory', 'digital_category', 'promo_seg', 'offer_code', 'ASSMT_VALID_START_TS', 'ASSMT_VALID_END_TS', 'rk']]\n\n    irpc_recos.to_csv(save_data_path, index=False)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 16.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-reg-offers-base-cat3": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "reg_offers_base_cat3"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef reg_offers_base_cat3(project_id: str\n                            , offer_parameter: str\n                            , whsia_eligible_base: str\n                            , qua_base: str\n                            , token: str\n                            ):\n\n    import pandas as pd\n    import sys\n    import os\n    import re\n    import time\n    from pathlib import Path\n    import pdb\n    from yaml import safe_load\n\n    from google.cloud import bigquery\n    import logging \n    from datetime import datetime\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n#     #### For prod \n#     client = bigquery.Client(project=project_id)\n#     job_config = bigquery.QueryJobConfig()\n\n    \"\"\"\n    This program creates eligible bases for three categories of customers\n      - existing home solutions customers\n      - naked mobility customers\n      - cat3\n\n    Initially drafted in Feb 2024\n      - @author: T892899\n\n\n    v0d4 @author: T892899; Feb 29, 2024\n      - update ffh_bas query to welcome 9167815983798937909\n      - double check pending orders\n\n\n    v0d5 @author: T892899; Mar 4th, 2024\n      - update a few tables\n       - bi-srv-hsmdet-pr-7b9def.campaign_data.bq_dly_dbm_customer_profl\n       - bi-srv-hsmdet-pr-7b9def.campaign_data.bq_fda_mob_mobility_base\n       - bi-srv-divgdsa-pr-098bdd.common.bq_mobility_active_data\n\n\n    v0d6 @author: T892899; Mar 6th, 2024\n      - Add SHS Pro-install eligibility flag\n        - this table is still a temp table, which requires more formal solution in the future\n      - Adjust MOB offer filters\n\n\n    v0d7 @author: T892899; Mar 8th, 2024\n      - Update Offer parameter BQ table - formal source / daily update\n      - New function for cr8bqt_sql_BI\n      - Update demostats data source\n\n\n    v0d8 @author: T892899; Mar 13th, 2024\n      - Update SHS Pro-install eligibility BQ table - BI layer\n      - Rename NCID to offer_code\n      - Modify function last_dt_check\n\n\n    v0d9 @author: T892899; Mar 22th, 2024\n      - Update some project names to be a variable, for easy stg to srv update \n      - Add dwelling type to existing customers\n\n    Notes: Feb 2024\n     - SHS eligibility flag need to be added\n     - prod_cd to be changed to bq table\n     - TOS tier model need to be added\n     - HSIC tier model need to be added\n     - valid start/end date format\n        - details to confirm with Weibo/Francis\n        - 2022-01-01T00:00:00.000Z\n\n    \"\"\"\n\n    # define some functions\n    # please feel free to improve as fit\n    def cr8bqt_sql_BI(\n        clnt,\n        sql_base,\n        opt,\n        est_num\n        ): \n\n        sql_s1 =f\"\"\"\n\n            TRUNCATE TABLE `{opt}_temp`;   \n            INSERT INTO `{opt}_temp`\n            {sql_base}            \n\n            \"\"\" \n\n        crdt_s1 = clnt.query(sql_s1).to_dataframe()\n\n        tableid = opt.split('.')\n\n        sql_s2 =f\"\"\"\n\n                SELECT\n                  row_count\n                FROM `{tableid[0]}.{tableid[1]}`.__TABLES__\n                where table_id = '{tableid[2]}_temp'\n                ;\n\n            \"\"\" \n\n        crdt_s2 = clnt.query(sql_s2).to_dataframe()\n\n        if crdt_s2['row_count'][0] > est_num:\n            sql_s3 =f\"\"\"\n\n                TRUNCATE TABLE `{opt}`;   \n                INSERT INTO `{opt}`\n                select * from `{opt}_temp`\n\n            \"\"\" \n            crdt_s3 = clnt.query(sql_s3).to_dataframe()\n\n        else:\n            raise Exception(f\"{opt}_temp has {crdt_s2['row_count'][0]} rows -- seems low. Update aborted.\")\n\n    def last_dt_check(\n        clnt,\n        ipt,\n        part_dt,\n        wd\n        ): \n\n        sql_s1 =f\"\"\"\n\n            with\n                max_date1 as (\n                    SELECT \n                        0 as a\n                        , {part_dt} \n                        , count({part_dt}) as mxx\n                    FROM `{ipt}`\n                        WHERE {part_dt} >= DATE_SUB(CURRENT_DATE(), INTERVAL {wd} DAY)\n                    group by a, {part_dt}\n                    order by a, {part_dt} desc\n                    )\n                ,  max_date2 as (\n                    select\n                        0 as a\n                        , avg(mxx) as mxx_avg\n                    from max_date1\n                        group by a\n                    )\n\n                select\n                    cast(max(a.{part_dt}) AS STRING) as part_dt\n                from max_date1 a left join max_date2 b\n                on a.a = b.a\n                where a.mxx >= b.mxx_avg * 0.8\n\n        \"\"\" \n\n        crdt_s1 = clnt.query(sql_s1).to_dataframe()\n\n        return(crdt_s1['part_dt'][0])\n\n    # Beginning of Part 3\n\n    # Creating eligible base for CSD channel technicians\n    # for brand new customers with pending orders \n\n\n    # Pull Offer Info\n\n    sq0l =f\"\"\"\n\n       with\n            max_dt as (    \n              SELECT \n              max(part_dt) as part_dt\n              FROM `{offer_parameter}` \n            )\n        select\n            Replace(a.Offer_Number, '-', '_') as Offer_Number2\n            , a.* \n            , CAST(a.valid_start_ts AS DATE FORMAT 'MON DD, YYYY') AS valid_start_dt \n            , CAST(a.valid_end_ts AS DATE FORMAT 'MON DD, YYYY') AS valid_end_dt\n        from `{offer_parameter}` a \n        inner join max_dt b\n        on a.part_dt = b.part_dt\n        where a.if_active = 1 and a.HS_filters is not null and if_cat3 = 1\n\n    \"\"\" \n\n    offer_info = client.query(sq0l).to_dataframe()\n\n\n    # Check latest snapshot date with reasonable counts\n\n\n    last_dt_pid = last_dt_check(clnt = client,\n                                ipt = 'bi-srv-divgdsa-pr-098bdd.common.bq_hs_product_instance_details',\n                                part_dt = 'part_load_dt',\n                                wd = 14 )\n\n    last_dt_pi = last_dt_check(clnt = client,\n                                ipt = 'bi-srv-divgdsa-pr-098bdd.common.bq_hs_product_instance',\n                                part_dt = 'part_load_dt',\n                                wd = 14 )\n\n    last_dt_spd = last_dt_check(clnt = client,\n                                ipt = 'bi-srv-divgdsa-pr-098bdd.common.bq_premise_universe',\n                                part_dt = 'part_dt' ,\n                                wd = 14)\n\n\n\n    # Create cat3 customer profile - base\n\n    sq0l =f\"\"\"\n\n        with cat3_bas as (\n\n                select  \n                    cust_id\n                    , bill_account_number as bacct_num\n                    , lpds_id\n                    , max(case when product_family = 'TOS' then 1 else 0 end) as TOS_IND\n                    , max(case when product_family = 'HSIC' then 1 else 0 end) as HSIA_ind\n                    , max(case when product_family = 'SMHM' then 1 else 0 end) as SHS_ind\n                    , max(case when product_family = 'TTV' then 1 else 0 end) as OPTIK_TV_IND\n                    , max(case when product_family = 'SING' then 1 else 0 end) as HP_IND\n                    , max(case when product_family = 'WIFI' then 1 else 0 end) as WFP_ind\n                    , max(case when product_family = 'WHSIA' then 1 else 0 end) as SMART_HUB_IND\n                    , max(case when product_family = 'LWC' then 1 else 0 end) as LWC_ind\n                    , max(case when product_family = 'SWS' then 1 else 0 end) as SWS_ind\n                    , max(case when product_family = 'SOD' then 1 else 0 end) as SOD_ind\n                    , max(case when product_family = 'HPRO' then 1 else 0 end) as HPRO_ind\n                 from `bi-srv-hsmsd-3c-pr-ca2cd4.hsmsd_3c_rpt_dataset.bq_rpt_chnl_order_ffh_dtl_view`\n                where is_current_order = 1 and current_yield_dt >= DATE_SUB(CURRENT_DATE(), INTERVAL 100 DAY)\n                    and (current_yield_sub_status = 'Pending')\n                    and current_order_status = 'Processing'\n                    and soi_transaction_type = 'Enroll'\n                    and is_existing_customer = 0\n                    group by 1,2,3\n\n        )\n\n        , spd as (\n\n            select distinct\n                lpds_id\n                , fms_address_id\n                , postal_cd as SERV_POSTAL_CODE\n                , hs_max_speed_bonded as HSIA_MAX_SPD\n                , SYSTEM_PROVINCE_CD as SERV_PROV\n                , snet_premise_type_cd\n                , ttv_eligible_ind as OPTIK_ELIGIBLE\n                , ttv_port_availability \n                , gpon_sellable_ind as TECH_GPON\n            from `bi-srv-divgdsa-pr-098bdd.common.bq_premise_universe` \n            WHERE part_dt = '{last_dt_spd}'\n        )\n\n\n        , pid as (\n\n                select \n                  cust_id\n                  , max(case when access_technology = 'COPPER' then 1 else 0 end) as cpf_acctech_copper_ind\n                  , max(case when access_technology = 'FIBRE' then 1 else 0 end) as cpf_acctech_fibre_ind\n                  , max(case when access_technology = 'WIRELESS' then 1 else 0 end) as cpf_acctech_wls_ind\n                  , max(case when access_technology = 'SATELLITE' then 1 else 0 end) as cpf_acctech_satellite_ind\n                  , sum(case when service_instance_type_cd != 'DIIC' then 1 else 0 end) as cpf_prod_cnt\n                  , max(case when service_instance_type_cd = 'DIIC' then 1 else 0 end) as cpf_diic_ind\n                  , max(case when service_instance_type_cd = 'HSIC' then 1 else 0 end) as cpf_hsic_ind\n                  , max(case when service_instance_type_cd = 'HSIC' then provisioned_hs else null end) as cpf_provisioned_hs\n                  , max(case when service_instance_type_cd = 'LWC' then 1 else 0 end) as cpf_lwc_ind\n                  , max(case when service_instance_type_cd = 'PIK' then 1 else 0 end) as cpf_pik_ind\n                  , max(case when service_instance_type_cd = 'SHS' then 1 else 0 end) as cpf_shs_ind\n                  , max(case when prod_intrnl_nm in ('Smart Automation Plus', 'Smart Automation Plus (V2)'\n                          , 'Smart Camera (V2)', 'Secure Business: Smart Camera') then 1 else 0 end) as cpf_shs_ind2\n                  , max(case when service_instance_type_cd = 'SING' then 1 else 0 end) as cpf_sing_ind\n                  , max(case when service_instance_type_cd = 'STV' then 1 else 0 end) as cpf_stv_ind\n                  , max(case when service_instance_type_cd = 'SWS' then 1 else 0 end) as cpf_sws_ind\n                  , max(case when service_instance_type_cd = 'STMP' then 1 else 0 end) as cpf_stmp_ind\n                  , max(case when service_instance_type_cd = 'TOS' then 1 else 0 end) as cpf_tos_ind\n                  , max(case when service_instance_type_cd = 'TOS'\n                          and prod_cd = '40983311' then 1 else 0 end) as cpf_tos_basic_ind\n                  , max(case when service_instance_type_cd = 'TOS'\n                          and prod_cd = '41079641' then 1 else 0 end) as cpf_tos_standard_ind\n                  , max(case when service_instance_type_cd = 'TTV' then 1 else 0 end) as cpf_ttv_ind\n                  , max(case when service_instance_type_cd = 'WFP' then 1 else 0 end) as cpf_wfp_ind\n                  , max(case when service_instance_type_cd = 'WHSIA' then 1 else 0 end) as cpf_whsia_ind  \n                  , max(case when service_instance_type_cd = 'HPRO' then 1 else 0 end) as cpf_HPRO_ind   \n\n                  from `bi-srv-divgdsa-pr-098bdd.common.bq_hs_product_instance`\n                        where part_load_dt = '{last_dt_pi}'\n                      and product_instance_status_cd = 'A' and current_ind = 1\n                    group by cust_id\n\n        )    \n\n        , ffh_bas as (\n            select \n                a.*\n                , b.* except (lpds_id)\n                , c.* except (cust_id)\n\n                , 0 as EX_STANDARD_EX\n                , 0 as std_exclud2\n                , 'FIFA' as PROVISIONING_SYSTEM\n                , 0 as MNH_MOB_BAN\n                , '' as SHS_CONTRACT_END_DT\n                , 0 as REWARDS_POINT_BALANCE\n                , CAST(NULL AS TIMESTAMP) as ACCT_START_DT\n                , 0 as OPTIK_PACKAGE_NUM\n                , 0 as STV_IND\n                , 0 as PIK_TV_IND\n\n                , case when (( d.HTA1519_pct > 0.25)\n                                or ( d.HTA2024_pct > 0.25)\n                                or ( d.HTA2529_pct > 0.25)\n                                or ( d.HTA3034_pct > 0.25)\n                                or ( d.HTA3539_pct > 0.25)\n                                or ( d.HTA4044_pct > 0.25)\n\n                                or ( d.HMA1519_pct > 0.25)\n                                or ( d.HMA2024_pct > 0.25)\n                                or ( d.HMA2529_pct > 0.25)\n                                or ( d.HMA3034_pct > 0.25)\n                                or ( d.HMA3539_pct > 0.25)\n                                or ( d.HMA4044_pct > 0.25)\n\n                                or ( d.HFA1519_pct > 0.25)\n                                or ( d.HFA2024_pct > 0.25)\n                                or ( d.HFA2529_pct > 0.25)\n                                or ( d.HFA3034_pct > 0.25)\n                                or ( d.HFA3539_pct > 0.25)\n                                or ( d.HFA4044_pct > 0.25)) then 1 else 0 end as demo_hs_189_ind\n\n                , case when d.baskid > 50 then 1 else 0 end as demo_hs_188_ind\n\n                , RAND() as rand_seed1\n\n                , 0 as hs_202_ind\n\n                , f.wHSIAQualTypeMarketing\n\n                , case when g1.ACQ_DATE is not null\n                            or g3.ACQ_DATE is not null\n                            then 1 else 0 end as alarm_full_universe\n\n                , 0 as hs_71_ind\n\n            from cat3_bas a            \n            left join spd b on a.lpds_id = cast(b.lpds_id as STRING)\n            left join pid c on a.cust_id = cast(c.cust_id as STRING) \n            left join `bi-srv-divgdsa-pr-098bdd.environics_derived.bq_demostats_2023_features` d on b.SERV_POSTAL_CODE = d.code\n            left join `{whsia_eligible_base}` f on a.LPDS_ID = cast(f.LPDSId as STRING)\n            left join `bi-srv-hsmdet-pr-7b9def.hsmdet_public.bq_pub_fda_alarm_full_universe` g1\n                on a.cust_id is not null and a.cust_id = cast(g1.cust_id as STRING)\n            left join `bi-srv-hsmdet-pr-7b9def.hsmdet_public.bq_pub_fda_alarm_full_universe` g3\n                on b.FMS_ADDRESS_ID is not null and b.FMS_ADDRESS_ID = g3.FMS_ADDRESS_ID        \n\n            )\n\n\n    \"\"\" \n\n    # Create eligible base for each offer\n\n    sql_all = sq0l\n    n_offer = offer_info.shape[0]\n    for ii in range(n_offer):\n        ii2 = ii + 1\n\n        sql_b1 = (\n                f\"\"\", {offer_info['Offer_Number2'][ii]} as (\n                select distinct cast(cust_id as int64) as cust_id \\n\n                , cast(bacct_num as int64) as bacct_num \\n\n                , cast(lpds_id as int64) as lpds_id \\n\n                , cast(ACCT_START_DT as timestamp) as candate \\n\n                , '{offer_info['Category'][ii]}' as Category  \\n\n                , '{offer_info['Subcategory'][ii]}' as Subcategory  \\n \n                , '' as digital_category\n                , '{offer_info['promo_seg'][ii]}' as promo_seg  \\n \n                , '{offer_info['NCID'][ii]}' as offer_code  \\n \n                , cast('{offer_info['valid_start_dt'][ii]}' AS DATE) as ASSMT_VALID_START_TS  \\n\n                , cast('{offer_info['valid_end_dt'][ii]}' AS DATE) as ASSMT_VALID_END_TS  \\n \n                , {str(offer_info['rk'][ii])} as rk  \\n\n                from ffh_bas \\n where  {offer_info['HS_filters'][ii]} )  \\n \"\"\"\n               )\n\n        sql_all0 = sql_all + sql_b1\n\n        sql_all = sql_all0\n\n\n    # Union eligible bases\n\n    sql_all0 = sql_all + f\" select * from {offer_info['Offer_Number2'][0]} \\n\"\n    sql_all = sql_all0\n    n_offer = offer_info.shape[0] - 1\n    for ii in range(n_offer):\n        ii2 = ii + 1\n        sql_b2 = f\" union all select * from {offer_info['Offer_Number2'][ii2]}  \\n\"\n        sql_all0 = sql_all + sql_b2\n        sql_all = sql_all0\n\n\n    # check base count before creating multiple eligible base\n    # \n\n    sq0l =\"\"\"\n\n            select count(distinct cust_id) as cnt \n             from `bi-srv-hsmsd-3c-pr-ca2cd4.hsmsd_3c_rpt_dataset.bq_rpt_chnl_order_ffh_dtl_view`\n            where is_current_order = 1 \n                and current_yield_dt >= DATE_SUB(CURRENT_DATE(), INTERVAL 180 DAY)\n                and (current_yield_sub_status = 'Pending')\n                and current_order_status = 'Processing'\n                and soi_transaction_type = 'Enroll'\n                and is_existing_customer = 0\n\n    \"\"\" \n\n    df_check = client.query(sq0l).to_dataframe()\n\n\n\n    start_time = time.time()\n\n    if df_check['cnt'][0] > 500:\n        cr8bqt_sql_BI(\n            clnt = client,\n            sql_base = sql_all,\n            opt = qua_base,\n            est_num = 1500\n        )\n\n    else:\n        raise Exception(f\"Cat3 base has {df_check['cnt'][0]} rows -- seems low. Update aborted.\")\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 16.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-reg-offers-base-existing": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "reg_offers_base_existing"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef reg_offers_base_existing(project_id: str\n                            , offer_parameter: str\n                            , whsia_eligible_base: str\n                            , shs_professional_install: str\n                            , prod_cd2remove: str\n                            , qua_base: str\n                            , token: str\n                            ):\n\n    import pandas as pd\n    import sys\n    import os\n    import re\n    import time\n    from pathlib import Path\n    import pdb\n    from yaml import safe_load\n\n    from google.cloud import bigquery\n    import logging \n    from datetime import datetime\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n#     #### For prod \n#     client = bigquery.Client(project=project_id)\n#     job_config = bigquery.QueryJobConfig()\n\n    \"\"\"\n    This program creates eligible bases for three categories of customers\n      - existing home solutions customers\n      - naked mobility customers\n      - cat3\n\n    Initially drafted in Feb 2024\n      - @author: T892899\n\n\n    v0d4 @author: T892899; Feb 29, 2024\n      - update ffh_bas query to welcome 9167815983798937909\n      - double check pending orders\n\n\n    v0d5 @author: T892899; Mar 4th, 2024\n      - update a few tables\n       - bi-srv-hsmdet-pr-7b9def.campaign_data.bq_dly_dbm_customer_profl\n       - bi-srv-hsmdet-pr-7b9def.campaign_data.bq_fda_mob_mobility_base\n       - bi-srv-divgdsa-pr-098bdd.common.bq_mobility_active_data\n\n\n    v0d6 @author: T892899; Mar 6th, 2024\n      - Add SHS Pro-install eligibility flag\n        - this table is still a temp table, which requires more formal solution in the future\n      - Adjust MOB offer filters\n\n\n    v0d7 @author: T892899; Mar 8th, 2024\n      - Update Offer parameter BQ table - formal source / daily update\n      - New function for cr8bqt_sql_BI\n      - Update demostats data source\n\n\n    v0d8 @author: T892899; Mar 13th, 2024\n      - Update SHS Pro-install eligibility BQ table - BI layer\n      - Rename NCID to offer_code\n      - Modify function last_dt_check\n\n\n    v0d9 @author: T892899; Mar 22th, 2024\n      - Update some project names to be a variable, for easy stg to srv update \n      - Add dwelling type to existing customers\n\n    Notes: Feb 2024\n     - SHS eligibility flag need to be added\n     - prod_cd to be changed to bq table\n     - TOS tier model need to be added\n     - HSIC tier model need to be added\n     - valid start/end date format\n        - details to confirm with Weibo/Francis\n        - 2022-01-01T00:00:00.000Z\n\n    \"\"\"\n\n    # define some functions\n    # please feel free to improve as fit\n    def cr8bqt_sql_BI(\n        clnt,\n        sql_base,\n        opt,\n        est_num\n        ): \n\n        sql_s1 =f\"\"\"\n\n            TRUNCATE TABLE `{opt}_temp`;   \n            INSERT INTO `{opt}_temp`\n            {sql_base}            \n\n            \"\"\" \n\n        crdt_s1 = clnt.query(sql_s1).to_dataframe()\n\n        tableid = opt.split('.')\n\n        sql_s2 =f\"\"\"\n\n                SELECT\n                  row_count\n                FROM `{tableid[0]}.{tableid[1]}`.__TABLES__\n                where table_id = '{tableid[2]}_temp'\n                ;\n\n            \"\"\" \n\n        crdt_s2 = clnt.query(sql_s2).to_dataframe()\n\n        if crdt_s2['row_count'][0] > est_num:\n            sql_s3 =f\"\"\"\n\n                TRUNCATE TABLE `{opt}`;   \n                INSERT INTO `{opt}`\n                select * from `{opt}_temp`\n\n            \"\"\" \n            crdt_s3 = clnt.query(sql_s3).to_dataframe()\n\n        else:\n            raise Exception(f\"{opt}_temp has {crdt_s2['row_count'][0]} rows -- seems low. Update aborted.\")\n\n    def last_dt_check(\n        clnt,\n        ipt,\n        part_dt,\n        wd\n        ): \n\n        sql_s1 =f\"\"\"\n\n            with\n                max_date1 as (\n                    SELECT \n                        0 as a\n                        , {part_dt} \n                        , count({part_dt}) as mxx\n                    FROM `{ipt}`\n                        WHERE {part_dt} >= DATE_SUB(CURRENT_DATE(), INTERVAL {wd} DAY)\n                    group by a, {part_dt}\n                    order by a, {part_dt} desc\n                    )\n                ,  max_date2 as (\n                    select\n                        0 as a\n                        , avg(mxx) as mxx_avg\n                    from max_date1\n                        group by a\n                    )\n\n                select\n                    cast(max(a.{part_dt}) AS STRING) as part_dt\n                from max_date1 a left join max_date2 b\n                on a.a = b.a\n                where a.mxx >= b.mxx_avg * 0.8\n\n        \"\"\" \n\n        crdt_s1 = clnt.query(sql_s1).to_dataframe()\n\n        return(crdt_s1['part_dt'][0])\n\n    # Beginning of Part 1\n    # Creating eligible base for existing home solutions customers\n    # Pull Offer Info\n\n    sq0l =f\"\"\"\n       with\n            max_dt as (    \n              SELECT \n              max(part_dt) as part_dt\n              FROM `{offer_parameter}` \n            )\n        select\n            Replace(a.Offer_Number, '-', '_') as Offer_Number2\n            , a.* \n            , CAST(a.valid_start_ts AS DATE FORMAT 'MON DD, YYYY') AS valid_start_dt \n            , CAST(a.valid_end_ts AS DATE FORMAT 'MON DD, YYYY') AS valid_end_dt\n        from `{offer_parameter}` a \n        inner join max_dt b\n        on a.part_dt = b.part_dt\n        where a.if_active = 1 and a.HS_filters is not null\n    \"\"\" \n\n    offer_info = client.query(sq0l).to_dataframe()\n\n    # Check latest snapshot date with reasonable counts\n\n    last_dt_spd = last_dt_check(clnt = client,\n                                ipt = 'bi-srv-divgdsa-pr-098bdd.common.bq_premise_universe',\n                                part_dt = 'part_dt',\n                                wd = 14 )\n\n    last_dt_pid = last_dt_check(clnt = client,\n                                ipt = 'bi-srv-divgdsa-pr-098bdd.common.bq_hs_product_instance_details',\n                                part_dt = 'part_load_dt',\n                                wd = 14 )\n\n    last_dt_pi = last_dt_check(clnt = client,\n                                ipt = 'bi-srv-divgdsa-pr-098bdd.common.bq_hs_product_instance',\n                                part_dt = 'part_load_dt',\n                                wd = 14 )\n\n    last_dt_gateway = last_dt_check(clnt = client,\n                                ipt = 'cio-datahub-enterprise-pr-183a.ent_resrc_config.bq_product_instance_gateway_daily_snpsht',\n                                part_dt = 'snapshot_load_dt',\n                                wd = 60 )\n\n    # last_dt_game = last_dt_check(clnt = client,\n    #                             ipt = 'cio-datahub-enterprise-pr-183a.ent_resrc_performance_device_kpi.bq_cloudcheck_game_station',\n    #                             part_dt = 'file_rcvd_dt' )\n\n    # Create Bigquery for HS customer profile - base\n    sq0l =f\"\"\"\n        with std1 as (\n            select distinct cust_id \n             from `bi-srv-divgdsa-pr-098bdd.common.bq_hs_product_instance_details`\n            where part_load_dt = '{last_dt_pid}'\n                and effective_end_dt >= CURRENT_DATE()\n                and (upper(prod_intrnl_nm) like '%TSD%'\n                     or upper(prod_intrnl_nm) like '%CONNECTING FAMILIES%'\n                     or upper(prod_intrnl_nm) like '%REALTOR%'\n                     or upper(prod_intrnl_nm) like '%STRATA%' \n                    )\n        )\n\n        , std2 as (\n\n            select distinct cust_id \n             from `bi-srv-divgdsa-pr-098bdd.common.bq_hs_product_instance_details` a \n             inner join `{prod_cd2remove}` b\n             on a.prod_cd = b.prod_cd\n            where a.part_load_dt = '{last_dt_pid}'\n                and a.effective_end_dt >= CURRENT_DATE()\n                and b.standard_exclusions = 1\n\n        )\n\n        , std as (\n            select * from std1\n            union all\n            select * from std2\n        )\n\n        , spd as (\n\n            select distinct\n                lpds_id\n                , coid \n                , snet_premise_type_cd\n            from `bi-srv-divgdsa-pr-098bdd.common.bq_premise_universe` \n            WHERE part_dt = '{last_dt_spd}'\n        )\n\n        , pid as (\n\n                select \n                  cust_id\n                  , bacct_num\n                  , max(case when access_technology = 'COPPER' then 1 else 0 end) as cpf_acctech_copper_ind\n                  , max(case when access_technology = 'FIBRE' then 1 else 0 end) as cpf_acctech_fibre_ind\n                  , max(case when access_technology = 'WIRELESS' then 1 else 0 end) as cpf_acctech_wls_ind\n                  , max(case when access_technology = 'SATELLITE' then 1 else 0 end) as cpf_acctech_satellite_ind\n                  , sum(case when service_instance_type_cd != 'DIIC' then 1 else 0 end) as cpf_prod_cnt\n                  , max(case when service_instance_type_cd = 'DIIC' then 1 else 0 end) as cpf_diic_ind\n                  , max(case when service_instance_type_cd = 'HSIC' then 1 else 0 end) as cpf_hsic_ind\n                  , max(case when service_instance_type_cd = 'HSIC' then provisioned_hs else null end) as cpf_provisioned_hs\n                  , max(case when service_instance_type_cd = 'LWC' then 1 else 0 end) as cpf_lwc_ind\n                  , max(case when service_instance_type_cd = 'PIK' then 1 else 0 end) as cpf_pik_ind\n                  , max(case when service_instance_type_cd = 'SHS' then 1 else 0 end) as cpf_shs_ind\n                  , max(case when prod_intrnl_nm in ('Smart Automation Plus', 'Smart Automation Plus (V2)'\n                          , 'Smart Camera (V2)', 'Secure Business: Smart Camera') then 1 else 0 end) as cpf_shs_ind2\n                  , max(case when service_instance_type_cd = 'SING' then 1 else 0 end) as cpf_sing_ind\n                  , max(case when service_instance_type_cd = 'STV' then 1 else 0 end) as cpf_stv_ind\n                  , max(case when service_instance_type_cd = 'SWS' then 1 else 0 end) as cpf_sws_ind\n                  , max(case when service_instance_type_cd = 'STMP' then 1 else 0 end) as cpf_stmp_ind\n                  , max(case when service_instance_type_cd = 'TOS' then 1 else 0 end) as cpf_tos_ind\n                  , max(case when service_instance_type_cd = 'TOS'\n                          and prod_cd = '40983311' then 1 else 0 end) as cpf_tos_basic_ind\n                  , max(case when service_instance_type_cd = 'TOS'\n                          and prod_cd = '41079641' then 1 else 0 end) as cpf_tos_standard_ind\n                  , max(case when service_instance_type_cd = 'TTV' then 1 else 0 end) as cpf_ttv_ind\n                  , max(case when service_instance_type_cd = 'WFP' then 1 else 0 end) as cpf_wfp_ind\n                  , max(case when service_instance_type_cd = 'WHSIA' then 1 else 0 end) as cpf_whsia_ind  \n                  , max(case when service_instance_type_cd = 'HPRO' then 1 else 0 end) as cpf_HPRO_ind   \n\n                  from `bi-srv-divgdsa-pr-098bdd.common.bq_hs_product_instance`\n                        where part_load_dt = '{last_dt_pi}'\n                      and product_instance_status_cd = 'A' and current_ind = 1\n                    group by cust_id, bacct_num\n\n        )\n\n        , pid4hproplus as (\n\n                select distinct\n                  cust_id\n                  , bacct_num\n\n                  from `bi-srv-divgdsa-pr-098bdd.common.bq_hs_product_instance`\n                        where part_load_dt = '{last_dt_pi}'\n                      and product_instance_status_cd = 'A' and current_ind = 1\n                      and service_instance_type_cd in ('HSIC','WHSIA','TTV','SHS','SWS')\n                        and si_start_dt >= DATE_SUB(CURRENT_DATE(), INTERVAL 30 DAY)\n\n        )\n\n        , pid_all as (\n\n                select distinct\n                  cust_id\n                  , bacct_num\n                  , product_instance_id\n                  from `bi-srv-divgdsa-pr-098bdd.common.bq_hs_product_instance`\n                        where part_load_dt = '{last_dt_pi}'\n                      and product_instance_status_cd = 'A' and current_ind = 1\n\n        )\n\n        , pending_orders as (\n\n                select  \n                    cust_id\n                    , lpds_id\n                    , max(case when product_family = 'TOS' then 1 else 0 end) as TOS_IND\n                    , max(case when product_family = 'HSIC' then 1 else 0 end) as HSIA_ind\n                    , max(case when product_family = 'SMHM' then 1 else 0 end) as SHS_ind\n                    , max(case when product_family = 'TTV' then 1 else 0 end) as OPTIK_TV_IND\n                    , max(case when product_family = 'SING' then 1 else 0 end) as HP_IND\n                    , max(case when product_family = 'WIFI' then 1 else 0 end) as WFP_ind\n                    , max(case when product_family = 'WHSIA' then 1 else 0 end) as SMART_HUB_IND\n                    , max(case when product_family = 'LWC' then 1 else 0 end) as LWC_ind\n                    , max(case when product_family = 'SWS' then 1 else 0 end) as SWS_ind\n                    , max(case when product_family = 'SOD' then 1 else 0 end) as SOD_ind\n                    , max(case when product_family = 'HPRO' then 1 else 0 end) as HPRO_ind\n                 from `bi-srv-hsmsd-3c-pr-ca2cd4.hsmsd_3c_rpt_dataset.bq_rpt_chnl_order_ffh_dtl_view`\n                where is_current_order = 1 and current_yield_dt >= DATE_SUB(CURRENT_DATE(), INTERVAL 100 DAY)\n                    and (current_yield_sub_status = 'Pending')\n                    and current_order_status = 'Processing'\n                    and soi_transaction_type = 'Enroll'\n                    group by 1,2\n\n        )\n\n        , ffh_bas as (\n            select \n                a.* except (OPTIK_TV_IND\n                            , HSIA_IND\n                            , HP_IND\n                            , LWC_IND\n                            , SHS_IND\n                            , SWS_IND\n                            , SMART_HUB_IND)\n\n                , case when a.OPTIK_TV_IND > 0 or k.OPTIK_TV_IND > 0 then 1 else 0 end as OPTIK_TV_IND\n                , case when a.HSIA_IND > 0 or k.HSIA_IND > 0 then 1 else 0 end as HSIA_IND\n                , case when a.HP_IND > 0 or k.HP_IND > 0 then 1 else 0 end as HP_IND\n                , case when a.SHS_IND > 0 or k.SHS_IND > 0 then 1 else 0 end as SHS_IND\n                , case when a.LWC_IND > 0 or k.LWC_IND > 0 then 1 else 0 end as LWC_IND\n                , case when a.SWS_IND > 0 or k.SWS_IND > 0 then 1 else 0 end as SWS_IND\n                , case when a.SMART_HUB_IND > 0 or k.SMART_HUB_IND > 0 then 1 else 0 end as SMART_HUB_IND\n\n                , case when b.cust_id is null then 0 else 1 end as std_exclud2\n\n                , c.* except (cust_id, bacct_num, cpf_HPRO_ind, cpf_wfp_ind, cpf_whsia_ind)\n                , case when c.cpf_whsia_ind > 0 or k.SMART_HUB_IND > 0 then 1 else 0 end as cpf_whsia_ind\n                , case when c.cpf_wfp_ind > 0 or k.WFP_ind > 0 then 1 else 0 end as cpf_wfp_ind\n                , case when c.cpf_HPRO_ind > 0 or k.HPRO_ind > 0 then 1 else 0 end as cpf_HPRO_ind\n\n                , case when (( d.HTA1519_pct > 0.25)\n                                or ( d.HTA2024_pct > 0.25)\n                                or ( d.HTA2529_pct > 0.25)\n                                or ( d.HTA3034_pct > 0.25)\n                                or ( d.HTA3539_pct > 0.25)\n                                or ( d.HTA4044_pct > 0.25)\n\n                                or ( d.HMA1519_pct > 0.25)\n                                or ( d.HMA2024_pct > 0.25)\n                                or ( d.HMA2529_pct > 0.25)\n                                or ( d.HMA3034_pct > 0.25)\n                                or ( d.HMA3539_pct > 0.25)\n                                or ( d.HMA4044_pct > 0.25)\n\n                                or ( d.HFA1519_pct > 0.25)\n                                or ( d.HFA2024_pct > 0.25)\n                                or ( d.HFA2529_pct > 0.25)\n                                or ( d.HFA3034_pct > 0.25)\n                                or ( d.HFA3539_pct > 0.25)\n                                or ( d.HFA4044_pct > 0.25)) then 1 else 0 end as demo_hs_189_ind\n\n                , case when d.baskid > 50 then 1 else 0 end as demo_hs_188_ind\n\n                , RAND() as rand_seed1\n\n                , case when e.cust_id is not null then 1 else 0 end as hs_202_ind\n\n                , f.wHSIAQualTypeMarketing\n\n                , case when g1.ACQ_DATE is not null\n                            or g2.ACQ_DATE is not null\n                            or g3.ACQ_DATE is not null\n                            then 1 else 0 end as alarm_full_universe\n\n                --, case when j.cust_id is not null then 1 else 0 end as hs_71_ind\n\n                , case when j.cust_id is not null then 1 else 0 end as hs_71_ind\n\n                , case when a.serv_prov in ('AB', 'BC') \n                        or h.Coverage_Status like '%Professional%' \n                        then 1 else 0 end as shs_professional_install\n\n                , m.snet_premise_type_cd\n\n            from `bi-srv-hsmdet-pr-7b9def.campaign_data.bq_dly_dbm_customer_profl` a\n            left join std b on a.cust_id = b.cust_id\n            left join pid c on a.cust_id = c.cust_id and a.bacct_num = c.bacct_num \n            left join `bi-srv-divgdsa-pr-098bdd.environics_derived.bq_demostats_2023_features` d\n                on a.SERV_POSTAL_CODE = d.code\n            left join pid4hproplus e on a.cust_id = e.cust_id and a.bacct_num = e.bacct_num \n            left join `{whsia_eligible_base}` f on a.LPDS_ID = f.LPDSId\n            left join `bi-srv-hsmdet-pr-7b9def.hsmdet_public.bq_pub_fda_alarm_full_universe` g1\n                on a.cust_id is not null and a.cust_id = g1.cust_id\n            left join `bi-srv-hsmdet-pr-7b9def.hsmdet_public.bq_pub_fda_alarm_full_universe` g2\n                on a.bacct_num is not null and a.bacct_num = g2.bacct_num\n            left join `bi-srv-hsmdet-pr-7b9def.hsmdet_public.bq_pub_fda_alarm_full_universe` g3\n                on a.FMS_ADDRESS_ID is not null and a.FMS_ADDRESS_ID = g3.FMS_ADDRESS_ID\n            left join `{shs_professional_install}` h on substr(a.SERV_POSTAL_CODE, 1, 3) = h.FSA\n            -- left join custid_gaming j on a.cust_id = j.cust_id and a.bacct_num = j.bacct_num \n            left join `divg-team-v03-pr-de558a.nba_offer_targeting.daily_cp_prod_gaming` j on a.cust_id = j.cust_id and cast(a.lpds_id as int64) = cast(j.lpds_id as int64)\n            left join pending_orders k on k.cust_id = cast(a.cust_id as STRING)\n                and k.LPDS_ID = cast(a.LPDS_ID as STRING) \n            left join spd m on a.LPDS_ID = m.LPDS_Id\n            where a.cust_id > 0\n\n            )\n    \"\"\" \n\n    # Create eligible base for each offer\n    sql_all = sq0l\n    n_offer = offer_info.shape[0]\n    for ii in range(n_offer):\n        ii2 = ii + 1\n\n        sql_b1 = (\n                f\"\"\", {offer_info['Offer_Number2'][ii]} as (\n                select distinct cust_id \\n\n                , bacct_num \\n\n                , lpds_id \\n\n                , ACCT_START_DT as candate \\n\n                , '{offer_info['Category'][ii]}' as Category  \\n\n                , '{offer_info['Subcategory'][ii]}' as Subcategory  \\n \n                , '' as digital_category\n                , '{offer_info['promo_seg'][ii]}' as promo_seg  \\n \n                , '{offer_info['NCID'][ii]}' as offer_code  \\n \n                , cast('{offer_info['valid_start_dt'][ii]}' AS DATE) as ASSMT_VALID_START_TS  \\n\n                , cast('{offer_info['valid_end_dt'][ii]}' AS DATE) as ASSMT_VALID_END_TS  \\n \n                , {str(offer_info['rk'][ii])} as rk  \\n\n                from ffh_bas \\n where  {offer_info['HS_filters'][ii]} )  \\n \"\"\"\n               )\n\n        sql_all0 = sql_all + sql_b1\n\n        sql_all = sql_all0\n\n    # Union eligible bases\n    sql_all0 = sql_all + f\" select * from {offer_info['Offer_Number2'][0]} \\n\"\n    sql_all = sql_all0\n    n_offer = offer_info.shape[0] - 1\n    for ii in range(n_offer):\n        ii2 = ii + 1\n        sql_b2 = f\" union all select * from {offer_info['Offer_Number2'][ii2]}  \\n\"\n        sql_all0 = sql_all + sql_b2\n        sql_all = sql_all0\n\n\n    # check base count before creating multiple eligible base\n    sq0l =\"\"\"\n\n        select\n            count(distinct bacct_num) as cnt\n        from `bi-srv-hsmdet-pr-7b9def.campaign_data.bq_dly_dbm_customer_profl`\n\n    \"\"\" \n\n    df_check = client.query(sq0l).to_dataframe()\n\n    # creating eligible base\n    start_time = time.time()\n\n    if df_check['cnt'][0] > 2_500_000:\n        cr8bqt_sql_BI(\n            clnt = client,\n            sql_base = sql_all,\n            opt = qua_base,\n            est_num = 10_000_000\n        )\n\n    else:\n        raise Exception(f\"FFH base has {df_check['cnt'][0]} rows -- seems low. Update aborted.\")\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 8.0,
              "memoryLimit": 16.0
            }
          }
        },
        "exec-reg-offers-base-prospects": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "reg_offers_base_prospects"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef reg_offers_base_prospects(project_id: str\n                            , offer_parameter: str\n                            , whsia_eligible_base: str\n                            , shs_professional_install: str\n                            , prod_cd2remove: str\n                            , qua_base: str\n                            , token: str\n                            ):\n\n    import pandas as pd\n    import sys\n    import os\n    import re\n    import time\n    from pathlib import Path\n    import pdb\n    from yaml import safe_load\n\n    from google.cloud import bigquery\n    import logging \n    from datetime import datetime\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n#     #### For prod \n#     client = bigquery.Client(project=project_id)\n#     job_config = bigquery.QueryJobConfig()\n\n    \"\"\"\n    This program creates eligible bases for three categories of customers\n      - existing home solutions customers\n      - naked mobility customers\n      - cat3\n\n    Initially drafted in Feb 2024\n      - @author: T892899\n\n\n    v0d4 @author: T892899; Feb 29, 2024\n      - update ffh_bas query to welcome 9167815983798937909\n      - double check pending orders\n\n\n    v0d5 @author: T892899; Mar 4th, 2024\n      - update a few tables\n       - bi-srv-hsmdet-pr-7b9def.campaign_data.bq_dly_dbm_customer_profl\n       - bi-srv-hsmdet-pr-7b9def.campaign_data.bq_fda_mob_mobility_base\n       - bi-srv-divgdsa-pr-098bdd.common.bq_mobility_active_data\n\n\n    v0d6 @author: T892899; Mar 6th, 2024\n      - Add SHS Pro-install eligibility flag\n        - this table is still a temp table, which requires more formal solution in the future\n      - Adjust MOB offer filters\n\n\n    v0d7 @author: T892899; Mar 8th, 2024\n      - Update Offer parameter BQ table - formal source / daily update\n      - New function for cr8bqt_sql_BI\n      - Update demostats data source\n\n\n    v0d8 @author: T892899; Mar 13th, 2024\n      - Update SHS Pro-install eligibility BQ table - BI layer\n      - Rename NCID to offer_code\n      - Modify function last_dt_check\n\n\n    v0d9 @author: T892899; Mar 22th, 2024\n      - Update some project names to be a variable, for easy stg to srv update \n      - Add dwelling type to existing customers\n\n    Notes: Feb 2024\n     - SHS eligibility flag need to be added\n     - prod_cd to be changed to bq table\n     - TOS tier model need to be added\n     - HSIC tier model need to be added\n     - valid start/end date format\n        - details to confirm with Weibo/Francis\n        - 2022-01-01T00:00:00.000Z\n\n    \"\"\"\n\n    # define some functions\n    # please feel free to improve as fit\n    def cr8bqt_sql_BI(\n        clnt,\n        sql_base,\n        opt,\n        est_num\n        ): \n\n        sql_s1 =f\"\"\"\n\n            TRUNCATE TABLE `{opt}_temp`;   \n            INSERT INTO `{opt}_temp`\n            {sql_base}            \n\n            \"\"\" \n\n        crdt_s1 = clnt.query(sql_s1).to_dataframe()\n\n        tableid = opt.split('.')\n\n        sql_s2 =f\"\"\"\n\n                SELECT\n                  row_count\n                FROM `{tableid[0]}.{tableid[1]}`.__TABLES__\n                where table_id = '{tableid[2]}_temp'\n                ;\n\n            \"\"\" \n\n        crdt_s2 = clnt.query(sql_s2).to_dataframe()\n\n        if crdt_s2['row_count'][0] > est_num:\n            sql_s3 =f\"\"\"\n\n                TRUNCATE TABLE `{opt}`;   \n                INSERT INTO `{opt}`\n                select * from `{opt}_temp`\n\n            \"\"\" \n            crdt_s3 = clnt.query(sql_s3).to_dataframe()\n\n        else:\n            raise Exception(f\"{opt}_temp has {crdt_s2['row_count'][0]} rows -- seems low. Update aborted.\")\n\n    def last_dt_check(\n        clnt,\n        ipt,\n        part_dt,\n        wd\n        ): \n\n        sql_s1 =f\"\"\"\n\n            with\n                max_date1 as (\n                    SELECT \n                        0 as a\n                        , {part_dt} \n                        , count({part_dt}) as mxx\n                    FROM `{ipt}`\n                        WHERE {part_dt} >= DATE_SUB(CURRENT_DATE(), INTERVAL {wd} DAY)\n                    group by a, {part_dt}\n                    order by a, {part_dt} desc\n                    )\n                ,  max_date2 as (\n                    select\n                        0 as a\n                        , avg(mxx) as mxx_avg\n                    from max_date1\n                        group by a\n                    )\n\n                select\n                    cast(max(a.{part_dt}) AS STRING) as part_dt\n                from max_date1 a left join max_date2 b\n                on a.a = b.a\n                where a.mxx >= b.mxx_avg * 0.8\n\n        \"\"\" \n\n        crdt_s1 = clnt.query(sql_s1).to_dataframe()\n\n        return(crdt_s1['part_dt'][0])\n\n    # Beginning of Part 2\n\n    # Creating eligible base for Naked mobility customers\n\n\n    # Pull Offer Info\n\n    sq0l =f\"\"\"\n\n       with\n            max_dt as (    \n              SELECT \n              max(part_dt) as part_dt\n              FROM `{offer_parameter}` \n            )\n        select\n            Replace(a.Offer_Number, '-', '_') as Offer_Number2\n            , a.* \n            , CAST(a.valid_start_ts AS DATE FORMAT 'MON DD, YYYY') AS valid_start_dt \n            , CAST(a.valid_end_ts AS DATE FORMAT 'MON DD, YYYY') AS valid_end_dt\n        from `{offer_parameter}` a \n        inner join max_dt b\n        on a.part_dt = b.part_dt\n        where a.if_active = 1 and a.MOB_filters is not null\n\n    \"\"\" \n\n    offer_info = client.query(sq0l).to_dataframe()\n\n    # Check latest snapshot date with reasonable counts\n\n    last_dt_spd = last_dt_check(clnt = client,\n                                ipt = 'bi-srv-divgdsa-pr-098bdd.common.bq_premise_universe',\n                                part_dt = 'part_dt',\n                                wd = 14 )\n\n    last_dt_pi = last_dt_check(clnt = client,\n                                ipt = 'bi-srv-divgdsa-pr-098bdd.common.bq_hs_product_instance',\n                                part_dt = 'part_load_dt',\n                                wd = 14 )\n\n    last_dt_mlpds = last_dt_check(clnt = client,\n                                ipt = 'bi-srv-divgdsa-pr-098bdd.common.bq_mobility_active_data',\n                                part_dt = 'part_dt',\n                                wd = 14 )\n\n    # Create Naked Mobility customer profile - base\n\n    sq0l =f\"\"\"\n\n        with\n\n        mob_lpds_id as (\n\n            select *\n            from `bi-srv-divgdsa-pr-098bdd.common.bq_mobility_active_data` \n            WHERE part_dt = '{last_dt_mlpds}'\n        )\n\n        , mob as (\n            SELECT distinct \n                fmbase.BAN, \n                fmbase.INIT_ACTIVATION_DATE as mobdate,\n                fmbase.PROVINCE,  \n                fmbase.POSTCODE, \n                fmbase.DEVICE_NAME,\n                fmbase.MNH_FFH_BAN,\n                fmbase.LANG_PREF,\n                CASE WHEN fmbase.LPDS_ID>0 then fmbase.LPDS_ID ELSE mad.LPDS_ID end as LPDS_ID\n\n            FROM `bi-srv-hsmdet-pr-7b9def.campaign_data.bq_fda_mob_mobility_base`  fmbase\n                left join mob_lpds_id mad\n                on fmbase.ban = cast(mad.ban as int)\n            WHERE fmbase.BRAND_ID =1\n                and fmbase.product_type  in   ('C','I')\n                and fmbase.account_type  in    ('I','C') \n                and fmbase.ACCOUNT_SUB_TYPE in ('I','R','E')\n                and (fmbase.MNH_FFH_BAN = 0 or fmbase.MNH_FFH_BAN is null)\n                and fmbase.PRIMARY_SUB = 1\n                and fmbase.SUB_STATUS = 'A'\n                and fmbase.STANDARD_EXCLUSIONS = 0 \n                and fmbase.STOP_SELL = 0\n        ),\n\n        spd as (\n\n            select \n                lpds_id\n                , hs_max_speed \n                , hs_max_speed_bonded\n                , obd_eligible_ind \n                , coid \n                , snet_premise_type_cd\n                , ttv_port_availability \n            from `bi-srv-divgdsa-pr-098bdd.common.bq_premise_universe` \n            WHERE part_dt = '{last_dt_spd}'\n        ),\n\n        pid as (\n\n                select \n                  lpds_id \n                  , max(case when access_technology = 'COPPER' then 1 else 0 end) as cpf_acctech_copper_ind\n                  , max(case when access_technology = 'FIBRE' then 1 else 0 end) as cpf_acctech_fibre_ind\n                  , max(case when access_technology = 'WIRELESS' then 1 else 0 end) as cpf_acctech_wls_ind\n                  , max(case when access_technology = 'SATELLITE' then 1 else 0 end) as cpf_acctech_satellite_ind\n                  , sum(case when service_instance_type_cd != 'DIIC' then 1 else 0 end) as cpf_prod_cnt\n                  , max(case when service_instance_type_cd = 'DIIC' then 1 else 0 end) as cpf_diic_ind\n                  , max(case when service_instance_type_cd = 'HSIC' then 1 else 0 end) as cpf_hsic_ind\n                  , max(case when service_instance_type_cd = 'HSIC' then provisioned_hs else null end) as cpf_provisioned_hs\n                  , max(case when service_instance_type_cd = 'LWC' then 1 else 0 end) as cpf_lwc_ind\n                  , max(case when service_instance_type_cd = 'PIK' then 1 else 0 end) as cpf_pik_ind\n                  , max(case when service_instance_type_cd = 'SHS' then 1 else 0 end) as cpf_shs_ind\n                  , max(case when prod_intrnl_nm in ('Smart Automation Plus', 'Smart Automation Plus (V2)'\n                          , 'Smart Camera (V2)', 'Secure Business: Smart Camera') then 1 else 0 end) as cpf_shs_ind2\n                  , max(case when service_instance_type_cd = 'SING' then 1 else 0 end) as cpf_sing_ind\n                  , max(case when service_instance_type_cd = 'STV' then 1 else 0 end) as cpf_stv_ind\n                  , max(case when service_instance_type_cd = 'SWS' then 1 else 0 end) as cpf_sws_ind\n                  , max(case when service_instance_type_cd = 'STMP' then 1 else 0 end) as cpf_stmp_ind\n                  , max(case when service_instance_type_cd = 'TOS' then 1 else 0 end) as cpf_tos_ind\n                  , max(case when service_instance_type_cd = 'TTV' then 1 else 0 end) as cpf_ttv_ind\n                  , max(case when service_instance_type_cd = 'WFP' then 1 else 0 end) as cpf_wfp_ind\n                  , max(case when service_instance_type_cd = 'WHSIA' then 1 else 0 end) as cpf_whsia_ind  \n                  , max(case when service_instance_type_cd = 'HPRO' then 1 else 0 end) as cpf_HPRO_ind  \n\n                  from `bi-srv-divgdsa-pr-098bdd.common.bq_hs_product_instance`\n                        where part_load_dt = '{last_dt_pi}'\n                      and product_instance_status_cd = 'A' and current_ind = 1\n                    group by lpds_id\n\n        )\n\n        , pending_orders as (\n\n                select  \n                    lpds_id\n                    , max(case when product_family = 'TOS' then 1 else 0 end) as TOS_IND\n                    , max(case when product_family = 'HSIC' then 1 else 0 end) as HSIA_ind\n                    , max(case when product_family = 'SMHM' then 1 else 0 end) as SHS_ind\n                    , max(case when product_family = 'TTV' then 1 else 0 end) as OPTIK_TV_IND\n                    , max(case when product_family = 'SING' then 1 else 0 end) as HP_IND\n                    , max(case when product_family = 'WIFI' then 1 else 0 end) as WFP_ind\n                    , max(case when product_family = 'WHSIA' then 1 else 0 end) as SMART_HUB_IND\n                    , max(case when product_family = 'LWC' then 1 else 0 end) as LWC_ind\n                    , max(case when product_family = 'SWS' then 1 else 0 end) as SWS_ind\n                    , max(case when product_family = 'SOD' then 1 else 0 end) as SOD_ind\n                    , max(case when product_family = 'HPRO' then 1 else 0 end) as HPRO_ind\n                 from `bi-srv-hsmsd-3c-pr-ca2cd4.hsmsd_3c_rpt_dataset.bq_rpt_chnl_order_ffh_dtl_view`\n                where is_current_order = 1 and current_yield_dt >= DATE_SUB(CURRENT_DATE(), INTERVAL 100 DAY)\n                    and (current_yield_sub_status = 'Pending')\n                    and current_order_status = 'Processing'\n                    and soi_transaction_type = 'Enroll'\n                    group by 1\n\n        )\n\n\n        , pid_pending as (\n\n                select distinct\n                  case when a.lpds_id is not null then a.lpds_id else b.lpds_id end as lpds_id  \n                  , case when a.cpf_hsic_ind > 0 or b.HSIA_IND > 0 then 1 else 0 end as cpf_hsic_ind\n                  , case when a.cpf_lwc_ind > 0 or b.LWC_ind > 0 then 1 else 0 end as cpf_lwc_ind\n                  , a.cpf_pik_ind\n                  , case when a.cpf_shs_ind > 0 or b.SHS_ind > 0 then 1 else 0 end as cpf_shs_ind\n                  , case when a.cpf_sing_ind > 0 or b.HP_IND > 0 then 1 else 0 end as cpf_sing_ind\n                  , case when a.cpf_sws_ind > 0 or b.SWS_ind > 0 then 1 else 0 end as cpf_sws_ind\n                  , case when a.cpf_ttv_ind > 0 or b.OPTIK_TV_IND > 0 then 1 else 0 end as cpf_ttv_ind\n                  , a.cpf_stv_ind\n                  , case when a.cpf_tos_ind > 0 or b.TOS_IND > 0 then 1 else 0 end as cpf_tos_ind\n                  , case when a.cpf_wfp_ind > 0 or b.WFP_ind > 0 then 1 else 0 end as cpf_wfp_ind\n                  , case when a.cpf_whsia_ind > 0 or b.SMART_HUB_IND > 0 then 1 else 0 end as cpf_whsia_ind\n                  , case when a.cpf_HPRO_ind > 0 or b.HPRO_ind > 0 then 1 else 0 end as cpf_HPRO_ind\n\n                  from pid a full join pending_orders b \n                      on b.LPDS_ID = a.LPDS_ID\n\n        )\n\n        , mob_base as (\n\n            select distinct \n                a.*\n                , p.* except (LPDS_ID)\n                , c.* except (LPDS_ID)\n                , case when (( d.HTA1519_pct > 0.25)\n                                or ( d.HTA2024_pct > 0.25)\n                                or ( d.HTA2529_pct > 0.25)\n                                or ( d.HTA3034_pct > 0.25)\n                                or ( d.HTA3539_pct > 0.25)\n                                or ( d.HTA4044_pct > 0.25)\n\n                                or ( d.HMA1519_pct > 0.25)\n                                or ( d.HMA2024_pct > 0.25)\n                                or ( d.HMA2529_pct > 0.25)\n                                or ( d.HMA3034_pct > 0.25)\n                                or ( d.HMA3539_pct > 0.25)\n                                or ( d.HMA4044_pct > 0.25)\n\n                                or ( d.HFA1519_pct > 0.25)\n                                or ( d.HFA2024_pct > 0.25)\n                                or ( d.HFA2529_pct > 0.25)\n                                or ( d.HFA3034_pct > 0.25)\n                                or ( d.HFA3539_pct > 0.25)\n                                or ( d.HFA4044_pct > 0.25)) then 1 else 0 end as demo_hs_189_ind\n\n                , case when d.baskid > 50 \n                            or upper(a.DEVICE_NAME) like '%APPLE%'\n                            or upper(a.DEVICE_NAME) like '%IPAD%'\n                            or upper(a.DEVICE_NAME) like '%IPHONE%'\n                            then 1 else 0 end as demo_hs_188_ind\n                , RAND() as rand_seed1\n                , case when e.ban > 0 then 1 else 0 end as mob_shs\n                , f.wHSIAQualTypeMarketing\n                , case when a.PROVINCE in ('AB', 'BC') \n                        or b.Coverage_Status like '%Professional%' \n                    then 1 else 0 end as shs_professional_install\n\n            from mob a \n                left join spd p on a.lpds_id = p.lpds_id  \n                left join `{shs_professional_install}` b on substr(a.POSTCODE, 1, 3) = b.FSA\n                left join pid_pending c on cast(a.lpds_id as STRING) = c.LPDS_ID \n                left join `bi-srv-divgdsa-pr-098bdd.environics_derived.bq_demostats_2023_features` d\n                on a.postcode = d.code\n                left join `bi-srv-hsmdet-pr-7b9def.hsmdet_public.bq_pub_fda_alarm_full_universe` e \n                on (a.ban is not null and a.ban = e.ban)\n                left join `{whsia_eligible_base}` f on a.LPDS_ID = f.LPDSId\n            where a.ban > 0\n       )\n\n    \"\"\" \n\n    # Create eligible base for each offer\n\n    sql_all = sq0l\n    n_offer = offer_info.shape[0]\n    for ii in range(n_offer):\n        ii2 = ii + 1\n\n        sql_b1 = (\n                f\"\"\", {offer_info['Offer_Number2'][ii]} as (\n                select distinct ban \\n\n                , lpds_id \\n\n                , mobdate as candate \\n\n                , '{offer_info['Category'][ii]}' as Category  \\n\n                , '{offer_info['Subcategory'][ii]}' as Subcategory  \\n \n                , '' as digital_category\n                , '{offer_info['promo_seg'][ii]}' as promo_seg  \\n \n                , '{offer_info['NCID'][ii]}' as offer_code  \\n \n                , cast('{offer_info['valid_start_dt'][ii]}' AS DATE) as ASSMT_VALID_START_TS  \\n\n                , cast('{offer_info['valid_end_dt'][ii]}' AS DATE) as ASSMT_VALID_END_TS  \\n \n                , {str(offer_info['rk'][ii])} as rk  \\n\n                from mob_base \\n where  {offer_info['MOB_filters'][ii]} )  \\n \"\"\"\n               )\n\n        sql_all0 = sql_all + sql_b1\n\n        sql_all = sql_all0\n\n\n\n    # Union eligible bases\n\n    sql_all0 = sql_all + f\" select * from {offer_info['Offer_Number2'][0]} \\n\"\n    sql_all = sql_all0\n    n_offer = offer_info.shape[0] - 1\n    for ii in range(n_offer):\n        ii2 = ii + 1\n        sql_b2 = f\" union all select * from {offer_info['Offer_Number2'][ii2]}  \\n\"\n        sql_all0 = sql_all + sql_b2\n        sql_all = sql_all0\n\n\n\n    # check base count before creating multiple eligible base\n    # \n\n    sq0l =\"\"\"\n\n        select\n            count(distinct fmbase.BAN) as cnt\n\n        FROM `bi-srv-hsmdet-pr-7b9def.campaign_data.bq_fda_mob_mobility_base`  fmbase\n        WHERE fmbase.BRAND_ID =1\n            and fmbase.product_type  in   ('C','I')\n            and fmbase.account_type  in    ('I','C') \n            and fmbase.ACCOUNT_SUB_TYPE in ('I','R','E')\n            and (fmbase.MNH_FFH_BAN = 0 or fmbase.MNH_FFH_BAN is null)\n            and fmbase.PRIMARY_SUB = 1\n            and fmbase.SUB_STATUS = 'A'\n            and fmbase.STANDARD_EXCLUSIONS = 0 \n            and fmbase.STOP_SELL = 0\n\n    \"\"\" \n\n    df_check = client.query(sq0l).to_dataframe()\n\n    # print(sql_all)\n\n    # creating eligible base\n\n    start_time = time.time()\n\n    if df_check['cnt'][0] > 800_000:\n        cr8bqt_sql_BI(\n            clnt = client,\n            sql_base = sql_all,\n            opt = qua_base,\n            est_num = 4_000_000\n        )\n\n    else:\n        raise Exception(f\"Naked Mobility base has {df_check['cnt'][0]} rows -- seems low. Update aborted.\")\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 16.0,
              "memoryLimit": 32.0
            }
          }
        }
      }
    },
    "pipelineInfo": {
      "name": "nba-offer-targeting-serving-pipeline"
    },
    "root": {
      "dag": {
        "tasks": {
          "bq-create-dataset": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-bq-create-dataset"
            },
            "dependentTasks": [
              "reg-offers-base-existing"
            ],
            "inputs": {
              "parameters": {
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "nba_offer_targeting"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0Ad52N3-_JEn8o-5STK8c-w6Uy60oc6JeqGD0zUjANzDB_owBN17XgyfG4yzU-Z32KiiUNtTpXHsaitYcGjkt9EzD5oTC9I0xfsKUiz0l3Z_lbcQt4YtYlGkYj3DA-N6vsSvF5_uGf7G2LoLOQK3AoQ9KaA230jqts1umwa4jYMoaCgYKAc4SARISFQHGX2Minp0iAJwYDNaadotIEWokJQ0178"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "bq-create-dataset"
            }
          },
          "bq-export-to-bq": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-bq-export-to-bq"
            },
            "dependentTasks": [
              "postprocess",
              "postprocess-2",
              "postprocess-3"
            ],
            "inputs": {
              "parameters": {
                "casa_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/bq_irpc_casa_base_postprocess.csv"
                    }
                  }
                },
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "nba_offer_targeting"
                    }
                  }
                },
                "digital_1p_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/bq_irpc_digital_1p_base_postprocess.csv"
                    }
                  }
                },
                "digital_2p_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/bq_irpc_digital_2p_base_postprocess.csv"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4"
                    }
                  }
                },
                "save_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/irpc_offers_assigned_existing_customers.csv"
                    }
                  }
                },
                "table_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "qua_base_hs"
                    }
                  }
                },
                "temp_table": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "qua_base_hs_irpc"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0Ad52N3-_JEn8o-5STK8c-w6Uy60oc6JeqGD0zUjANzDB_owBN17XgyfG4yzU-Z32KiiUNtTpXHsaitYcGjkt9EzD5oTC9I0xfsKUiz0l3Z_lbcQt4YtYlGkYj3DA-N6vsSvF5_uGf7G2LoLOQK3AoQ9KaA230jqts1umwa4jYMoaCgYKAc4SARISFQHGX2Minp0iAJwYDNaadotIEWokJQ0178"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "bq-export-to-bq"
            }
          },
          "bq-import-tbl-to-df": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-bq-import-tbl-to-df"
            },
            "dependentTasks": [
              "bq-create-dataset"
            ],
            "inputs": {
              "parameters": {
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "nba_offer_targeting"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4"
                    }
                  }
                },
                "save_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/bq_irpc_digital_1p_base.csv"
                    }
                  }
                },
                "table_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "bq_irpc_digital_1p_base"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0Ad52N3-_JEn8o-5STK8c-w6Uy60oc6JeqGD0zUjANzDB_owBN17XgyfG4yzU-Z32KiiUNtTpXHsaitYcGjkt9EzD5oTC9I0xfsKUiz0l3Z_lbcQt4YtYlGkYj3DA-N6vsSvF5_uGf7G2LoLOQK3AoQ9KaA230jqts1umwa4jYMoaCgYKAc4SARISFQHGX2Minp0iAJwYDNaadotIEWokJQ0178"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "bq-import-tbl-to-df"
            }
          },
          "bq-import-tbl-to-df-2": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-bq-import-tbl-to-df-2"
            },
            "dependentTasks": [
              "bq-import-tbl-to-df"
            ],
            "inputs": {
              "parameters": {
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "nba_offer_targeting"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4"
                    }
                  }
                },
                "save_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/irpc_offer_1p_plans.csv"
                    }
                  }
                },
                "table_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "irpc_offer_1p_plans"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0Ad52N3-_JEn8o-5STK8c-w6Uy60oc6JeqGD0zUjANzDB_owBN17XgyfG4yzU-Z32KiiUNtTpXHsaitYcGjkt9EzD5oTC9I0xfsKUiz0l3Z_lbcQt4YtYlGkYj3DA-N6vsSvF5_uGf7G2LoLOQK3AoQ9KaA230jqts1umwa4jYMoaCgYKAc4SARISFQHGX2Minp0iAJwYDNaadotIEWokJQ0178"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "bq-import-tbl-to-df-2"
            }
          },
          "bq-import-tbl-to-df-3": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-bq-import-tbl-to-df-3"
            },
            "dependentTasks": [
              "bq-import-tbl-to-df-2"
            ],
            "inputs": {
              "parameters": {
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "nba_offer_targeting"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4"
                    }
                  }
                },
                "save_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/irpc_offer_prices.csv"
                    }
                  }
                },
                "table_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "irpc_offer_prices"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0Ad52N3-_JEn8o-5STK8c-w6Uy60oc6JeqGD0zUjANzDB_owBN17XgyfG4yzU-Z32KiiUNtTpXHsaitYcGjkt9EzD5oTC9I0xfsKUiz0l3Z_lbcQt4YtYlGkYj3DA-N6vsSvF5_uGf7G2LoLOQK3AoQ9KaA230jqts1umwa4jYMoaCgYKAc4SARISFQHGX2Minp0iAJwYDNaadotIEWokJQ0178"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "bq-import-tbl-to-df-3"
            }
          },
          "bq-import-tbl-to-df-4": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-bq-import-tbl-to-df-4"
            },
            "dependentTasks": [
              "bq-create-dataset"
            ],
            "inputs": {
              "parameters": {
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "nba_offer_targeting"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4"
                    }
                  }
                },
                "save_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/bq_irpc_digital_2p_base.csv"
                    }
                  }
                },
                "table_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "bq_irpc_digital_2p_base"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0Ad52N3-_JEn8o-5STK8c-w6Uy60oc6JeqGD0zUjANzDB_owBN17XgyfG4yzU-Z32KiiUNtTpXHsaitYcGjkt9EzD5oTC9I0xfsKUiz0l3Z_lbcQt4YtYlGkYj3DA-N6vsSvF5_uGf7G2LoLOQK3AoQ9KaA230jqts1umwa4jYMoaCgYKAc4SARISFQHGX2Minp0iAJwYDNaadotIEWokJQ0178"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "bq-import-tbl-to-df-4"
            }
          },
          "bq-import-tbl-to-df-5": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-bq-import-tbl-to-df-5"
            },
            "dependentTasks": [
              "bq-import-tbl-to-df-4"
            ],
            "inputs": {
              "parameters": {
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "nba_offer_targeting"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4"
                    }
                  }
                },
                "save_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/irpc_offer_2p_plans.csv"
                    }
                  }
                },
                "table_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "irpc_offer_2p_plans"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0Ad52N3-_JEn8o-5STK8c-w6Uy60oc6JeqGD0zUjANzDB_owBN17XgyfG4yzU-Z32KiiUNtTpXHsaitYcGjkt9EzD5oTC9I0xfsKUiz0l3Z_lbcQt4YtYlGkYj3DA-N6vsSvF5_uGf7G2LoLOQK3AoQ9KaA230jqts1umwa4jYMoaCgYKAc4SARISFQHGX2Minp0iAJwYDNaadotIEWokJQ0178"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "bq-import-tbl-to-df-5"
            }
          },
          "bq-import-tbl-to-df-6": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-bq-import-tbl-to-df-6"
            },
            "dependentTasks": [
              "bq-create-dataset"
            ],
            "inputs": {
              "parameters": {
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "nba_offer_targeting"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4"
                    }
                  }
                },
                "save_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/bq_irpc_casa_base.csv"
                    }
                  }
                },
                "table_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "bq_irpc_casa_base"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0Ad52N3-_JEn8o-5STK8c-w6Uy60oc6JeqGD0zUjANzDB_owBN17XgyfG4yzU-Z32KiiUNtTpXHsaitYcGjkt9EzD5oTC9I0xfsKUiz0l3Z_lbcQt4YtYlGkYj3DA-N6vsSvF5_uGf7G2LoLOQK3AoQ9KaA230jqts1umwa4jYMoaCgYKAc4SARISFQHGX2Minp0iAJwYDNaadotIEWokJQ0178"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "bq-import-tbl-to-df-6"
            }
          },
          "nba-ffh-offer-ranking": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-nba-ffh-offer-ranking"
            },
            "dependentTasks": [
              "bq-export-to-bq",
              "reg-offers-base-cat3",
              "reg-offers-base-prospects"
            ],
            "inputs": {
              "parameters": {
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "nba_offer_targeting"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0Ad52N3-_JEn8o-5STK8c-w6Uy60oc6JeqGD0zUjANzDB_owBN17XgyfG4yzU-Z32KiiUNtTpXHsaitYcGjkt9EzD5oTC9I0xfsKUiz0l3Z_lbcQt4YtYlGkYj3DA-N6vsSvF5_uGf7G2LoLOQK3AoQ9KaA230jqts1umwa4jYMoaCgYKAc4SARISFQHGX2Minp0iAJwYDNaadotIEWokJQ0178"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "nba-ffh-offer-ranking"
            }
          },
          "offer-attachment-casa": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-offer-attachment-casa"
            },
            "dependentTasks": [
              "bq-import-tbl-to-df-2",
              "bq-import-tbl-to-df-3",
              "bq-import-tbl-to-df-6"
            ],
            "inputs": {
              "parameters": {
                "channel": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "casa"
                    }
                  }
                },
                "irpc_base_csv": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/bq_irpc_casa_base.csv"
                    }
                  }
                },
                "irpc_offer_plans_csv": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/irpc_offer_1p_plans.csv"
                    }
                  }
                },
                "irpc_offer_prices_csv": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/irpc_offer_prices.csv"
                    }
                  }
                },
                "save_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/bq_irpc_casa_base_with_offers.csv"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "offer-attachment-casa"
            }
          },
          "offer-attachment-digital": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-offer-attachment-digital"
            },
            "dependentTasks": [
              "bq-import-tbl-to-df-3"
            ],
            "inputs": {
              "parameters": {
                "channel": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "digital"
                    }
                  }
                },
                "irpc_base_csv": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/bq_irpc_digital_1p_base.csv"
                    }
                  }
                },
                "irpc_offer_plans_csv": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/irpc_offer_1p_plans.csv"
                    }
                  }
                },
                "irpc_offer_prices_csv": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/irpc_offer_prices.csv"
                    }
                  }
                },
                "save_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/bq_irpc_digital_1p_base_with_offers.csv"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "offer-attachment-digital"
            }
          },
          "offer-attachment-digital-2": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-offer-attachment-digital-2"
            },
            "dependentTasks": [
              "bq-import-tbl-to-df-3",
              "bq-import-tbl-to-df-5"
            ],
            "inputs": {
              "parameters": {
                "channel": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "digital"
                    }
                  }
                },
                "irpc_base_csv": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/bq_irpc_digital_2p_base.csv"
                    }
                  }
                },
                "irpc_offer_plans_csv": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/irpc_offer_2p_plans.csv"
                    }
                  }
                },
                "irpc_offer_prices_csv": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/irpc_offer_prices.csv"
                    }
                  }
                },
                "save_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/bq_irpc_digital_2p_base_with_offers.csv"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "offer-attachment-digital-2"
            }
          },
          "postprocess": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-postprocess"
            },
            "dependentTasks": [
              "offer-attachment-digital"
            ],
            "inputs": {
              "parameters": {
                "base_type": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "digital_1p"
                    }
                  }
                },
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "nba_offer_targeting"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4"
                    }
                  }
                },
                "read_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/bq_irpc_digital_1p_base_with_offers.csv"
                    }
                  }
                },
                "save_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/bq_irpc_digital_1p_base_postprocess.csv"
                    }
                  }
                },
                "table_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "nba_digital_offer_details"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0Ad52N3-_JEn8o-5STK8c-w6Uy60oc6JeqGD0zUjANzDB_owBN17XgyfG4yzU-Z32KiiUNtTpXHsaitYcGjkt9EzD5oTC9I0xfsKUiz0l3Z_lbcQt4YtYlGkYj3DA-N6vsSvF5_uGf7G2LoLOQK3AoQ9KaA230jqts1umwa4jYMoaCgYKAc4SARISFQHGX2Minp0iAJwYDNaadotIEWokJQ0178"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "postprocess"
            }
          },
          "postprocess-2": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-postprocess-2"
            },
            "dependentTasks": [
              "offer-attachment-digital-2"
            ],
            "inputs": {
              "parameters": {
                "base_type": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "digital_2p"
                    }
                  }
                },
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "nba_offer_targeting"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4"
                    }
                  }
                },
                "read_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/bq_irpc_digital_2p_base_with_offers.csv"
                    }
                  }
                },
                "save_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/bq_irpc_digital_2p_base_postprocess.csv"
                    }
                  }
                },
                "table_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "nba_digital_offer_details"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0Ad52N3-_JEn8o-5STK8c-w6Uy60oc6JeqGD0zUjANzDB_owBN17XgyfG4yzU-Z32KiiUNtTpXHsaitYcGjkt9EzD5oTC9I0xfsKUiz0l3Z_lbcQt4YtYlGkYj3DA-N6vsSvF5_uGf7G2LoLOQK3AoQ9KaA230jqts1umwa4jYMoaCgYKAc4SARISFQHGX2Minp0iAJwYDNaadotIEWokJQ0178"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "postprocess-2"
            }
          },
          "postprocess-3": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-postprocess-3"
            },
            "dependentTasks": [
              "offer-attachment-casa"
            ],
            "inputs": {
              "parameters": {
                "base_type": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "casa"
                    }
                  }
                },
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "nba_offer_targeting"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4"
                    }
                  }
                },
                "read_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/bq_irpc_casa_base_with_offers.csv"
                    }
                  }
                },
                "save_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/bq_irpc_casa_base_postprocess.csv"
                    }
                  }
                },
                "table_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "nba_casa_offer_details"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0Ad52N3-_JEn8o-5STK8c-w6Uy60oc6JeqGD0zUjANzDB_owBN17XgyfG4yzU-Z32KiiUNtTpXHsaitYcGjkt9EzD5oTC9I0xfsKUiz0l3Z_lbcQt4YtYlGkYj3DA-N6vsSvF5_uGf7G2LoLOQK3AoQ9KaA230jqts1umwa4jYMoaCgYKAc4SARISFQHGX2Minp0iAJwYDNaadotIEWokJQ0178"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "postprocess-3"
            }
          },
          "reg-offers-base-cat3": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-reg-offers-base-cat3"
            },
            "inputs": {
              "parameters": {
                "offer_parameter": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "bi-stg-mobilityds-pr-db8ce2.nba_ot.bq_offering_target_params_upd"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4"
                    }
                  }
                },
                "qua_base": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4.nba_offer_targeting.qua_base_cat3"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0Ad52N3-_JEn8o-5STK8c-w6Uy60oc6JeqGD0zUjANzDB_owBN17XgyfG4yzU-Z32KiiUNtTpXHsaitYcGjkt9EzD5oTC9I0xfsKUiz0l3Z_lbcQt4YtYlGkYj3DA-N6vsSvF5_uGf7G2LoLOQK3AoQ9KaA230jqts1umwa4jYMoaCgYKAc4SARISFQHGX2Minp0iAJwYDNaadotIEWokJQ0178"
                    }
                  }
                },
                "whsia_eligible_base": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-team-v03-pr-de558a.nba_offer_targeting.bq_whsiagtm4testing"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "reg-offers-base-cat3"
            }
          },
          "reg-offers-base-existing": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-reg-offers-base-existing"
            },
            "inputs": {
              "parameters": {
                "offer_parameter": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "bi-stg-mobilityds-pr-db8ce2.nba_ot.bq_offering_target_params_upd"
                    }
                  }
                },
                "prod_cd2remove": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4.nba_offer_targeting.prod_cd_exclusions"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4"
                    }
                  }
                },
                "qua_base": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4.nba_offer_targeting.qua_base_hs"
                    }
                  }
                },
                "shs_professional_install": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-team-v03-pr-de558a.OT.SHS_FSA_List_native"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0Ad52N3-_JEn8o-5STK8c-w6Uy60oc6JeqGD0zUjANzDB_owBN17XgyfG4yzU-Z32KiiUNtTpXHsaitYcGjkt9EzD5oTC9I0xfsKUiz0l3Z_lbcQt4YtYlGkYj3DA-N6vsSvF5_uGf7G2LoLOQK3AoQ9KaA230jqts1umwa4jYMoaCgYKAc4SARISFQHGX2Minp0iAJwYDNaadotIEWokJQ0178"
                    }
                  }
                },
                "whsia_eligible_base": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-team-v03-pr-de558a.nba_offer_targeting.bq_whsiagtm4testing"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "reg-offers-base-existing"
            }
          },
          "reg-offers-base-prospects": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-reg-offers-base-prospects"
            },
            "inputs": {
              "parameters": {
                "offer_parameter": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "bi-stg-mobilityds-pr-db8ce2.nba_ot.bq_offering_target_params_upd"
                    }
                  }
                },
                "prod_cd2remove": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4.nba_offer_targeting.prod_cd_exclusions"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4"
                    }
                  }
                },
                "qua_base": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4.nba_offer_targeting.qua_base_mob"
                    }
                  }
                },
                "shs_professional_install": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-team-v03-pr-de558a.OT.SHS_FSA_List_native"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0Ad52N3-_JEn8o-5STK8c-w6Uy60oc6JeqGD0zUjANzDB_owBN17XgyfG4yzU-Z32KiiUNtTpXHsaitYcGjkt9EzD5oTC9I0xfsKUiz0l3Z_lbcQt4YtYlGkYj3DA-N6vsSvF5_uGf7G2LoLOQK3AoQ9KaA230jqts1umwa4jYMoaCgYKAc4SARISFQHGX2Minp0iAJwYDNaadotIEWokJQ0178"
                    }
                  }
                },
                "whsia_eligible_base": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-team-v03-pr-de558a.nba_offer_targeting.bq_whsiagtm4testing"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "reg-offers-base-prospects"
            }
          }
        }
      },
      "inputDefinitions": {
        "parameters": {
          "file_bucket": {
            "type": "STRING"
          },
          "project_id": {
            "type": "STRING"
          },
          "region": {
            "type": "STRING"
          },
          "resource_bucket": {
            "type": "STRING"
          }
        }
      }
    },
    "schemaVersion": "2.0.0",
    "sdkVersion": "kfp-1.8.18"
  },
  "runtimeConfig": {
    "parameters": {
      "file_bucket": {
        "stringValue": "divg-groovyhoon-pr-d2eab4-default"
      },
      "project_id": {
        "stringValue": "divg-groovyhoon-pr-d2eab4"
      },
      "region": {
        "stringValue": "northamerica-northeast1"
      },
      "resource_bucket": {
        "stringValue": "divg-groovyhoon-pr-d2eab4-default"
      }
    }
  }
}