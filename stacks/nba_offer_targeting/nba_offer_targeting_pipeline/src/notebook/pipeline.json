{
  "pipelineSpec": {
    "components": {
      "comp-bq-create-dataset": {
        "executorLabel": "exec-bq-create-dataset",
        "inputDefinitions": {
          "parameters": {
            "dataset_id": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "token": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-bq-import-tbl-to-df": {
        "executorLabel": "exec-bq-import-tbl-to-df",
        "inputDefinitions": {
          "parameters": {
            "dataset_id": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "save_data_path": {
              "type": "STRING"
            },
            "table_id": {
              "type": "STRING"
            },
            "token": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "parameters": {
            "col_list": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-bq-import-tbl-to-df-2": {
        "executorLabel": "exec-bq-import-tbl-to-df-2",
        "inputDefinitions": {
          "parameters": {
            "dataset_id": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "save_data_path": {
              "type": "STRING"
            },
            "table_id": {
              "type": "STRING"
            },
            "token": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "parameters": {
            "col_list": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-bq-import-tbl-to-df-3": {
        "executorLabel": "exec-bq-import-tbl-to-df-3",
        "inputDefinitions": {
          "parameters": {
            "dataset_id": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "save_data_path": {
              "type": "STRING"
            },
            "table_id": {
              "type": "STRING"
            },
            "token": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "parameters": {
            "col_list": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-offer-attachment-digital": {
        "executorLabel": "exec-offer-attachment-digital",
        "inputDefinitions": {
          "parameters": {
            "channel": {
              "type": "STRING"
            },
            "irpc_base_csv": {
              "type": "STRING"
            },
            "irpc_offer_plans_csv": {
              "type": "STRING"
            },
            "irpc_offer_prices_csv": {
              "type": "STRING"
            },
            "save_data_path": {
              "type": "STRING"
            }
          }
        }
      }
    },
    "deploymentSpec": {
      "executors": {
        "exec-bq-create-dataset": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "bq_create_dataset"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef bq_create_dataset(project_id: str\n                      , dataset_id: str\n                      , token: str\n                      ):\n\n    from google.cloud import bigquery\n    import logging \n    from datetime import datetime\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n#     #### For prod \n#     client = bigquery.Client(project=project_id)\n#     job_config = bigquery.QueryJobConfig()\n\n    # Change dataset / table + sp table name to version in bi-layer\n    query =\\\n        f'''        \n            -- Change dataset / sp name to the version in the bi_layer\n            CALL nba_offer_targeting.bq_sp_internet_payment(); \n\n            CALL nba_offer_targeting.bq_sp_irpc_digital_1p_base();\n\n            CALL nba_offer_targeting.bq_sp_irpc_digital_2p_base(); \n\n            CALL nba_offer_targeting.bq_sp_irpc_casa_base(); \n\n            SELECT\n                *\n            FROM {dataset_id}.INFORMATION_SCHEMA.PARTITIONS\n            WHERE table_name='bq_irpc_digital_1p_base'\n        '''\n\n    df = client.query(query, job_config=job_config).to_dataframe()\n    logging.info(df.to_string())\n\n    logging.info(f\"Loaded {df.total_rows[0]} rows into \\\n             {df.table_catalog[0]}.{df.table_schema[0]}.{df.table_name[0]} on \\\n             {datetime.strftime((df.last_modified_time[0]), '%Y-%m-%d %H:%M:%S') } !\")\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 8.0,
              "memoryLimit": 16.0
            }
          }
        },
        "exec-bq-import-tbl-to-df": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "bq_import_tbl_to_df"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef bq_import_tbl_to_df(project_id: str\n              , dataset_id: str\n              , table_id: str\n              , save_data_path: str\n              , token: str \n              ) -> NamedTuple(\"output\", [(\"col_list\", list)]):\n\n    from google.cloud import bigquery\n    import logging\n    from datetime import datetime\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n#     #### For prod \n#     client = bigquery.Client(project=project_id)\n#     job_config = bigquery.QueryJobConfig()\n\n    # Change dataset / table + sp table name to version in bi-layer\n    query =\\\n        f'''\n            SELECT * FROM `{project_id}.{dataset_id}.{table_id}`\n        '''\n\n    df = client.query(query, job_config=job_config).to_dataframe()\n\n    df.to_csv(save_data_path, index=False) \n\n    col_list = list([col for col in df.columns])\n\n    return (col_list,)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 8.0,
              "memoryLimit": 16.0
            }
          }
        },
        "exec-bq-import-tbl-to-df-2": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "bq_import_tbl_to_df"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef bq_import_tbl_to_df(project_id: str\n              , dataset_id: str\n              , table_id: str\n              , save_data_path: str\n              , token: str \n              ) -> NamedTuple(\"output\", [(\"col_list\", list)]):\n\n    from google.cloud import bigquery\n    import logging\n    from datetime import datetime\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n#     #### For prod \n#     client = bigquery.Client(project=project_id)\n#     job_config = bigquery.QueryJobConfig()\n\n    # Change dataset / table + sp table name to version in bi-layer\n    query =\\\n        f'''\n            SELECT * FROM `{project_id}.{dataset_id}.{table_id}`\n        '''\n\n    df = client.query(query, job_config=job_config).to_dataframe()\n\n    df.to_csv(save_data_path, index=False) \n\n    col_list = list([col for col in df.columns])\n\n    return (col_list,)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 8.0,
              "memoryLimit": 16.0
            }
          }
        },
        "exec-bq-import-tbl-to-df-3": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "bq_import_tbl_to_df"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef bq_import_tbl_to_df(project_id: str\n              , dataset_id: str\n              , table_id: str\n              , save_data_path: str\n              , token: str \n              ) -> NamedTuple(\"output\", [(\"col_list\", list)]):\n\n    from google.cloud import bigquery\n    import logging\n    from datetime import datetime\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n#     #### For prod \n#     client = bigquery.Client(project=project_id)\n#     job_config = bigquery.QueryJobConfig()\n\n    # Change dataset / table + sp table name to version in bi-layer\n    query =\\\n        f'''\n            SELECT * FROM `{project_id}.{dataset_id}.{table_id}`\n        '''\n\n    df = client.query(query, job_config=job_config).to_dataframe()\n\n    df.to_csv(save_data_path, index=False) \n\n    col_list = list([col for col in df.columns])\n\n    return (col_list,)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 8.0,
              "memoryLimit": 16.0
            }
          }
        },
        "exec-offer-attachment-digital": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "offer_attachment_digital"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef offer_attachment_digital(irpc_base_csv: str\n                   , irpc_offer_plans_csv: str \n                   , irpc_offer_prices_csv: str\n                   , channel: str\n                   , save_data_path: str\n                  ): \n    import pandas as pd \n    import numpy as np \n\n    def convert_df_to_list_dict(df, \n                                channel: str = 'digital' # digital or casa\n                                ): \n\n        import re\n        import logging \n        from datetime import datetime\n\n        print(df.head())\n\n        # Change dataset / table + sp table name to version in bi-layer\n        if channel == 'digital': \n            df = df\n        elif channel == 'casa': \n            df = df.iloc[:4]\n        else: \n            print(\"a parameter 'channel' can only be either 'digital' or 'casa'\")\n\n        # create list_hsia_speed = [250, 500, 1000, 1500, 3000]\n        list_hsia_speed = df.columns[3:]\n\n        print(list_hsia_speed)\n\n        list_hsia_speed = [int(re.search(r'\\d+', speed).group()) for speed in list_hsia_speed]\n\n        # create dictionary of hsia_prices \n        # Convert DataFrame to a dictionary\n        dict_hsia_details = df.to_dict(orient='list')\n\n        return list_hsia_speed, dict_hsia_details\n\n    def find_digital_irpc_offers(list_hsia_speed: str, # list_hsia_speed = [250, 500, 1000, 1500, 3000] as of Feb 2024\n                             dict_hsia_plans_details: str, # e.g. internet_250: ['1P:Regular (Internet 250)', '1P:Tier 0 (Internet 250)', '1P:Tier 1 (Internet 250)']\n                             dict_hsia_prices_details: str, # e.g. internet_250: [105, 100, 95, 85, 75]\n                             row, \n                             offer_num: int\n                             ):\n\n        import pandas as pd\n        import numpy as np \n\n        cust_id, ban, lpds_id = row['cust_id'], row['bacct_num'], row['lpds_id']\n\n        if offer_num == 1: \n            provisioned_hs_speed_numeric, hs_max_speed_numeric, total_charges = row['provisioned_hs_speed_numeric'], row['hs_max_speed_numeric'], row['total_charges']\n        elif offer_num == 2: \n            provisioned_hs_speed_numeric, hs_max_speed_numeric, total_charges = row['hsia_speed1'], row['hs_max_speed_numeric1'], row['hsia_price1']\n        elif offer_num == 3: \n            provisioned_hs_speed_numeric, hs_max_speed_numeric, total_charges = row['hsia_speed2'], row['hs_max_speed_numeric2'], row['hsia_price2']\n\n        if provisioned_hs_speed_numeric is None and hs_max_speed_numeric is None and total_charges is None: \n            return [None, None, None, None]\n\n        ### 1. Find the smallest number in hsia_speed that is greater than provisioned_hs_speed_numeric\n\n        # exception: if the current hsia_speed >= 150 AND hsia_speed < 500, then change the value to 499 so that it bypasses 250 \n        ## Internet 150 customers should not be shown Internet 250 tier, as they are upsped in the backend to speeds of 300mbps ##\n        if provisioned_hs_speed_numeric >= 150 and provisioned_hs_speed_numeric < 500: \n            provisioned_hs_speed_numeric = 499\n\n        # It doesn't make sense when hs_max_speed_numeric < provisioned_hs_speed_numeric. \n        # Update hs_max_speed_numeric to provisioned_hs_speed_numeric when it's the case. \n        if hs_max_speed_numeric < provisioned_hs_speed_numeric: \n            hs_max_speed_numeric = provisioned_hs_speed_numeric\n\n        # store minimum hsia speed offer available greater than (or equal to) the current speed in 'hsia_speed'\n        # AND \n        # minimum speed offer available where the highest offer price in that speed is greater than or equal to 'total_charges'\n\n        # requirements:\n            # - list_hsia_speed\n            # - np.max([spd for spd in dict_hsia_prices_details[f'internet_{hsia_speed}'] if not pd.isna(spd)]) --> max offer price in the internet speed\n            # - compare max offer price vs total_charges \n            # - since internet_250 does not have offer tier equal to or greater than $125, we need to move on to the next speed, which is 500\n            # - since internet_500 does not have offer tier equal to or greater than $125, we need to again move on to the next speed, which is 1000\n            # - internet_1000 has an offer tier equal to or greater than $125, so hsia_speed = 1000\n\n        try: \n            if offer_num == 1: \n                hsia_speed = np.min([spd for spd in list_hsia_speed if spd >= provisioned_hs_speed_numeric and spd <= hs_max_speed_numeric and not pd.isna(spd)]) # --> 250\n            else: \n                hsia_speed = np.min([spd for spd in list_hsia_speed if spd > provisioned_hs_speed_numeric and spd <= hs_max_speed_numeric and not pd.isna(spd)])\n\n            max_offer_price = np.max([spd for spd in dict_hsia_prices_details[f'internet_{hsia_speed}'] if not pd.isna(spd)])\n\n        except ValueError: \n            return [None, None, None, None]\n\n        try: \n            while max_offer_price < total_charges: \n                hsia_speed_idx = list_hsia_speed.index(hsia_speed)\n                hsia_speed = list_hsia_speed[hsia_speed_idx + 1]\n                max_offer_price = np.max([spd for spd in dict_hsia_prices_details[f'internet_{hsia_speed}'] if not pd.isna(spd)])\n\n        except IndexError: \n            print(f\"The customer {cust_id} {ban} {lpds_id} is currently paying > $145, thus not eligible for any offers\")\n\n        ### 2. Find the smallest number in dict_hsia_prices_details[hsia_speed] that is greater (or equal to) than total_charges --> 75\n\n        list_hsia_price = dict_hsia_prices_details[f'internet_{hsia_speed}']\n\n        if len([price for price in list_hsia_price if price >= total_charges]) > 0: \n\n            try: \n                if offer_num == 1: \n                    hsia_price = np.min([price for price in list_hsia_price if price >= total_charges])\n                else: \n                    hsia_price = np.min([price for price in list_hsia_price if price > total_charges])\n\n            except ValueError: \n                return [None, None, None, None]\n\n            try: \n                # scenario when the same price DOES EXIST in the next speed offer (e.g. if internet_500, check internet_1000 for $95 offer ==> YES): \n                hsia_speed_idx = list_hsia_speed.index(hsia_speed)\n                next_hsia_speed = list_hsia_speed[hsia_speed_idx + 1]\n\n                if hsia_price in dict_hsia_prices_details[f'internet_{next_hsia_speed}'] and hsia_speed == provisioned_hs_speed_numeric: \n                    list_hsia_price = dict_hsia_prices_details[f'internet_{next_hsia_speed}']\n                    hsia_speed = next_hsia_speed \n\n            except IndexError: \n                print(f\"For {cust_id} {ban} {lpds_id}, the hsia_speed {hsia_speed} is the fastest internet speed available.\")\n\n            except UnboundLocalError: \n                print(f\"For {cust_id} {ban} {lpds_id}, the hsia_speed {hsia_speed} is the fastest internet speed available.\")\n\n            # scenario when the same price DOES NOT EXIST in the next speed offer (e.g. if internet_1000, check internet_1500 for $95 offer ==> NO): \n\n            if hsia_price in list_hsia_price:\n                plan_idx = list_hsia_price.index(hsia_price)    \n\n            ### 4. Call the plan name by hsia_plans[provisioned_hs_speed_numeric]==250][plan_idx==4] --> \"1P: Tier 3 (Internet 250)\"\n\n            hsia_plan_name = dict_hsia_plans_details[f'internet_{hsia_speed}'][plan_idx]\n\n            return [hsia_speed, hs_max_speed_numeric, hsia_price, hsia_plan_name] \n\n        else: \n\n            return [None, None, None, None]\n\n    # read the above 3 csv's (bq_irpc_digital_1p_base.csv, irpc_offer_1p_plans.csv, irpc_offer_prices.csv\n    # read bq_irpc_digital_1p_base and store in df\n    df_base = pd.read_csv(irpc_base_csv)\n    df_plans = pd.read_csv(irpc_offer_plans_csv)\n    df_prices = pd.read_csv(irpc_offer_prices_csv)\n\n    # convert irpc_offer_1p_plans and irpc_offer_prices to lists and dictionaries\n    # - list_hsia_speed\n    # - dict_hsia_details\n    list_hsia_speed, dict_hsia_plans_details = convert_df_to_list_dict(df_plans, channel)\n    list_hsia_speed, dict_hsia_prices_details = convert_df_to_list_dict(df_prices, channel)\n\n    offer_1_list, offer_2_list, offer_3_list = [] , [], [] \n\n    df_base[['hsia_speed1', 'hs_max_speed_numeric1', 'hsia_price1', 'promo_seg1']]  = df_base.apply(lambda row: pd.Series(find_digital_irpc_offers(list_hsia_speed, dict_hsia_plans_details, dict_hsia_prices_details, row, 1)), axis=1)\n    df_base[['hsia_speed2', 'hs_max_speed_numeric2', 'hsia_price2', 'promo_seg2']]  = df_base.apply(lambda row: pd.Series(find_digital_irpc_offers(list_hsia_speed, dict_hsia_plans_details, dict_hsia_prices_details, row, 2)), axis=1)\n    df_base[['hsia_speed3', 'hs_max_speed_numeric3', 'hsia_price3', 'promo_seg3']]  = df_base.apply(lambda row: pd.Series(find_digital_irpc_offers(list_hsia_speed, dict_hsia_plans_details, dict_hsia_prices_details, row, 3)), axis=1)\n\n    df_base = df_base[['cust_id', 'bacct_num', 'fms_address_id', 'lpds_id', 'candate', 'OPTIK_TV_IND', 'HSIA_IND', 'hs_max_speed_numeric', 'provisioned_hs_speed_numeric', \n                       'rpp_hsia_end_dt', 'rpp_ttv_end_dt', 'total_charges', 'promo_seg1', 'promo_seg2', 'promo_seg3']] \n\n    df_base.to_csv(save_data_path)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 16.0,
              "memoryLimit": 32.0
            }
          }
        }
      }
    },
    "pipelineInfo": {
      "name": "nba-offer-targeting-serving-pipeline"
    },
    "root": {
      "dag": {
        "tasks": {
          "bq-create-dataset": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-bq-create-dataset"
            },
            "inputs": {
              "parameters": {
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "nba_offer_targeting"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0Ad52N39KS36XYKnt1g9Jwh5p28hPQ5WkX0H3tnHqIkIj0TpXNSZJzvY_p8XCXBwkyUeAs3ioHptMLRCzyyEtgYxOg037ZDPQOUG_L35pw4Xl_JyuGa4EJUACl-K6J75eLMN3AqEdJXzQb3i5QSjuWBn6Xw90x4M16OQ2WtaUkgaCgYKATMSARISFQHGX2MiPYKyGoP63j0wZkkZlHKc3Q0177"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "bq-create-dataset"
            }
          },
          "bq-import-tbl-to-df": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-bq-import-tbl-to-df"
            },
            "dependentTasks": [
              "bq-create-dataset"
            ],
            "inputs": {
              "parameters": {
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "nba_offer_targeting"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4"
                    }
                  }
                },
                "save_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/bq_irpc_digital_1p_base.csv"
                    }
                  }
                },
                "table_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "bq_irpc_digital_1p_base"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0Ad52N39KS36XYKnt1g9Jwh5p28hPQ5WkX0H3tnHqIkIj0TpXNSZJzvY_p8XCXBwkyUeAs3ioHptMLRCzyyEtgYxOg037ZDPQOUG_L35pw4Xl_JyuGa4EJUACl-K6J75eLMN3AqEdJXzQb3i5QSjuWBn6Xw90x4M16OQ2WtaUkgaCgYKATMSARISFQHGX2MiPYKyGoP63j0wZkkZlHKc3Q0177"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "bq-import-tbl-to-df"
            }
          },
          "bq-import-tbl-to-df-2": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-bq-import-tbl-to-df-2"
            },
            "dependentTasks": [
              "bq-import-tbl-to-df"
            ],
            "inputs": {
              "parameters": {
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "nba_offer_targeting"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4"
                    }
                  }
                },
                "save_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/irpc_offer_1p_plans.csv"
                    }
                  }
                },
                "table_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "irpc_offer_1p_plans"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0Ad52N39KS36XYKnt1g9Jwh5p28hPQ5WkX0H3tnHqIkIj0TpXNSZJzvY_p8XCXBwkyUeAs3ioHptMLRCzyyEtgYxOg037ZDPQOUG_L35pw4Xl_JyuGa4EJUACl-K6J75eLMN3AqEdJXzQb3i5QSjuWBn6Xw90x4M16OQ2WtaUkgaCgYKATMSARISFQHGX2MiPYKyGoP63j0wZkkZlHKc3Q0177"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "bq-import-tbl-to-df-2"
            }
          },
          "bq-import-tbl-to-df-3": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-bq-import-tbl-to-df-3"
            },
            "dependentTasks": [
              "bq-import-tbl-to-df-2"
            ],
            "inputs": {
              "parameters": {
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "nba_offer_targeting"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-groovyhoon-pr-d2eab4"
                    }
                  }
                },
                "save_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/irpc_offer_prices.csv"
                    }
                  }
                },
                "table_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "irpc_offer_prices"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0Ad52N39KS36XYKnt1g9Jwh5p28hPQ5WkX0H3tnHqIkIj0TpXNSZJzvY_p8XCXBwkyUeAs3ioHptMLRCzyyEtgYxOg037ZDPQOUG_L35pw4Xl_JyuGa4EJUACl-K6J75eLMN3AqEdJXzQb3i5QSjuWBn6Xw90x4M16OQ2WtaUkgaCgYKATMSARISFQHGX2MiPYKyGoP63j0wZkkZlHKc3Q0177"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "bq-import-tbl-to-df-3"
            }
          },
          "offer-attachment-digital": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-offer-attachment-digital"
            },
            "dependentTasks": [
              "bq-import-tbl-to-df-3"
            ],
            "inputs": {
              "parameters": {
                "channel": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "digital"
                    }
                  }
                },
                "irpc_base_csv": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/bq_irpc_digital_1p_base.csv"
                    }
                  }
                },
                "irpc_offer_plans_csv": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/irpc_offer_1p_plans.csv"
                    }
                  }
                },
                "irpc_offer_prices_csv": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/irpc_offer_prices.csv"
                    }
                  }
                },
                "save_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-groovyhoon-pr-d2eab4-default/nba_offer_targeting/irpc_digital_1p_base_with_offers.csv"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "offer-attachment-digital"
            }
          }
        }
      },
      "inputDefinitions": {
        "parameters": {
          "file_bucket": {
            "type": "STRING"
          },
          "project_id": {
            "type": "STRING"
          },
          "region": {
            "type": "STRING"
          },
          "resource_bucket": {
            "type": "STRING"
          }
        }
      }
    },
    "schemaVersion": "2.0.0",
    "sdkVersion": "kfp-1.8.18"
  },
  "runtimeConfig": {
    "parameters": {
      "file_bucket": {
        "stringValue": "divg-groovyhoon-pr-d2eab4-default"
      },
      "project_id": {
        "stringValue": "divg-groovyhoon-pr-d2eab4"
      },
      "region": {
        "stringValue": "northamerica-northeast1"
      },
      "resource_bucket": {
        "stringValue": "divg-groovyhoon-pr-d2eab4-default"
      }
    }
  }
}