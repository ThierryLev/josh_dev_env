name: Bq test offer parameter sheet
inputs:
- {name: project_id, type: String}
- {name: dataset_id, type: String}
- {name: token, type: String}
outputs:
- {name: result, type: String}
implementation:
  container:
    image: northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing\
      \ import *\n\ndef bq_test_offer_parameter_sheet(project_id: str\n          \
      \            , dataset_id: str\n                      , token: str\n       \
      \               )-> NamedTuple(\"output\", [(\"result\", str)]):\n\n    from\
      \ google.cloud import bigquery\n    import logging \n    from datetime import\
      \ datetime\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS\
      \ = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id,\
      \ credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n#\
      \     #### For prod \n#     client = bigquery.Client(project=project_id)\n#\
      \     job_config = bigquery.QueryJobConfig()\n\n    # Change dataset / table\
      \ + sp table name to version in bi-layer\n    query =\\\n        f'''      \
      \  \n        with max_dt as (\n            SELECT \n            max(part_dt)\
      \ as part_dt\n            FROM `nba_offer_targeting.bq_offer_targeting_params_upd`\
      \ \n        )\n        , tdy as (\n            select a.* \n            from\
      \ `nba_offer_targeting.bq_offer_targeting_params_upd` a \n            inner\
      \ join max_dt b\n            on a.part_dt = b.part_dt\n            where a.if_active\
      \ = 1 and a.HS_filters is not null\n        )\n\n        select \n        count(*)\
      \ as col1\n        , count(distinct ncid) as col2\n        , count(distinct\
      \ promo_seg) as col3\n        from tdy\n        '''\n\n    df = client.query(query,\
      \ job_config=job_config).to_dataframe()\n\n    dict_df = df.to_dict(orient='list')\n\
      \n    def checker_logic(dict_df): \n        col1 = dict_df['col1']\n       \
      \ col2 = dict_df['col2']\n        col3 = dict_df['col3']\n\n        if col1\
      \ == col2 == col3: \n            return 'pass'\n        else: \n           \
      \ return 'fail'\n\n    result = checker_logic(dict_df)\n\n    print(result)\
      \ \n\n    if result == 'fail':\n        raise ValueError(\"initial checks failed.\
      \ please review the `nba_offer_targeting.bq_offer_targeting_params_upd` table.\"\
      )\n\n    return (result, )\n\n"
    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - bq_test_offer_parameter_sheet
