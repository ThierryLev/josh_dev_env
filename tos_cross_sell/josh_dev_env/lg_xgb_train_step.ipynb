{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0c603b-3f78-40d0-bc02-7dac3ea2a76c",
   "metadata": {},
   "source": [
    "### Import Libraries, declare variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1294f3f-ee1c-4c57-bbb1-635ef08b52d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import google\n",
    "from google.oauth2 import credentials\n",
    "from google.oauth2 import service_account\n",
    "from google.oauth2.service_account import Credentials\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# build model\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "SERVICE_TYPE = 'tos_cross_sell'\n",
    "DATASET_ID = 'tos_cross_sell'\n",
    "PROJECT_ID = 'divg-josh-pr-d1cc3a' #mapping['PROJECT_ID']\n",
    "RESOURCE_BUCKET = 'divg-josh-pr-d1cc3a-default' #mapping['resources_bucket']\n",
    "FILE_BUCKET = 'divg-josh-pr-d1cc3a-default' #mapping['gcs_csv_bucket']\n",
    "REGION = 'northamerica-northeast1' #mapping['REGION']\n",
    "MODEL_ID = '5060'\n",
    "FOLDER_NAME = 'xgb_tos_cross_sell_train_deploy'.format(MODEL_ID)\n",
    "QUERIES_PATH = 'vertex_pipelines/' + FOLDER_NAME + '/queries/'\n",
    "\n",
    "scoringDate = date(2022, 9, 1)  # date.today() - relativedelta(days=2)- relativedelta(months=30)\n",
    "valScoringDate = date(2022, 12, 1)  # scoringDate - relativedelta(days=2)\n",
    "\n",
    "# training views\n",
    "CONSL_VIEW_NAME = '{}_pipeline_consl_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "FFH_BILLING_VIEW_NAME = '{}_pipeline_ffh_billing_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "HS_USAGE_VIEW_NAME = '{}_pipeline_hs_usage_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "DEMO_INCOME_VIEW_NAME = '{}_pipeline_demo_income_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "PROMO_EXPIRY_VIEW_NAME = '{}_pipeline_promo_expiry_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "TROUBLE_TICKETS_VIEW_NAME = '{}_pipeline_trouble_tickets_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "GPON_COPPER_VIEW_NAME = '{}_pipeline_gpon_copper_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "CALL_DATA_VIEW_NAME = '{}_pipeline_call_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "HSIA_DROPS_VIEW_NAME = '{}_pipeline_hsia_drops_training_bi_layer'.format(SERVICE_TYPE)\n",
    "CLCKSTRM_TELUS_VIEW_NAME = '{}_pipeline_clckstrm_telus_training_bi_layer'.format(SERVICE_TYPE)\n",
    "TOS_ACTIVE_BANS_VIEW_NAME = '{}_pipeline_tos_active_bans_training_bi_layer'.format(SERVICE_TYPE) \n",
    "\n",
    "# validation views\n",
    "CONSL_VIEW_VALIDATION_NAME = '{}_pipeline_consl_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "FFH_BILLING_VIEW_VALIDATION_NAME = '{}_pipeline_ffh_billing_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "HS_USAGE_VIEW_VALIDATION_NAME = '{}_pipeline_hs_usage_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "DEMO_INCOME_VIEW_VALIDATION_NAME = '{}_pipeline_demo_income_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "PROMO_EXPIRY_VIEW_VALIDATION_NAME = '{}_pipeline_promo_expiry_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "TROUBLE_TICKETS_VIEW_VALIDATION_NAME = '{}_pipeline_trouble_tickets_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "GPON_COPPER_VIEW_VALIDATION_NAME = '{}_pipeline_gpon_copper_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "CALL_DATA_VIEW_VALIDATION_NAME = '{}_pipeline_call_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "HSIA_DROPS_VIEW_VALIDATION_NAME = '{}_pipeline_hsia_drops_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "CLCKSTRM_TELUS_VIEW_VALIDATION_NAME = '{}_pipeline_clckstrm_telus_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "TOS_ACTIVE_BANS_VALIDATION_VIEW_NAME = '{}_pipeline_tos_active_bans_validation_bi_layer'.format(SERVICE_TYPE) \n",
    "\n",
    "# training dates\n",
    "SCORE_DATE = scoringDate.strftime('%Y%m%d')  # date.today().strftime('%Y%m%d')\n",
    "SCORE_DATE_DASH = scoringDate.strftime('%Y-%m-%d')\n",
    "SCORE_DATE_MINUS_6_MOS_DASH = ((scoringDate - relativedelta(months=6)).replace(day=1)).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_LAST_MONTH_START_DASH = (scoringDate.replace(day=1) - timedelta(days=1)).replace(day=1).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_LAST_MONTH_END_DASH = ((scoringDate.replace(day=1)) - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_LAST_MONTH_YEAR = ((scoringDate.replace(day=1)) - timedelta(days=1)).year\n",
    "SCORE_DATE_LAST_MONTH_MONTH = ((scoringDate.replace(day=1)) - timedelta(days=1)).month\n",
    "\n",
    "# validation dates\n",
    "SCORE_DATE_VAL = valScoringDate.strftime('%Y%m%d')\n",
    "SCORE_DATE_VAL_DASH = valScoringDate.strftime('%Y-%m-%d')\n",
    "SCORE_DATE_VAL_MINUS_6_MOS_DASH = ((valScoringDate - relativedelta(months=6)).replace(day=1)).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_VAL_LAST_MONTH_START_DASH = (valScoringDate.replace(day=1) - timedelta(days=1)).replace(day=1).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_VAL_LAST_MONTH_END_DASH = ((valScoringDate.replace(day=1)) - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_VAL_LAST_MONTH_YEAR = ((valScoringDate.replace(day=1)) - timedelta(days=1)).year\n",
    "SCORE_DATE_VAL_LAST_MONTH_MONTH = ((valScoringDate.replace(day=1)) - timedelta(days=1)).month\n",
    "\n",
    "SCORE_DATE_DELTA = 0\n",
    "SCORE_DATE_VAL_DELTA = 0\n",
    "TICKET_DATE_WINDOW = 30  # Days of ticket data to be queried\n",
    "\n",
    "ACCOUNT_CONSL_QUERY_PATH = QUERIES_PATH + 'create_input_account_consl_query.txt'\n",
    "ACCOUNT_HSIA_DROPS_QUERY_PATH = QUERIES_PATH + 'create_input_account_hsia_drops_query.txt'\n",
    "ACCOUNT_CALL_DATA_QUERY_PATH = QUERIES_PATH + 'create_input_account_call_data_query.txt'\n",
    "ACCOUNT_GPON_COPPER_QUERY_PATH = QUERIES_PATH + 'create_input_account_gpon_copper_query.txt'\n",
    "ACCOUNT_TROUBLE_TICKETS_QUERY_PATH = QUERIES_PATH + 'create_input_account_trouble_tickets_query.txt'\n",
    "ACCOUNT_PROMO_EXPIRY_QUERY_PATH = QUERIES_PATH + 'create_input_account_promo_expiry_query.txt'\n",
    "# ACCOUNT_TV_USAGE_QUERY_PATH = QUERIES_PATH + 'create_input_account_tv_usage_query.txt'\n",
    "ACCOUNT_DEMO_INCOME_QUERY_PATH = QUERIES_PATH + 'create_input_account_demo_income_query.txt'\n",
    "ACCOUNT_HS_USAGE_QUERY_PATH = QUERIES_PATH + 'create_input_account_hs_usage_query.txt'\n",
    "ACCOUNT_FFH_BILLING_QUERY_PATH = QUERIES_PATH + 'create_input_account_ffh_billing_query.txt'\n",
    "ACCOUNT_CLCKSTRM_TELUS_QUERY_PATH = QUERIES_PATH + 'create_input_account_clckstrm_telus_query.txt'\n",
    "ACCOUNT_TOS_ACTIVE_BANS_QUERY_PATH = QUERIES_PATH + 'create_input_account_tos_active_bans_query.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a31e45-47f9-445e-aab4-1e2d8243e1f9",
   "metadata": {},
   "source": [
    "### define get_lift function, import df_train and df_test from gcs bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea3837b0-0180-4a8a-978d-b56402062efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "project_id = PROJECT_ID\n",
    "region = REGION\n",
    "resource_bucket = RESOURCE_BUCKET\n",
    "file_bucket = FILE_BUCKET\n",
    "service_type=SERVICE_TYPE\n",
    "score_date_dash=SCORE_DATE_DASH\n",
    "score_date_val_dash=SCORE_DATE_VAL_DASH\n",
    "project_id=PROJECT_ID\n",
    "dataset_id=DATASET_ID\n",
    "\n",
    "def get_lift(prob, y_test, q):\n",
    "    result = pd.DataFrame(columns=['Prob', 'Churn'])\n",
    "    result['Prob'] = prob\n",
    "    result['Churn'] = y_test\n",
    "    # result['Decile'] = pd.qcut(1-result['Prob'], 10, labels = False)\n",
    "    result['Decile'] = pd.qcut(result['Prob'], q, labels=[i for i in range(q, 0, -1)])\n",
    "    add = pd.DataFrame(result.groupby('Decile')['Churn'].mean()).reset_index()\n",
    "    add.columns = ['Decile', 'avg_real_churn_rate']\n",
    "    result = result.merge(add, on='Decile', how='left')\n",
    "    result.sort_values('Decile', ascending=True, inplace=True)\n",
    "    lg = pd.DataFrame(result.groupby('Decile')['Prob'].mean()).reset_index()\n",
    "    lg.columns = ['Decile', 'avg_model_pred_churn_rate']\n",
    "    lg.sort_values('Decile', ascending=False, inplace=True)\n",
    "    lg['avg_churn_rate_total'] = result['Churn'].mean()\n",
    "    lg = lg.merge(add, on='Decile', how='left')\n",
    "    lg['lift'] = lg['avg_real_churn_rate'] / lg['avg_churn_rate_total']\n",
    "\n",
    "    return lg\n",
    "\n",
    "df_train = pd.read_csv('gs://{}/{}/{}_train.csv.gz'.format(file_bucket, service_type, service_type),\n",
    "                       compression='gzip')  # for 2022-08-01\n",
    "df_test = pd.read_csv('gs://{}/{}/{}_validation.csv.gz'.format(file_bucket, service_type, service_type),  # 2022-09-01\n",
    "                      compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c2c5658-f91b-45ca-84f0-6f9818aa7962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ban</th>\n",
       "      <th>productMix_product_mix_all</th>\n",
       "      <th>productMix_sing_count</th>\n",
       "      <th>productMix_hsic_count</th>\n",
       "      <th>productMix_mob_count</th>\n",
       "      <th>productMix_shs_count</th>\n",
       "      <th>productMix_ttv_count</th>\n",
       "      <th>productMix_stv_count</th>\n",
       "      <th>productMix_diic_count</th>\n",
       "      <th>productMix_new_c_ind</th>\n",
       "      <th>...</th>\n",
       "      <th>infra_num_srvc_typ_gpon_sum</th>\n",
       "      <th>clckstrmData_tot_click_cnt_r30d</th>\n",
       "      <th>clckstrmData_wln_tot_cnt_r30d</th>\n",
       "      <th>clckstrmData_wln_hsic_cnt_r30d</th>\n",
       "      <th>clckstrmData_wln_tv_cnt_r30d</th>\n",
       "      <th>clckstrmData_wln_streaming_cnt_r30d</th>\n",
       "      <th>clckstrmData_wln_security_cnt_r30d</th>\n",
       "      <th>clckstrmData_wln_smarthome_security_cnt_r30d</th>\n",
       "      <th>clckstrmData_wln_online_security_cnt_r30d</th>\n",
       "      <th>clckstrmData_wln_smartwear_security_cnt_r30d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ban, productMix_product_mix_all, productMix_sing_count, productMix_hsic_count, productMix_mob_count, productMix_shs_count, productMix_ttv_count, productMix_stv_count, productMix_diic_count, productMix_new_c_ind, productMix_new_sing_ind, productMix_new_hsic_ind, productMix_new_ttv_ind, productMix_mnh_ind, ffhBill_ffh_amt_0, ffhBill_ffh_amt_1, ffhBill_ffh_amt_2, ffhBill_ffh_amt_3, ffhBill_ffh_amt_4, ffhBill_ffh_amt_5, hsiaUsage_hs_tot_gb_0, hsiaUsage_hs_tot_gb_1, hsiaUsage_hs_tot_gb_2, hsiaUsage_hs_tot_gb_3, hsiaUsage_hs_tot_gb_4, hsiaUsage_hs_tot_gb_5, demographics_demo_avg_income, demographics_demo_urban_flag, demographics_demo_rural_flag, demographics_demo_family_flag, demographics_demo_lsname_Large_Diverse_Families, demographics_demo_lsname_Mature_Singles_and_Couples, demographics_demo_lsname_Middle_Age_Families, demographics_demo_lsname_Older_Families_and_Empty_Nests, demographics_demo_lsname_School_Age_Families, demographics_demo_lsname_Unassigned, demographics_demo_lsname_Very_Young_Singles_and_Couples, demographics_demo_lsname_Young_Families, demographics_demo_lsname_Younger_Singles_and_Couples, promo_sing_disc_exp_lst_nxt_mth_cnt, promo_sing_disc_exp_lst_nxt_mth_amt, promo_hsic_disc_exp_lst_nxt_mth_cnt, promo_hsic_disc_exp_lst_nxt_mth_amt, promo_ttv_disc_exp_lst_nxt_mth_cnt, promo_ttv_disc_exp_lst_nxt_mth_amt, promo_smhm_disc_exp_lst_nxt_mth_cnt, promo_smhm_disc_exp_lst_nxt_mth_amt, ffhBill_bill_tot_inv_amt, ffhBill_tot_net_amt, ffhBill_sing_net_amt, ffhBill_hsic_net_amt, ffhBill_ttv_net_amt, ffhBill_smhm_net_amt, ffhBill_other_net_amt, infra_num_srvc_typ_copper_sum, infra_num_srvc_typ_gpon_sum, clckstrmData_tot_click_cnt_r30d, clckstrmData_wln_tot_cnt_r30d, clckstrmData_wln_hsic_cnt_r30d, clckstrmData_wln_tv_cnt_r30d, clckstrmData_wln_streaming_cnt_r30d, clckstrmData_wln_security_cnt_r30d, clckstrmData_wln_smarthome_security_cnt_r30d, clckstrmData_wln_online_security_cnt_r30d, clckstrmData_wln_smartwear_security_cnt_r30d]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 65 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df_test[df_test['ban'] == 604337639]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94961cc0-7e92-44eb-9e1e-15d16d2024ed",
   "metadata": {},
   "source": [
    "### add targets to df_train and df_target \n",
    "\n",
    "- df_target_train is from `divg-josh-pr-d1cc3a.tos_crosssell.bq_tos_cross_sell_targets_q3` \n",
    "- df_target_test is from `divg-josh-pr-d1cc3a.tos_crosssell.bq_tos_cross_sell_targets_q4` \n",
    "- some parts of the code and sql queries need to be dynamically adjusted to be included in the deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc272d97-768b-401b-9100-923cc63cf1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11222\n",
      "10544\n"
     ]
    }
   ],
   "source": [
    "def get_gcp_bqclient(project_id, use_local_credential=True):\n",
    "    token = os.popen('gcloud auth print-access-token').read()\n",
    "    token = re.sub(f'\\n$', '', token)\n",
    "    credentials = google.oauth2.credentials.Credentials(token)\n",
    "\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    if use_local_credential:\n",
    "        bq_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "    return bq_client\n",
    "\n",
    "client = get_gcp_bqclient(project_id)\n",
    "\n",
    "#set up df_train\n",
    "sql_train = ''' SELECT * FROM `{}.{}.bq_tos_cross_sell_targets_202209` '''.format(project_id, dataset_id)\n",
    "df_target_train = client.query(sql_train).to_dataframe()\n",
    "df_target_train = df_target_train.loc[\n",
    "    df_target_train['YEAR_MONTH'] == \"2022-09\"] #'-'.join(score_date_dash.split('-')[:2])]  # score_date_dash = '2022-08-31'\n",
    "\n",
    "#set up df_train and df_test (add 'target')\n",
    "df_target_train['ban'] = df_target_train['ban'].astype('int64')\n",
    "df_target_train = df_target_train.groupby('ban').tail(1)\n",
    "\n",
    "df_train = df_train.merge(df_target_train[['ban', 'product_acq_ind']], on='ban', how='left')\n",
    "df_train.rename(columns={'product_acq_ind': 'target'}, inplace=True)\n",
    "df_train.dropna(subset=['target'], inplace=True)\n",
    "df_train['target'] = df_train['target'].astype(int)\n",
    "# df_train.to_csv('gs://{}/outputs/{}_train_final.csv'.format(FILE_BUCKET, SERVICE_TYPE), index=False)\n",
    "\n",
    "print(np.sum(df_train['target']))\n",
    "\n",
    "client = get_gcp_bqclient(project_id)\n",
    "\n",
    "#set up df_test\n",
    "sql_test = ''' SELECT * FROM `{}.{}.bq_tos_cross_sell_targets_202212` '''.format(project_id, dataset_id)\n",
    "df_target_test = client.query(sql_test).to_dataframe()\n",
    "df_target_test = df_target_test.loc[\n",
    "    df_target_test['YEAR_MONTH'] == \"2022-12\"] #'-'.join(score_date_val_dash.split('-')[:2])]  # score_date_dash = '2022-09-30'\n",
    "\n",
    "#set up df_train and df_test (add 'target')\n",
    "df_target_test['ban'] = df_target_test['ban'].astype('int64')\n",
    "df_target_test = df_target_test.groupby('ban').tail(1)\n",
    "\n",
    "df_test = df_test.merge(df_target_test[['ban', 'product_acq_ind']], on='ban', how='left')\n",
    "df_test.rename(columns={'product_acq_ind': 'target'}, inplace=True)\n",
    "df_test.dropna(subset=['target'], inplace=True)\n",
    "df_test['target'] = df_test['target'].astype(int)\n",
    "# df_test.to_csv('gs://{}/outputs/{}_test_final.csv'.format(FILE_BUCKET, SERVICE_TYPE), index=False)\n",
    "\n",
    "print(np.sum(df_test['target']))\n",
    "\n",
    "#set up features (list)\n",
    "cols_1 = df_train.columns.values\n",
    "cols_2 = df_test.columns.values\n",
    "cols = set(cols_1).intersection(set(cols_2))\n",
    "features = [f for f in cols if f not in ['ban', 'target']]\n",
    "\n",
    "# #train test split\n",
    "# df_train, df_val = train_test_split(df_train, shuffle=True, test_size=0.2, random_state=42,\n",
    "#                                     stratify=df_train['target']\n",
    "#                                     )\n",
    "\n",
    "ban_train = df_train['ban']\n",
    "X_train = df_train[features]\n",
    "y_train = np.squeeze(df_train['target'].values)\n",
    "target_train = df_train['target']\n",
    "\n",
    "# ban_val = df_val['ban']\n",
    "# X_val = df_val[features]\n",
    "# y_val = np.squeeze(df_val['target'].values)\n",
    "# target_val = df_val['target']\n",
    "\n",
    "ban_test = df_test['ban']\n",
    "X_test = df_test[features]\n",
    "y_test = np.squeeze(df_test['target'].values)\n",
    "target_test = df_test['target']\n",
    "\n",
    "# del df_train, df_val, df_test\n",
    "# del df_train, df_test\n",
    "# gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99db762c-22c9-484b-a217-f39ed9abdfa0",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ac5de-6d00-4bc2-960d-6a15d8da71e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_train_1 = df_train[['productMix_product_mix_all', 'productMix_sing_count',\n",
    "       'productMix_hsic_count', 'productMix_mob_count', 'productMix_shs_count',\n",
    "       'productMix_ttv_count', 'productMix_stv_count', 'productMix_diic_count',\n",
    "       'productMix_new_c_ind', 'productMix_new_sing_ind',\n",
    "       'productMix_new_hsic_ind', 'productMix_new_ttv_ind',\n",
    "       'productMix_new_smhm_ind', 'productMix_mnh_ind', 'target']]\n",
    "                      \n",
    "df_train_2 = df_train[['ffhBill_avg_ffh_amt',\n",
    "       'hsiaUsage_avg_hs_tot_gb', 'demographics_demo_avg_income',\n",
    "       'demographics_demo_urban_flag', 'demographics_demo_rural_flag',\n",
    "       'demographics_demo_family_flag',\n",
    "       'demographics_demo_lsname_Large_Diverse_Families',\n",
    "       'demographics_demo_lsname_Mature_Singles_and_Couples',\n",
    "       'demographics_demo_lsname_Middle_Age_Families',\n",
    "       'demographics_demo_lsname_Older_Families_and_Empty_Nests',\n",
    "       'demographics_demo_lsname_School_Age_Families',\n",
    "       'demographics_demo_lsname_Unassigned',\n",
    "       'demographics_demo_lsname_Very_Young_Singles_and_Couples',\n",
    "       'demographics_demo_lsname_Young_Families',\n",
    "       'demographics_demo_lsname_Younger_Singles_and_Couples', 'target']]\n",
    "                      \n",
    "df_train_3 = df_train[[\n",
    "       'promo_sing_disc_exp_lst_nxt_mth_cnt',\n",
    "       'promo_sing_disc_exp_lst_nxt_mth_amt',\n",
    "       'promo_hsic_disc_exp_lst_nxt_mth_cnt',\n",
    "       'promo_hsic_disc_exp_lst_nxt_mth_amt',\n",
    "       'promo_ttv_disc_exp_lst_nxt_mth_cnt',\n",
    "       'promo_ttv_disc_exp_lst_nxt_mth_amt',\n",
    "       'promo_smhm_disc_exp_lst_nxt_mth_cnt',\n",
    "       'promo_smhm_disc_exp_lst_nxt_mth_amt', 'ffhBill_bill_tot_inv_amt',\n",
    "       'ffhBill_tot_net_amt', 'ffhBill_sing_net_amt', 'ffhBill_hsic_net_amt',\n",
    "       'ffhBill_ttv_net_amt', 'ffhBill_smhm_net_amt', 'ffhBill_other_net_amt',\n",
    "       'infra_num_srvc_typ_copper_sum', 'infra_num_srvc_typ_gpon_sum', 'target']] \n",
    "                      \n",
    "df_train_4 = df_train[['clckstrmData_tot_click_cnt_r30d', 'clckstrmData_wln_tot_cnt_r30d',\n",
    "       'clckstrmData_wln_hsic_cnt_r30d', 'clckstrmData_wln_tv_cnt_r30d',\n",
    "       'clckstrmData_wln_streaming_cnt_r30d',\n",
    "       'clckstrmData_wln_security_cnt_r30d',\n",
    "       'clckstrmData_wln_smarthome_security_cnt_r30d',\n",
    "       'clckstrmData_wln_online_security_cnt_r30d',\n",
    "       'clckstrmData_wln_smartwear_security_cnt_r30d',\n",
    "       'alarmdotcomAppUsage_alarm_ul_vol_kb',\n",
    "       'alarmdotcomAppUsage_alarm_dl_vol_kb',\n",
    "       'alarmdotcomAppUsage_alarm_ul_pkt_kb',\n",
    "       'alarmdotcomAppUsage_alarm_dl_pkt_kb', 'target']]\n",
    "\n",
    "\n",
    "# Create the correlation matrix\n",
    "corr = df_train_4.corr()\n",
    "\n",
    "# Create the cmap \n",
    "cmap = sns.diverging_palette(h_neg = 10, h_pos = 240, as_cmap = True) \n",
    "\n",
    "# Draw the heatmap\n",
    "sns.heatmap(corr,  cmap=cmap, center=0, linewidths=1, annot=True, fmt=\".2f\")\n",
    "sns.set(rc={'figure.figsize':(50,50)})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfd29e3-d1b3-4cbe-983c-b0033ed8554a",
   "metadata": {},
   "source": [
    "### fit training data in xgboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe7616d7-5909-4cb8-8e74-821d3e92dee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb training done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build model and fit in training data\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1\n",
    "    # seed=27\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print('xgb training done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6cd38f-1967-4282-84a1-c7caf3ded75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# build model and fit in training data\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    learning_rate=0.02,\n",
    "    n_estimators=1000,\n",
    "    max_depth=10,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train, \n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)], \n",
    "            early_stopping_rounds=20) \n",
    "\n",
    "print('xgb training done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb7dfaa-92ea-4788-b698-392ed5ea442a",
   "metadata": {},
   "source": [
    "### fit training data in random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5235b1c5-c12c-4d1d-9826-e5f2aad525a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Create the random forest model and fit to the training data\n",
    "rfc = RandomForestClassifier(n_estimators=75, max_features=8, max_depth=9)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d2c799-5e4b-4b79-84c3-97208961956a",
   "metadata": {},
   "source": [
    "### make predictions on validation set and get auc score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9015b5-b0e0-4b1a-bd1e-1e2ecbba4026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions on X_val\n",
    "y_pred = xgb_model.predict_proba(X_val, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "y_pred_label = (y_pred > 0.5).astype(int)\n",
    "auc = roc_auc_score(y_val, y_pred_label)\n",
    "print(f'auc score is {auc}')\n",
    "# metrics.log_metric(\"AUC\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994582c9-d3ff-4ecc-96c2-deaf0311fad3",
   "metadata": {},
   "source": [
    "### make predictions on X_test set, assign deciles to the predicted values, and save in df_test_exp (RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e1c29c-7af6-4ce7-b1c0-d13bc20ae1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#predictions on X_test\n",
    "pred_prb = rfc.predict_proba(X_test)[:, 1]\n",
    "pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "#join ban_test, X_test, y_test and pred_prb and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_test = ban_test.to_frame()\n",
    "df_test_exp = df_ban_test.join(X_test) \n",
    "df_test_exp['y_test'] = y_test\n",
    "df_test_exp['y_pred_proba'] = pred_prb\n",
    "df_test_exp['y_pred'] = (df_test_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_test_exp['decile'] = pd.qcut(df_test_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(pred_prb, y_test, q)\n",
    "\n",
    "lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8450ef-a002-412e-8d8f-d2f63a43a59e",
   "metadata": {},
   "source": [
    "### make predictions on X_train set, assign deciles to the predicted values, and save in df_train_exp (RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8017502e-75eb-44e8-9edc-cfd06d42f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#predictions on X_test\n",
    "pred_prb = rfc.predict_proba(X_train)[:, 1]\n",
    "pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "#join ban_test, X_test, y_test and pred_prb and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_train = ban_train.to_frame()\n",
    "df_train_exp = df_ban_train.join(X_train) \n",
    "df_train_exp['y_test'] = y_train\n",
    "df_train_exp['y_pred_proba'] = pred_prb\n",
    "df_train_exp['y_pred'] = (df_train_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_train_exp['decile'] = pd.qcut(df_train_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(pred_prb, y_train, q)\n",
    "\n",
    "lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0ea7ec-74db-4419-84bb-0d44545fec56",
   "metadata": {},
   "source": [
    "### make predictions on X_test set, assign deciles to the predicted values, and save in df_test_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b3c55fb-754b-4fa9-b0ac-cdcf45a3dc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/core.py:90: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decile</th>\n",
       "      <th>avg_model_pred_churn_rate</th>\n",
       "      <th>avg_churn_rate_total</th>\n",
       "      <th>avg_real_churn_rate</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.005425</td>\n",
       "      <td>0.018337</td>\n",
       "      <td>3.380160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.005425</td>\n",
       "      <td>0.008289</td>\n",
       "      <td>1.527861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.005425</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>1.103032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.005425</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>0.856958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.005425</td>\n",
       "      <td>0.004218</td>\n",
       "      <td>0.777567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.005425</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.658026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.005425</td>\n",
       "      <td>0.003139</td>\n",
       "      <td>0.578535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.005425</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>0.514399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.005425</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>0.460441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.005425</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.154492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Decile  avg_model_pred_churn_rate  avg_churn_rate_total  \\\n",
       "0      1                   0.000745              0.005425   \n",
       "1      2                   0.000722              0.005425   \n",
       "2      3                   0.000717              0.005425   \n",
       "3      4                   0.000716              0.005425   \n",
       "4      5                   0.000714              0.005425   \n",
       "5      6                   0.000713              0.005425   \n",
       "6      7                   0.000711              0.005425   \n",
       "7      8                   0.000711              0.005425   \n",
       "8      9                   0.000709              0.005425   \n",
       "9     10                   0.000706              0.005425   \n",
       "\n",
       "   avg_real_churn_rate      lift  \n",
       "0             0.018337  3.380160  \n",
       "1             0.008289  1.527861  \n",
       "2             0.005984  1.103032  \n",
       "3             0.004649  0.856958  \n",
       "4             0.004218  0.777567  \n",
       "5             0.003570  0.658026  \n",
       "6             0.003139  0.578535  \n",
       "7             0.002791  0.514399  \n",
       "8             0.002498  0.460441  \n",
       "9             0.000838  0.154492  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#predictions on X_test\n",
    "pred_prb = xgb_model.predict_proba(X_test, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "#join ban_test, X_test, y_test and pred_prb and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_test = ban_test.to_frame()\n",
    "df_test_exp = df_ban_test.join(X_test) \n",
    "df_test_exp['y_test'] = y_test\n",
    "df_test_exp['y_pred_proba'] = pred_prb\n",
    "df_test_exp['y_pred'] = (df_test_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_test_exp['decile'] = pd.qcut(df_test_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(pred_prb, y_test, q)\n",
    "\n",
    "lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2767b8f5-8bdb-4d5f-9b5b-2b340289cb94",
   "metadata": {},
   "source": [
    "### export df_test_exp and lift scores to gcs bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c2015d1-d1a5-410f-95c5-2b5054e2abac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....df_test_exp done\n",
      "....lift_to_csv done\n"
     ]
    }
   ],
   "source": [
    "df_test_exp.to_csv('gs://{}/df_test_exp.csv'.format(file_bucket, index=True))\n",
    "print(\"....df_test_exp done\")\n",
    "\n",
    "lg.to_csv('gs://{}/lift_on_scoring_data.csv'.format(file_bucket, index=False))\n",
    "print(\"....lift_to_csv done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a41125-a188-4bc4-885e-71d69a95b8f9",
   "metadata": {},
   "source": [
    "### make predictions on X_train set, assign deciles to the predicted values, and save in df_train_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbc6661c-06cc-44cb-8dd9-a3eba6696156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/core.py:90: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decile</th>\n",
       "      <th>avg_model_pred_churn_rate</th>\n",
       "      <th>avg_churn_rate_total</th>\n",
       "      <th>avg_real_churn_rate</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.020254</td>\n",
       "      <td>3.500311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.008327</td>\n",
       "      <td>1.439126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>1.010715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.004888</td>\n",
       "      <td>0.844658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>0.824495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.689218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>0.633869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>0.498355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.420099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.157512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Decile  avg_model_pred_churn_rate  avg_churn_rate_total  \\\n",
       "0      1                   0.000744              0.005786   \n",
       "1      2                   0.000723              0.005786   \n",
       "2      3                   0.000718              0.005786   \n",
       "3      4                   0.000717              0.005786   \n",
       "4      5                   0.000715              0.005786   \n",
       "5      6                   0.000714              0.005786   \n",
       "6      7                   0.000713              0.005786   \n",
       "7      8                   0.000712              0.005786   \n",
       "8      9                   0.000710              0.005786   \n",
       "9     10                   0.000707              0.005786   \n",
       "\n",
       "   avg_real_churn_rate      lift  \n",
       "0             0.020254  3.500311  \n",
       "1             0.008327  1.439126  \n",
       "2             0.005848  1.010715  \n",
       "3             0.004888  0.844658  \n",
       "4             0.004771  0.824495  \n",
       "5             0.003988  0.689218  \n",
       "6             0.003668  0.633869  \n",
       "7             0.002884  0.498355  \n",
       "8             0.002431  0.420099  \n",
       "9             0.000911  0.157512  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#predictions on X_test\n",
    "pred_prb = xgb_model.predict_proba(X_train, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "#join ban_test, X_test, y_test and pred_prb and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_train = ban_train.to_frame()\n",
    "df_train_exp = df_ban_train.join(X_train) \n",
    "df_train_exp['y_test'] = y_train\n",
    "df_train_exp['y_pred_proba'] = pred_prb\n",
    "df_train_exp['y_pred'] = (df_train_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_train_exp['decile'] = pd.qcut(df_train_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(pred_prb, y_train, q)\n",
    "\n",
    "lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75c888e-9373-4a25-8803-68f1ad49e402",
   "metadata": {},
   "source": [
    "### export df_test_exp and lift scores to gcs bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3f246bb-de19-40dd-82d8-881903e10349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....df_train_exp done\n",
      "....lift_to_csv done\n"
     ]
    }
   ],
   "source": [
    "df_train_exp.to_csv('gs://{}/df_train_exp.csv'.format(file_bucket, index=True))\n",
    "print(\"....df_train_exp done\")\n",
    "\n",
    "lg.to_csv('gs://{}/lift_on_training_data_.csv'.format(file_bucket, index=False))\n",
    "print(\"....lift_to_csv done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab0b310-accc-4e60-98c7-cff0bc2db9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e1d814-e627-4b25-8ffe-6d15ee24b7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot\n",
    "\n",
    "# Create the correlation matrix\n",
    "corr = df_train.corr()\n",
    "\n",
    "# Create the cmap \n",
    "\n",
    "\n",
    "# Draw the heatmap\n",
    "sns.heatmap(corr,  cmap=cmap, center=0, linewidths=1, annot=True, fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce20d37b-0e62-4c81-b446-a88539baf2d9",
   "metadata": {},
   "source": [
    "### save the model in gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e0caa-94a8-497c-a395-15a1ac041f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model in GCS\n",
    "from datetime import datetime\n",
    "models_dict = {}\n",
    "create_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "models_dict['create_time'] = create_time\n",
    "models_dict['model'] = xgb_model\n",
    "models_dict['features'] = features\n",
    "\n",
    "with open('model_dict.pkl', 'wb') as handle:\n",
    "    pickle.dump(models_dict, handle)\n",
    "handle.close()\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(file_bucket)\n",
    "\n",
    "MODEL_PATH = '{}_xgb_models/'.format(service_type)\n",
    "blob = bucket.blob(MODEL_PATH)\n",
    "if not blob.exists(storage_client):\n",
    "    blob.upload_from_string('')\n",
    "\n",
    "model_name_onbkt = '{}{}_models_xgb_{}'.format(MODEL_PATH, service_type, models_dict['create_time'])\n",
    "blob = bucket.blob(model_name_onbkt)\n",
    "blob.upload_from_filename('model_dict.pkl')\n",
    "\n",
    "print(f\"....model loaded to GCS done at {str(create_time)}\")\n",
    "\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8864bda6-bda0-4032-9704-f513da84e132",
   "metadata": {},
   "source": [
    "### get feature importances from xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43768ef0-d6cc-40e4-a3a9-dbcdbceedb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from xgboost model\n",
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "# Get the index of importances from greatest importance to least\n",
    "sorted_index = np.argsort(importances)[::-1]\n",
    "x = range(len(importances))\n",
    "\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create tick labels \n",
    "labels = np.array(feature_names)[sorted_index]\n",
    "importances = np.array(importances)[sorted_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dba71566-b4d2-4229-8d00-bfb4a3e42d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demographics_demo_avg_income 0.18497573\n",
      "productMix_diic_count 0.11446643\n",
      "productMix_shs_count 0.0780222\n",
      "productMix_new_hsic_ind 0.056737293\n",
      "productMix_hsic_count 0.051196627\n",
      "ffhBill_ffh_amt_5 0.04507623\n",
      "ffhBill_tot_net_amt 0.03582422\n",
      "hsiaUsage_hs_tot_gb_0 0.034663964\n",
      "ffhBill_ffh_amt_4 0.026461767\n",
      "productMix_new_ttv_ind 0.025600439\n",
      "productMix_sing_count 0.020514486\n",
      "ffhBill_hsic_net_amt 0.019779608\n",
      "ffhBill_bill_tot_inv_amt 0.019711934\n",
      "clckstrmData_tot_click_cnt_r30d 0.018794045\n",
      "productMix_product_mix_all 0.01697829\n",
      "infra_num_srvc_typ_copper_sum 0.015377036\n",
      "infra_num_srvc_typ_gpon_sum 0.015177511\n",
      "promo_ttv_disc_exp_lst_nxt_mth_cnt 0.014364893\n",
      "productMix_ttv_count 0.014112309\n",
      "demographics_demo_urban_flag 0.010041573\n",
      "promo_hsic_disc_exp_lst_nxt_mth_cnt 0.008443659\n",
      "ffhBill_smhm_net_amt 0.007973543\n",
      "demographics_demo_lsname_Older_Families_and_Empty_Nests 0.0076689227\n",
      "clckstrmData_wln_security_cnt_r30d 0.0069633187\n",
      "demographics_demo_family_flag 0.0062965997\n",
      "hsiaUsage_hs_tot_gb_3 0.006178595\n",
      "ffhBill_other_net_amt 0.0061603477\n",
      "hsiaUsage_hs_tot_gb_5 0.0059284307\n",
      "clckstrmData_wln_smarthome_security_cnt_r30d 0.0058086393\n",
      "ffhBill_ffh_amt_0 0.00580256\n",
      "hsiaUsage_hs_tot_gb_2 0.00563651\n",
      "demographics_demo_lsname_Mature_Singles_and_Couples 0.0053948406\n",
      "ffhBill_ffh_amt_3 0.005020846\n",
      "demographics_demo_lsname_Middle_Age_Families 0.00488868\n",
      "promo_ttv_disc_exp_lst_nxt_mth_amt 0.004874204\n",
      "hsiaUsage_hs_tot_gb_1 0.0048299762\n",
      "clckstrmData_wln_tot_cnt_r30d 0.004606962\n",
      "clckstrmData_wln_hsic_cnt_r30d 0.004575622\n",
      "demographics_demo_rural_flag 0.0045186672\n",
      "productMix_mob_count 0.0043032817\n",
      "hsiaUsage_hs_tot_gb_4 0.004238043\n",
      "promo_smhm_disc_exp_lst_nxt_mth_cnt 0.0040692887\n",
      "productMix_mnh_ind 0.003942076\n",
      "productMix_stv_count 0.003865915\n",
      "promo_hsic_disc_exp_lst_nxt_mth_amt 0.0038360446\n",
      "ffhBill_ffh_amt_1 0.003727841\n",
      "clckstrmData_wln_tv_cnt_r30d 0.0035670637\n",
      "ffhBill_ttv_net_amt 0.0033940673\n",
      "demographics_demo_lsname_Unassigned 0.0030574056\n",
      "demographics_demo_lsname_Very_Young_Singles_and_Couples 0.0029839016\n",
      "ffhBill_ffh_amt_2 0.0029407053\n",
      "clckstrmData_wln_online_security_cnt_r30d 0.002885852\n",
      "ffhBill_sing_net_amt 0.0028025087\n",
      "clckstrmData_wln_streaming_cnt_r30d 0.0026787692\n",
      "promo_smhm_disc_exp_lst_nxt_mth_amt 0.0026374455\n",
      "promo_sing_disc_exp_lst_nxt_mth_cnt 0.0025411106\n",
      "demographics_demo_lsname_Large_Diverse_Families 0.002314022\n",
      "demographics_demo_lsname_Young_Families 0.0021965995\n",
      "demographics_demo_lsname_Younger_Singles_and_Couples 0.002072711\n",
      "clckstrmData_wln_smartwear_security_cnt_r30d 0.002064622\n",
      "productMix_new_c_ind 0.0012980733\n",
      "promo_sing_disc_exp_lst_nxt_mth_amt 0.0012897953\n",
      "productMix_new_sing_ind 0.0011417537\n",
      "demographics_demo_lsname_School_Age_Families 0.00070359634\n"
     ]
    }
   ],
   "source": [
    "for idx, item in enumerate(labels): \n",
    "    print(labels[idx], importances[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccc17986-5dd7-4e6c-8b90-55d8c7b4ae20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18497573, 0.11446643, 0.0780222 , 0.05673729, 0.05119663,\n",
       "       0.04507623, 0.03582422, 0.03466396, 0.02646177, 0.02560044,\n",
       "       0.02051449, 0.01977961, 0.01971193, 0.01879404, 0.01697829,\n",
       "       0.01537704, 0.01517751, 0.01436489, 0.01411231, 0.01004157,\n",
       "       0.00844366, 0.00797354, 0.00766892, 0.00696332, 0.0062966 ,\n",
       "       0.0061786 , 0.00616035, 0.00592843, 0.00580864, 0.00580256,\n",
       "       0.00563651, 0.00539484, 0.00502085, 0.00488868, 0.0048742 ,\n",
       "       0.00482998, 0.00460696, 0.00457562, 0.00451867, 0.00430328,\n",
       "       0.00423804, 0.00406929, 0.00394208, 0.00386591, 0.00383604,\n",
       "       0.00372784, 0.00356706, 0.00339407, 0.00305741, 0.0029839 ,\n",
       "       0.00294071, 0.00288585, 0.00280251, 0.00267877, 0.00263745,\n",
       "       0.00254111, 0.00231402, 0.0021966 , 0.00207271, 0.00206462,\n",
       "       0.00129807, 0.0012898 , 0.00114175, 0.0007036 ], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6c8ac8-5108-4d00-ac4b-c649bb2d7399",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07cc154-244e-4352-8f89-a4e8a3670613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "036d6fe5-7b90-4200-a9bd-1432adfc08c0",
   "metadata": {},
   "source": [
    "### Plotting the ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a260a7-011f-4e98-9c2d-84cec00d85f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pred_prb) \n",
    "plt.plot([0, 1], [0, 1], 'k--') \n",
    "plt.plot(fpr, tpr) \n",
    "plt.xlabel('False Positive Rate') \n",
    "plt.ylabel('True Positive Rate') \n",
    "plt.title('XGBoost ROC Curve') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e986d2-bd7d-4fd8-b44d-7ea221df5e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b9f58-8334-43ed-8ea2-bf76eaf93804",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d9d01-f009-45c6-90fe-95a61cc169cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb40188a-3865-4993-be01-fb27f7d07dd6",
   "metadata": {},
   "source": [
    "### load the latest saved xgb_model to the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f240186-29e9-4d12-8c11-bb468cae8067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_PATH = '{}_xgb_models/'.format(service_type)\n",
    "# df_score = pd.read_csv('gs://{}/{}_score.csv.gz'.format(file_bucket, service_type), compression='gzip')\n",
    "# df_score.dropna(subset=['ban'], inplace=True)\n",
    "# df_score.reset_index(drop=True, inplace=True)\n",
    "# print('......scoring data loaded:{}'.format(df_score.shape))\n",
    "# time.sleep(10)\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "MODEL_PATH = '{}_xgb_models/'.format(service_type)\n",
    "\n",
    "def load_model(file_bucket: str, service_type: str): \n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(file_bucket)\n",
    "    blobs = storage_client.list_blobs(file_bucket, prefix='{}{}_models_xgb_'.format(MODEL_PATH, service_type))\n",
    "\n",
    "    model_lists = []\n",
    "    for blob in blobs:\n",
    "        model_lists.append(blob.name)\n",
    "\n",
    "    blob = bucket.blob(model_lists[-1])\n",
    "    blob_in = blob.download_as_string()\n",
    "    model_dict = pickle.loads(blob_in)\n",
    "    xgb_model = model_dict['model']\n",
    "    features = model_dict['features']\n",
    "    print('...... model loaded')\n",
    "    time.sleep(10)\n",
    "    \n",
    "    return xgb_model, features\n",
    "\n",
    "xgb_model, features = load_model(file_bucket = FILE_BUCKET, service_type = SERVICE_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625bbaf0-6a67-4151-8504-a187037aa4f8",
   "metadata": {},
   "source": [
    "### backup codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ced94be-d4ec-4eb5-8aed-8199f09bdbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gcp_bqclient(project_id, use_local_credential=True):\n",
    "    token = os.popen('gcloud auth print-access-token').read()\n",
    "    token = re.sub(f'\\n$', '', token)\n",
    "    credentials = google.oauth2.credentials.Credentials(token)\n",
    "\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    if use_local_credential:\n",
    "        bq_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "    return bq_client\n",
    "\n",
    "client = get_gcp_bqclient(project_id)\n",
    "\n",
    "#instantiate df_target_train and df_target_test\n",
    "sql_train = ''' SELECT * FROM `{}.{}.bq_tos_cross_sell_targets_q3` '''.format(project_id, dataset_id)\n",
    "df_target_train = client.query(sql_train).to_dataframe()\n",
    "df_target_train = df_target_train.loc[\n",
    "    df_target_train['YEAR_MONTH'] == \"2022-Q3\"] #'-'.join(score_date_dash.split('-')[:2])]  # score_date_dash = '2022-08-31'\n",
    "\n",
    "#set up df_train and df_test (add 'target')\n",
    "df_target_train['ban'] = df_target_train['ban'].astype('int64')\n",
    "df_target_train = df_target_train.groupby('ban').tail(1)\n",
    "\n",
    "df_train = df_train.merge(df_target_train[['ban', 'product_crosssell_ind']], on='ban', how='left')\n",
    "df_train.rename(columns={'product_crosssell_ind': 'target'}, inplace=True)\n",
    "df_train.dropna(subset=['target'], inplace=True)\n",
    "df_train['target'] = df_train['target'].astype(int)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32473d2-a75d-48ff-afc1-f34af20e2cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b9b389-df11-402a-ab09-20bd55af3d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gcp_bqclient(project_id, use_local_credential=True):\n",
    "    token = os.popen('gcloud auth print-access-token').read()\n",
    "    token = re.sub(f'\\n$', '', token)\n",
    "    credentials = google.oauth2.credentials.Credentials(token)\n",
    "\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    if use_local_credential:\n",
    "        bq_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "    return bq_client\n",
    "\n",
    "client = get_gcp_bqclient(project_id)\n",
    "sql_test = ''' SELECT * FROM `{}.{}.bq_tos_cross_sell_targets_q4` '''.format(project_id, dataset_id)\n",
    "df_target_test = client.query(sql_test).to_dataframe()\n",
    "df_target_test = df_target_test.loc[\n",
    "    df_target_test['YEAR_MONTH'] == \"2022-Q4\"] #'-'.join(score_date_val_dash.split('-')[:2])]  # score_date_dash = '2022-09-30'\n",
    "\n",
    "#set up df_train and df_test (add 'target')\n",
    "df_target_test['ban'] = df_target_test['ban'].astype('int64')\n",
    "df_target_test = df_target_test.groupby('ban').tail(1)\n",
    "\n",
    "df_test = df_test.merge(df_target_test[['ban', 'product_crosssell_ind']], on='ban', how='left')\n",
    "df_test.rename(columns={'product_crosssell_ind': 'target'}, inplace=True)\n",
    "df_test.dropna(subset=['target'], inplace=True)\n",
    "df_test['target'] = df_test['target'].astype(int)\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62170f7-10b3-47f6-9610-7d758e68b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_test['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426e602c-d3dd-4748-9617-410bc68b193e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbace01-af78-4606-be60-24a54a9d73ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9160899b-d021-4fd8-a872-99da8fabb4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f18065-c141-461c-9a6a-ceb9e30cd595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b5220-bd60-499a-8007-223fbf0afc47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca08d2-cba3-4688-927c-3b0925b916b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502dee0c-28ed-42cb-b0ec-a915d94dcb3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031e2eac-09ae-4456-a0a1-ed0f41a27ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c634d001-0124-4325-8f3f-58838fdd1451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6f555e-86fa-416f-970c-bd980b464287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
