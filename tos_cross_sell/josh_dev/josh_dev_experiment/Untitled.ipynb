{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c6fb2d2-2257-4542-88be-b8a2f71d0949",
   "metadata": {},
   "source": [
    "### Import Libraries, declare variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93adda22-ea9d-4cc1-9d77-d8ad1ded9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import google\n",
    "from google.oauth2 import credentials\n",
    "from google.oauth2 import service_account\n",
    "from google.oauth2.service_account import Credentials\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# build model\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "SERVICE_TYPE = 'tos_crosssell'\n",
    "DATASET_ID = 'tos_crosssell'\n",
    "PROJECT_ID = 'divg-josh-pr-d1cc3a' #mapping['PROJECT_ID']\n",
    "RESOURCE_BUCKET = 'divg-josh-pr-d1cc3a-default' #mapping['resources_bucket']\n",
    "FILE_BUCKET = 'divg-josh-pr-d1cc3a-default' #mapping['gcs_csv_bucket']\n",
    "REGION = 'northamerica-northeast1' #mapping['REGION']\n",
    "MODEL_ID = '9999'\n",
    "FOLDER_NAME = 'xgb_tos_cross_sell_train_deploy'.format(MODEL_ID)\n",
    "QUERIES_PATH = 'vertex_pipelines/' + FOLDER_NAME + '/queries/'\n",
    "\n",
    "scoringDate = date(2022, 4, 1)  # date.today() - relativedelta(days=2)- relativedelta(months=30)\n",
    "valScoringDate = date(2022, 7, 1)  # scoringDate - relativedelta(days=2)\n",
    "\n",
    "# training views\n",
    "# training views\n",
    "CONSL_VIEW_NAME = '{}_pipeline_consl_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "FFH_BILLING_VIEW_NAME = '{}_pipeline_ffh_billing_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "HS_USAGE_VIEW_NAME = '{}_pipeline_hs_usage_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "DEMO_INCOME_VIEW_NAME = '{}_pipeline_demo_income_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "PROMO_EXPIRY_VIEW_NAME = '{}_pipeline_promo_expiry_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "TROUBLE_TICKETS_VIEW_NAME = '{}_pipeline_trouble_tickets_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "GPON_COPPER_VIEW_NAME = '{}_pipeline_gpon_copper_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "CALL_DATA_VIEW_NAME = '{}_pipeline_call_data_training_bi_layer'.format(SERVICE_TYPE)  # done\n",
    "HSIA_DROPS_VIEW_NAME = '{}_pipeline_hsia_drops_training_bi_layer'.format(SERVICE_TYPE)\n",
    "\n",
    "# validation views\n",
    "CONSL_VIEW_VALIDATION_NAME = '{}_pipeline_consl_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "FFH_BILLING_VIEW_VALIDATION_NAME = '{}_pipeline_ffh_billing_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "HS_USAGE_VIEW_VALIDATION_NAME = '{}_pipeline_hs_usage_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "DEMO_INCOME_VIEW_VALIDATION_NAME = '{}_pipeline_demo_income_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "PROMO_EXPIRY_VIEW_VALIDATION_NAME = '{}_pipeline_promo_expiry_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "TROUBLE_TICKETS_VIEW_VALIDATION_NAME = '{}_pipeline_trouble_tickets_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "GPON_COPPER_VIEW_VALIDATION_NAME = '{}_pipeline_gpon_copper_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "CALL_DATA_VIEW_VALIDATION_NAME = '{}_pipeline_call_data_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "HSIA_DROPS_VIEW_VALIDATION_NAME = '{}_pipeline_hsia_drops_validation_bi_layer'.format(SERVICE_TYPE)\n",
    "\n",
    "# training dates\n",
    "SCORE_DATE = scoringDate.strftime('%Y%m%d')  # date.today().strftime('%Y%m%d')\n",
    "SCORE_DATE_DASH = scoringDate.strftime('%Y-%m-%d')\n",
    "SCORE_DATE_MINUS_6_MOS_DASH = ((scoringDate - relativedelta(months=6)).replace(day=1)).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_LAST_MONTH_END_DASH = ((scoringDate.replace(day=1)) - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_LAST_MONTH_YEAR = ((scoringDate.replace(day=1)) - timedelta(days=1)).year\n",
    "SCORE_DATE_LAST_MONTH_MONTH = ((scoringDate.replace(day=1)) - timedelta(days=1)).month\n",
    "\n",
    "# validation dates\n",
    "SCORE_DATE_VAL = valScoringDate.strftime('%Y%m%d')\n",
    "\n",
    "SCORE_DATE_VAL_DASH = valScoringDate.strftime('%Y-%m-%d')\n",
    "SCORE_DATE_VAL_MINUS_6_MOS_DASH = ((valScoringDate - relativedelta(months=6)).replace(day=1)).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_VAL_LAST_MONTH_END_DASH = ((valScoringDate.replace(day=1)) - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "SCORE_DATE_VAL_LAST_MONTH_YEAR = ((valScoringDate.replace(day=1)) - timedelta(days=1)).year\n",
    "SCORE_DATE_VAL_LAST_MONTH_MONTH = ((valScoringDate.replace(day=1)) - timedelta(days=1)).month\n",
    "\n",
    "SCORE_DATE_DELTA = 0\n",
    "SCORE_DATE_VAL_DELTA = 0\n",
    "TICKET_DATE_WINDOW = 30  # Days of ticket data to be queried\n",
    "\n",
    "ACCOUNT_CONSL_QUERY_PATH = QUERIES_PATH + 'create_input_account_consl_query.txt'\n",
    "ACCOUNT_HSIA_DROPS_QUERY_PATH = QUERIES_PATH + 'create_input_account_hsia_drops_query.txt'\n",
    "ACCOUNT_CALL_DATA_QUERY_PATH = QUERIES_PATH + 'create_input_account_call_data_query.txt'\n",
    "ACCOUNT_GPON_COPPER_QUERY_PATH = QUERIES_PATH + 'create_input_account_gpon_copper_query.txt'\n",
    "ACCOUNT_TROUBLE_TICKETS_QUERY_PATH = QUERIES_PATH + 'create_input_account_trouble_tickets_query.txt'\n",
    "ACCOUNT_PROMO_EXPIRY_QUERY_PATH = QUERIES_PATH + 'create_input_account_promo_expiry_query.txt'\n",
    "# ACCOUNT_TV_USAGE_QUERY_PATH = QUERIES_PATH + 'create_input_account_tv_usage_query.txt'\n",
    "ACCOUNT_DEMO_INCOME_QUERY_PATH = QUERIES_PATH + 'create_input_account_demo_income_query.txt'\n",
    "ACCOUNT_HS_USAGE_QUERY_PATH = QUERIES_PATH + 'create_input_account_hs_usage_query.txt'\n",
    "ACCOUNT_FFH_BILLING_QUERY_PATH = QUERIES_PATH + 'create_input_account_ffh_billing_query.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832f77c4-e846-47f5-b88c-b63bcaf32829",
   "metadata": {},
   "source": [
    "### define get_lift function, import df_train and df_test from gcs bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72dcae61-4a2e-436a-a337-d10cae9d7311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "project_id = PROJECT_ID\n",
    "region = REGION\n",
    "resource_bucket = RESOURCE_BUCKET\n",
    "file_bucket = FILE_BUCKET\n",
    "service_type=SERVICE_TYPE\n",
    "score_date_dash=SCORE_DATE_DASH\n",
    "score_date_val_dash=SCORE_DATE_VAL_DASH\n",
    "project_id=PROJECT_ID\n",
    "dataset_id=DATASET_ID\n",
    "\n",
    "def get_lift(prob, y_test, q):\n",
    "    result = pd.DataFrame(columns=['Prob', 'Churn'])\n",
    "    result['Prob'] = prob\n",
    "    result['Churn'] = y_test\n",
    "    # result['Decile'] = pd.qcut(1-result['Prob'], 10, labels = False)\n",
    "    result['Decile'] = pd.qcut(result['Prob'], q, labels=[i for i in range(q, 0, -1)])\n",
    "    add = pd.DataFrame(result.groupby('Decile')['Churn'].mean()).reset_index()\n",
    "    add.columns = ['Decile', 'avg_real_churn_rate']\n",
    "    result = result.merge(add, on='Decile', how='left')\n",
    "    result.sort_values('Decile', ascending=True, inplace=True)\n",
    "    lg = pd.DataFrame(result.groupby('Decile')['Prob'].mean()).reset_index()\n",
    "    lg.columns = ['Decile', 'avg_model_pred_churn_rate']\n",
    "    lg.sort_values('Decile', ascending=False, inplace=True)\n",
    "    lg['avg_churn_rate_total'] = result['Churn'].mean()\n",
    "    lg = lg.merge(add, on='Decile', how='left')\n",
    "    lg['lift'] = lg['avg_real_churn_rate'] / lg['avg_churn_rate_total']\n",
    "\n",
    "    return lg\n",
    "\n",
    "df_train = pd.read_csv('gs://{}/{}_train.csv.gz'.format(file_bucket, service_type),\n",
    "                       compression='gzip')  # for 2022-08-01\n",
    "df_test = pd.read_csv('gs://{}/{}_validation.csv.gz'.format(file_bucket, service_type),  # 2022-09-01\n",
    "                      compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5560020-78c1-43f3-85c0-1ad29402905d",
   "metadata": {},
   "source": [
    "### add targets to df_train and df_target \n",
    "\n",
    "- df_target_train is from `divg-josh-pr-d1cc3a.tos_crosssell.bq_tos_cross_sell_targets_q3` \n",
    "- df_target_test is from `divg-josh-pr-d1cc3a.tos_crosssell.bq_tos_cross_sell_targets_q4` \n",
    "- some parts of the code and sql queries need to be dynamically adjusted to be included in the deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dca5f01c-636d-4bde-a16e-ec5acd357fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25393\n",
      "28201\n"
     ]
    }
   ],
   "source": [
    "def get_gcp_bqclient(project_id, use_local_credential=True):\n",
    "    token = os.popen('gcloud auth print-access-token').read()\n",
    "    token = re.sub(f'\\n$', '', token)\n",
    "    credentials = google.oauth2.credentials.Credentials(token)\n",
    "\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    if use_local_credential:\n",
    "        bq_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "    return bq_client\n",
    "\n",
    "client = get_gcp_bqclient(project_id)\n",
    "\n",
    "#set up df_train\n",
    "sql_train = ''' SELECT * FROM `{}.{}.bq_tos_cross_sell_targets_q2` '''.format(project_id, dataset_id)\n",
    "df_target_train = client.query(sql_train).to_dataframe()\n",
    "df_target_train = df_target_train.loc[\n",
    "    df_target_train['YEAR_MONTH'] == \"2022-Q2\"] #'-'.join(score_date_dash.split('-')[:2])]  # score_date_dash = '2022-08-31'\n",
    "\n",
    "#set up df_train and df_test (add 'target')\n",
    "df_target_train['ban'] = df_target_train['ban'].astype('int64')\n",
    "df_target_train = df_target_train.groupby('ban').tail(1)\n",
    "\n",
    "df_train = df_train.merge(df_target_train[['ban', 'product_crosssell_ind']], on='ban', how='left')\n",
    "df_train.rename(columns={'product_crosssell_ind': 'target'}, inplace=True)\n",
    "df_train.dropna(subset=['target'], inplace=True)\n",
    "df_train['target'] = df_train['target'].astype(int)\n",
    "df_train.to_csv('gs://{}/outputs/{}_train_final.csv'.format(FILE_BUCKET, SERVICE_TYPE), index=False)\n",
    "\n",
    "print(np.sum(df_train['target']))\n",
    "\n",
    "client = get_gcp_bqclient(project_id)\n",
    "\n",
    "#set up df_test\n",
    "sql_test = ''' SELECT * FROM `{}.{}.bq_tos_cross_sell_targets_q3` '''.format(project_id, dataset_id)\n",
    "df_target_test = client.query(sql_test).to_dataframe()\n",
    "df_target_test = df_target_test.loc[\n",
    "    df_target_test['YEAR_MONTH'] == \"2022-Q3\"] #'-'.join(score_date_val_dash.split('-')[:2])]  # score_date_dash = '2022-09-30'\n",
    "\n",
    "#set up df_train and df_test (add 'target')\n",
    "df_target_test['ban'] = df_target_test['ban'].astype('int64')\n",
    "df_target_test = df_target_test.groupby('ban').tail(1)\n",
    "\n",
    "df_test = df_test.merge(df_target_test[['ban', 'product_crosssell_ind']], on='ban', how='left')\n",
    "df_test.rename(columns={'product_crosssell_ind': 'target'}, inplace=True)\n",
    "df_test.dropna(subset=['target'], inplace=True)\n",
    "df_test['target'] = df_test['target'].astype(int)\n",
    "df_test.to_csv('gs://{}/outputs/{}_test_final.csv'.format(FILE_BUCKET, SERVICE_TYPE), index=False)\n",
    "\n",
    "print(np.sum(df_test['target']))\n",
    "\n",
    "#set up features (list)\n",
    "cols_1 = df_train.columns.values\n",
    "cols_2 = df_test.columns.values\n",
    "cols = set(cols_1).intersection(set(cols_2))\n",
    "features = [f for f in cols if f not in ['ban', 'target']]\n",
    "\n",
    "#train test split\n",
    "df_train, df_val = train_test_split(df_train, shuffle=True, test_size=0.3, random_state=42,\n",
    "                                    stratify=df_train['target']\n",
    "                                    )\n",
    "\n",
    "ban_train = df_train['ban']\n",
    "X_train = df_train[features]\n",
    "y_train = np.squeeze(df_train['target'].values)\n",
    "target_train = df_train['target']\n",
    "\n",
    "ban_val = df_val['ban']\n",
    "X_val = df_val[features]\n",
    "y_val = np.squeeze(df_val['target'].values)\n",
    "target_val = df_val['target']\n",
    "\n",
    "ban_test = df_test['ban']\n",
    "X_test = df_test[features]\n",
    "y_test = np.squeeze(df_test['target'].values)\n",
    "target_test = df_test['target']\n",
    "\n",
    "# # del df_train, df_val, df_test\n",
    "# del df_train, df_test\n",
    "# gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564912fb-ab03-4521-8996-94695b504fd1",
   "metadata": {},
   "source": [
    "### load the latest saved xgb_model to the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a60b4476-1997-4826-96a9-7b807a60ba4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tos_crosssell_xgb_models/tos_crosssell_models_xgb_2023-02-02 05:11:42', 'tos_crosssell_xgb_models/tos_crosssell_models_xgb_2023-02-02 07:43:09']\n",
      "...... model loaded\n"
     ]
    }
   ],
   "source": [
    "# MODEL_PATH = '{}_xgb_models/'.format(service_type)\n",
    "# df_score = pd.read_csv('gs://{}/{}_score.csv.gz'.format(file_bucket, service_type), compression='gzip')\n",
    "# df_score.dropna(subset=['ban'], inplace=True)\n",
    "# df_score.reset_index(drop=True, inplace=True)\n",
    "# print('......scoring data loaded:{}'.format(df_score.shape))\n",
    "# time.sleep(10)\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "MODEL_PATH = '{}_xgb_models/'.format(service_type)\n",
    "\n",
    "def load_model(file_bucket: str, service_type: str): \n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(file_bucket)\n",
    "    blobs = storage_client.list_blobs(file_bucket, prefix='{}{}_models_xgb_2023-02-02'.format(MODEL_PATH, service_type))\n",
    "\n",
    "    model_lists = []\n",
    "    for blob in blobs:\n",
    "        model_lists.append(blob.name)\n",
    "        \n",
    "    print(model_lists)\n",
    "\n",
    "    blob = bucket.blob(model_lists[-1])\n",
    "    blob_in = blob.download_as_string()\n",
    "    model_dict = pickle.loads(blob_in)\n",
    "    xgb_model = model_dict['model']\n",
    "    features = model_dict['features']\n",
    "    print('...... model loaded')\n",
    "    time.sleep(10)\n",
    "    \n",
    "    return xgb_model, features\n",
    "\n",
    "xgb_model, features = load_model(file_bucket = FILE_BUCKET, service_type = SERVICE_TYPE) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a892174-3ca6-4d29-b3ec-852aa868c0be",
   "metadata": {},
   "source": [
    "### make predictions on X_test set, assign deciles to the predicted values, and save in df_test_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73864ebc-16d3-46a3-ab4b-780f25e0167b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decile</th>\n",
       "      <th>avg_model_pred_churn_rate</th>\n",
       "      <th>avg_churn_rate_total</th>\n",
       "      <th>avg_real_churn_rate</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.017226</td>\n",
       "      <td>1.175132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.014762</td>\n",
       "      <td>1.007059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.015261</td>\n",
       "      <td>1.041100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.015510</td>\n",
       "      <td>1.058115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.914168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.011484</td>\n",
       "      <td>0.783397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.011920</td>\n",
       "      <td>0.813178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.015395</td>\n",
       "      <td>1.050265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.016261</td>\n",
       "      <td>1.109344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.015375</td>\n",
       "      <td>1.048896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Decile  avg_model_pred_churn_rate  avg_churn_rate_total  \\\n",
       "0      1                   0.001338              0.014659   \n",
       "1      2                   0.000958              0.014659   \n",
       "2      3                   0.000792              0.014659   \n",
       "3      4                   0.000667              0.014659   \n",
       "4      5                   0.000579              0.014659   \n",
       "5      6                   0.000528              0.014659   \n",
       "6      7                   0.000490              0.014659   \n",
       "7      8                   0.000444              0.014659   \n",
       "8      9                   0.000379              0.014659   \n",
       "9     10                   0.000265              0.014659   \n",
       "\n",
       "   avg_real_churn_rate      lift  \n",
       "0             0.017226  1.175132  \n",
       "1             0.014762  1.007059  \n",
       "2             0.015261  1.041100  \n",
       "3             0.015510  1.058115  \n",
       "4             0.013400  0.914168  \n",
       "5             0.011484  0.783397  \n",
       "6             0.011920  0.813178  \n",
       "7             0.015395  1.050265  \n",
       "8             0.016261  1.109344  \n",
       "9             0.015375  1.048896  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#predictions on X_test\n",
    "pred_prb = xgb_model.predict_proba(X_test, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "#join ban_test, X_test, y_test and pred_prb and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_test = ban_test.to_frame()\n",
    "df_test_exp = df_ban_test.join(X_test) \n",
    "df_test_exp['y_test'] = y_test\n",
    "df_test_exp['y_pred_proba'] = pred_prb\n",
    "df_test_exp['y_pred'] = (df_test_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_test_exp['decile'] = pd.qcut(df_test_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(pred_prb, y_test, q)\n",
    "\n",
    "lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf99bd6-0718-49d2-8bf0-55291ccaed12",
   "metadata": {},
   "source": [
    "### make predictions on X_train set, assign deciles to the predicted values, and save in df_train_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6e2a02e-8197-4c8a-9aa1-59b6b5c2ba21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/core.py:90: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decile</th>\n",
       "      <th>avg_model_pred_churn_rate</th>\n",
       "      <th>avg_churn_rate_total</th>\n",
       "      <th>avg_real_churn_rate</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.01379</td>\n",
       "      <td>0.014771</td>\n",
       "      <td>1.071166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.01379</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.941771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.01379</td>\n",
       "      <td>0.012832</td>\n",
       "      <td>0.930519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.01379</td>\n",
       "      <td>0.011924</td>\n",
       "      <td>0.864645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.01379</td>\n",
       "      <td>0.009408</td>\n",
       "      <td>0.682257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.01379</td>\n",
       "      <td>0.010854</td>\n",
       "      <td>0.787059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.01379</td>\n",
       "      <td>0.015959</td>\n",
       "      <td>1.157251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.01379</td>\n",
       "      <td>0.017751</td>\n",
       "      <td>1.287199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.01379</td>\n",
       "      <td>0.017262</td>\n",
       "      <td>1.251766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.01379</td>\n",
       "      <td>0.014158</td>\n",
       "      <td>1.026713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Decile  avg_model_pred_churn_rate  avg_churn_rate_total  \\\n",
       "0      1                   0.001566               0.01379   \n",
       "1      2                   0.001168               0.01379   \n",
       "2      3                   0.001024               0.01379   \n",
       "3      4                   0.000814               0.01379   \n",
       "4      5                   0.000719               0.01379   \n",
       "5      6                   0.000663               0.01379   \n",
       "6      7                   0.000608               0.01379   \n",
       "7      8                   0.000557               0.01379   \n",
       "8      9                   0.000511               0.01379   \n",
       "9     10                   0.000371               0.01379   \n",
       "\n",
       "   avg_real_churn_rate      lift  \n",
       "0             0.014771  1.071166  \n",
       "1             0.012987  0.941771  \n",
       "2             0.012832  0.930519  \n",
       "3             0.011924  0.864645  \n",
       "4             0.009408  0.682257  \n",
       "5             0.010854  0.787059  \n",
       "6             0.015959  1.157251  \n",
       "7             0.017751  1.287199  \n",
       "8             0.017262  1.251766  \n",
       "9             0.014158  1.026713  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictions on X_test\n",
    "pred_prb = xgb_model.predict_proba(X_train, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "pred_prb = np.array(normalize([pred_prb]))[0]\n",
    "\n",
    "#join ban_test, X_test, y_test and pred_prb and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_train = ban_train.to_frame()\n",
    "df_train_exp = df_ban_train.join(X_train) \n",
    "df_train_exp['y_test'] = y_train\n",
    "df_train_exp['y_pred_proba'] = pred_prb\n",
    "df_train_exp['y_pred'] = (df_train_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_train_exp['decile'] = pd.qcut(df_train_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(pred_prb, y_train, q)\n",
    "\n",
    "lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2515727d-4aa2-4dab-9834-a77b8fbc99ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed87cf74-afc9-443a-84c5-787011a436be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
